{
  "allSuites": [
    {
      "time": 4,
      "tests": 3,
      "failures": 0,
      "errors": 0,
      "skipped": 0,
      "name": "io.lenses.core.monitoring.actions.RaiseZkAlertsFnTest",
      "timestamp": "2020-07-26T21:54:50",
      "testcase": [
        {
          "name": "RaiseZkAlertsFn should raise an alert when the ZK is down",
          "classname": "io.lenses.core.monitoring.actions.RaiseZkAlertsFnTest",
          "time": 2,
          "failure": null,
          "error": null,
          "skipped": false
        },
        {
          "name": "RaiseZkAlertsFn should not raise the alert more than once",
          "classname": "io.lenses.core.monitoring.actions.RaiseZkAlertsFnTest",
          "time": 1,
          "failure": null,
          "error": null,
          "skipped": false
        },
        {
          "name": "RaiseZkAlertsFn should raise an alert when the one ZK node is online and another one is down",
          "classname": "io.lenses.core.monitoring.actions.RaiseZkAlertsFnTest",
          "time": 1,
          "failure": null,
          "error": null,
          "skipped": false
        }
      ]
    },
    {
      "time": 47,
      "tests": 5,
      "failures": 0,
      "errors": 0,
      "skipped": 0,
      "name": "io.lenses.core.channels.ChannelLicenseChecksTest",
      "timestamp": "2020-07-26T21:54:52",
      "testcase": [
        {
          "name": "ChannelLicenseChecksTest should check maximum number of alert channels when maximum number not reached",
          "classname": "io.lenses.core.channels.ChannelLicenseChecksTest",
          "time": 42,
          "failure": null,
          "error": null,
          "skipped": false
        },
        {
          "name": "ChannelLicenseChecksTest should check maximum number of alert channels when maximum number reached",
          "classname": "io.lenses.core.channels.ChannelLicenseChecksTest",
          "time": 2,
          "failure": null,
          "error": null,
          "skipped": false
        },
        {
          "name": "ChannelLicenseChecksTest should check allowed channel integration when trying to create new channel with allowed name/type",
          "classname": "io.lenses.core.channels.ChannelLicenseChecksTest",
          "time": 2,
          "failure": null,
          "error": null,
          "skipped": false
        },
        {
          "name": "ChannelLicenseChecksTest should check allowed channel integration when trying to create new channel with disabled name/type",
          "classname": "io.lenses.core.channels.ChannelLicenseChecksTest",
          "time": 0,
          "failure": null,
          "error": null,
          "skipped": false
        },
        {
          "name": "ChannelLicenseChecksTest should check allowed channel integration when trying to create new channel when there is no restriction on name/type",
          "classname": "io.lenses.core.channels.ChannelLicenseChecksTest",
          "time": 1,
          "failure": null,
          "error": null,
          "skipped": false
        }
      ]
    },
    {
      "time": 10,
      "tests": 5,
      "failures": 0,
      "errors": 0,
      "skipped": 0,
      "name": "io.lenses.core.kafka.ConnectorsRepositoryImplTest",
      "timestamp": "2020-07-26T21:54:43",
      "testcase": [
        {
          "name": "ConnectorsRepositoryImpl should return None if the cluster is not present",
          "classname": "io.lenses.core.kafka.ConnectorsRepositoryImplTest",
          "time": 2,
          "failure": null,
          "error": null,
          "skipped": false
        },
        {
          "name": "ConnectorsRepositoryImpl should handles a remove even if the connector is not present",
          "classname": "io.lenses.core.kafka.ConnectorsRepositoryImplTest",
          "time": 1,
          "failure": null,
          "error": null,
          "skipped": false
        },
        {
          "name": "ConnectorsRepositoryImpl should return None if the connector config is not understood",
          "classname": "io.lenses.core.kafka.ConnectorsRepositoryImplTest",
          "time": 3,
          "failure": null,
          "error": null,
          "skipped": false
        },
        {
          "name": "ConnectorsRepositoryImpl should adds the connector to the repo",
          "classname": "io.lenses.core.kafka.ConnectorsRepositoryImplTest",
          "time": 4,
          "failure": null,
          "error": null,
          "skipped": false
        },
        {
          "name": "ConnectorsRepositoryImpl should adds the connector and remove it",
          "classname": "io.lenses.core.kafka.ConnectorsRepositoryImplTest",
          "time": 0,
          "failure": null,
          "error": null,
          "skipped": false
        }
      ]
    },
    {
      "time": 65372,
      "tests": 11,
      "failures": 3,
      "errors": 0,
      "skipped": 0,
      "name": "io.lenses.core.kafka.TopicCommandTest",
      "timestamp": "2020-07-26T21:54:37",
      "testcase": [
        {
          "name": "type is not CreateTime or LogAppendTime",
          "classname": "io.lenses.core.kafka.TopicCommandTest",
          "time": 27,
          "failure": null,
          "error": null,
          "skipped": false
        },
        {
          "name": "createTopic should create a topic with compact cleanup policy",
          "classname": "io.lenses.core.kafka.TopicCommandTest",
          "time": 20011,
          "failure": {
            "message": null,
            "type": "java.util.concurrent.TimeoutException",
            "stackTrace": "java.util.concurrent.TimeoutException\n\tat org.apache.kafka.common.internals.KafkaFutureImpl$SingleWaiter.await(KafkaFutureImpl.java:108)\n\tat org.apache.kafka.common.internals.KafkaFutureImpl.get(KafkaFutureImpl.java:272)\n\tat io.lenses.core.kafka.TopicCommand$.$anonfun$createTopic$1(TopicCommand.scala:93)\n\tat io.lenses.domain.logging.MetricsSupport.timed(MetricsSupport.scala:22)\n\tat io.lenses.domain.logging.MetricsSupport.timed$(MetricsSupport.scala:20)\n\tat io.lenses.core.kafka.TopicCommand$.timed(TopicCommand.scala:47)\n\tat io.lenses.core.kafka.TopicCommand$.createTopic(TopicCommand.scala:58)\n\tat io.lenses.core.kafka.TopicCommandTest.$anonfun$new$8(TopicCommandTest.scala:105)\n\tat io.lenses.core.kafka.TopicCommandTest.$anonfun$new$8$adapted(TopicCommandTest.scala:96)\n\tat io.lenses.core.kafka.TopicCommandTest.testEnvironment$1(TopicCommandTest.scala:67)\n\tat io.lenses.core.kafka.TopicCommandTest.$anonfun$new$6(TopicCommandTest.scala:96)\n\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n\tat org.scalatest.OutcomeOf.outcomeOf(OutcomeOf.scala:85)\n\tat org.scalatest.OutcomeOf.outcomeOf$(OutcomeOf.scala:83)\n\tat org.scalatest.OutcomeOf$.outcomeOf(OutcomeOf.scala:104)\n\tat org.scalatest.Transformer.apply(Transformer.scala:22)\n\tat org.scalatest.Transformer.apply(Transformer.scala:20)\n\tat org.scalatest.wordspec.AnyWordSpecLike$$anon$3.apply(AnyWordSpecLike.scala:1076)\n\tat org.scalatest.TestSuite.withFixture(TestSuite.scala:196)\n\tat org.scalatest.TestSuite.withFixture$(TestSuite.scala:195)\n\tat org.scalatest.wordspec.AnyWordSpec.withFixture(AnyWordSpec.scala:1879)\n\tat org.scalatest.wordspec.AnyWordSpecLike.invokeWithFixture$1(AnyWordSpecLike.scala:1074)\n\tat org.scalatest.wordspec.AnyWordSpecLike.$anonfun$runTest$1(AnyWordSpecLike.scala:1086)\n\tat org.scalatest.SuperEngine.runTestImpl(Engine.scala:306)\n\tat org.scalatest.wordspec.AnyWordSpecLike.runTest(AnyWordSpecLike.scala:1086)\n\tat org.scalatest.wordspec.AnyWordSpecLike.runTest$(AnyWordSpecLike.scala:1068)\n\tat org.scalatest.wordspec.AnyWordSpec.runTest(AnyWordSpec.scala:1879)\n\tat org.scalatest.wordspec.AnyWordSpecLike.$anonfun$runTests$1(AnyWordSpecLike.scala:1145)\n\tat org.scalatest.SuperEngine.$anonfun$runTestsInBranch$1(Engine.scala:413)\n\tat scala.collection.immutable.List.foreach(List.scala:392)\n\tat org.scalatest.SuperEngine.traverseSubNodes$1(Engine.scala:401)\n\tat org.scalatest.SuperEngine.runTestsInBranch(Engine.scala:390)\n\tat org.scalatest.SuperEngine.$anonfun$runTestsInBranch$1(Engine.scala:427)\n\tat scala.collection.immutable.List.foreach(List.scala:392)\n\tat org.scalatest.SuperEngine.traverseSubNodes$1(Engine.scala:401)\n\tat org.scalatest.SuperEngine.runTestsInBranch(Engine.scala:396)\n\tat org.scalatest.SuperEngine.runTestsImpl(Engine.scala:475)\n\tat org.scalatest.wordspec.AnyWordSpecLike.runTests(AnyWordSpecLike.scala:1145)\n\tat org.scalatest.wordspec.AnyWordSpecLike.runTests$(AnyWordSpecLike.scala:1144)\n\tat org.scalatest.wordspec.AnyWordSpec.runTests(AnyWordSpec.scala:1879)\n\tat org.scalatest.Suite.run(Suite.scala:1112)\n\tat org.scalatest.Suite.run$(Suite.scala:1094)\n\tat org.scalatest.wordspec.AnyWordSpec.org$scalatest$wordspec$AnyWordSpecLike$$super$run(AnyWordSpec.scala:1879)\n\tat org.scalatest.wordspec.AnyWordSpecLike.$anonfun$run$1(AnyWordSpecLike.scala:1190)\n\tat org.scalatest.SuperEngine.runImpl(Engine.scala:535)\n\tat org.scalatest.wordspec.AnyWordSpecLike.run(AnyWordSpecLike.scala:1190)\n\tat org.scalatest.wordspec.AnyWordSpecLike.run$(AnyWordSpecLike.scala:1188)\n\tat io.lenses.core.kafka.TopicCommandTest.org$scalatest$BeforeAndAfterAll$$super$run(TopicCommandTest.scala:53)\n\tat org.scalatest.BeforeAndAfterAll.liftedTree1$1(BeforeAndAfterAll.scala:213)\n\tat org.scalatest.BeforeAndAfterAll.run(BeforeAndAfterAll.scala:210)\n\tat org.scalatest.BeforeAndAfterAll.run$(BeforeAndAfterAll.scala:208)\n\tat io.lenses.core.kafka.TopicCommandTest.run(TopicCommandTest.scala:53)\n\tat org.scalatest.tools.Framework.org$scalatest$tools$Framework$$runSuite(Framework.scala:318)\n\tat org.scalatest.tools.Framework$ScalaTestTask.execute(Framework.scala:513)\n\tat sbt.TestRunner.runTest$1(TestFramework.scala:139)\n\tat sbt.TestRunner.run(TestFramework.scala:154)\n\tat sbt.TestFramework$$anon$3$$anonfun$$lessinit$greater$1.$anonfun$apply$1(TestFramework.scala:317)\n\tat sbt.TestFramework$.sbt$TestFramework$$withContextLoader(TestFramework.scala:277)\n\tat sbt.TestFramework$$anon$3$$anonfun$$lessinit$greater$1.apply(TestFramework.scala:317)\n\tat sbt.TestFramework$$anon$3$$anonfun$$lessinit$greater$1.apply(TestFramework.scala:317)\n\tat sbt.TestFunction.apply(TestFramework.scala:329)\n\tat sbt.Tests$.$anonfun$toTask$1(Tests.scala:311)\n\tat sbt.std.Transform$$anon$3.$anonfun$apply$2(Transform.scala:46)\n\tat sbt.std.Transform$$anon$4.work(Transform.scala:67)\n\tat sbt.Execute.$anonfun$submit$2(Execute.scala:281)\n\tat sbt.internal.util.ErrorHandling$.wideConvert(ErrorHandling.scala:19)\n\tat sbt.Execute.work(Execute.scala:290)\n\tat sbt.Execute.$anonfun$submit$1(Execute.scala:281)\n\tat sbt.ConcurrentRestrictions$$anon$4.$anonfun$submitValid$1(ConcurrentRestrictions.scala:178)\n\tat sbt.CompletionService$$anon$2.call(CompletionService.scala:37)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:748)"
          },
          "error": null,
          "skipped": false
        },
        {
          "name": "type CreateTime",
          "classname": "io.lenses.core.kafka.TopicCommandTest",
          "time": 20010,
          "failure": {
            "message": null,
            "type": "java.util.concurrent.TimeoutException",
            "stackTrace": "java.util.concurrent.TimeoutException\n\tat org.apache.kafka.common.internals.KafkaFutureImpl$SingleWaiter.await(KafkaFutureImpl.java:108)\n\tat org.apache.kafka.common.internals.KafkaFutureImpl.get(KafkaFutureImpl.java:272)\n\tat io.lenses.core.kafka.TopicCommand$.$anonfun$createTopic$1(TopicCommand.scala:93)\n\tat io.lenses.domain.logging.MetricsSupport.timed(MetricsSupport.scala:22)\n\tat io.lenses.domain.logging.MetricsSupport.timed$(MetricsSupport.scala:20)\n\tat io.lenses.core.kafka.TopicCommand$.timed(TopicCommand.scala:47)\n\tat io.lenses.core.kafka.TopicCommand$.createTopic(TopicCommand.scala:58)\n\tat io.lenses.core.kafka.TopicCommandTest.$anonfun$new$13(TopicCommandTest.scala:125)\n\tat io.lenses.core.kafka.TopicCommandTest.$anonfun$new$13$adapted(TopicCommandTest.scala:118)\n\tat io.lenses.core.kafka.TopicCommandTest.testEnvironment$1(TopicCommandTest.scala:67)\n\tat io.lenses.core.kafka.TopicCommandTest.$anonfun$new$11(TopicCommandTest.scala:118)\n\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n\tat org.scalatest.OutcomeOf.outcomeOf(OutcomeOf.scala:85)\n\tat org.scalatest.OutcomeOf.outcomeOf$(OutcomeOf.scala:83)\n\tat org.scalatest.OutcomeOf$.outcomeOf(OutcomeOf.scala:104)\n\tat org.scalatest.Transformer.apply(Transformer.scala:22)\n\tat org.scalatest.Transformer.apply(Transformer.scala:20)\n\tat org.scalatest.wordspec.AnyWordSpecLike$$anon$3.apply(AnyWordSpecLike.scala:1076)\n\tat org.scalatest.TestSuite.withFixture(TestSuite.scala:196)\n\tat org.scalatest.TestSuite.withFixture$(TestSuite.scala:195)\n\tat org.scalatest.wordspec.AnyWordSpec.withFixture(AnyWordSpec.scala:1879)\n\tat org.scalatest.wordspec.AnyWordSpecLike.invokeWithFixture$1(AnyWordSpecLike.scala:1074)\n\tat org.scalatest.wordspec.AnyWordSpecLike.$anonfun$runTest$1(AnyWordSpecLike.scala:1086)\n\tat org.scalatest.SuperEngine.runTestImpl(Engine.scala:306)\n\tat org.scalatest.wordspec.AnyWordSpecLike.runTest(AnyWordSpecLike.scala:1086)\n\tat org.scalatest.wordspec.AnyWordSpecLike.runTest$(AnyWordSpecLike.scala:1068)\n\tat org.scalatest.wordspec.AnyWordSpec.runTest(AnyWordSpec.scala:1879)\n\tat org.scalatest.wordspec.AnyWordSpecLike.$anonfun$runTests$1(AnyWordSpecLike.scala:1145)\n\tat org.scalatest.SuperEngine.$anonfun$runTestsInBranch$1(Engine.scala:413)\n\tat scala.collection.immutable.List.foreach(List.scala:392)\n\tat org.scalatest.SuperEngine.traverseSubNodes$1(Engine.scala:401)\n\tat org.scalatest.SuperEngine.runTestsInBranch(Engine.scala:390)\n\tat org.scalatest.SuperEngine.$anonfun$runTestsInBranch$1(Engine.scala:427)\n\tat scala.collection.immutable.List.foreach(List.scala:392)\n\tat org.scalatest.SuperEngine.traverseSubNodes$1(Engine.scala:401)\n\tat org.scalatest.SuperEngine.runTestsInBranch(Engine.scala:396)\n\tat org.scalatest.SuperEngine.runTestsImpl(Engine.scala:475)\n\tat org.scalatest.wordspec.AnyWordSpecLike.runTests(AnyWordSpecLike.scala:1145)\n\tat org.scalatest.wordspec.AnyWordSpecLike.runTests$(AnyWordSpecLike.scala:1144)\n\tat org.scalatest.wordspec.AnyWordSpec.runTests(AnyWordSpec.scala:1879)\n\tat org.scalatest.Suite.run(Suite.scala:1112)\n\tat org.scalatest.Suite.run$(Suite.scala:1094)\n\tat org.scalatest.wordspec.AnyWordSpec.org$scalatest$wordspec$AnyWordSpecLike$$super$run(AnyWordSpec.scala:1879)\n\tat org.scalatest.wordspec.AnyWordSpecLike.$anonfun$run$1(AnyWordSpecLike.scala:1190)\n\tat org.scalatest.SuperEngine.runImpl(Engine.scala:535)\n\tat org.scalatest.wordspec.AnyWordSpecLike.run(AnyWordSpecLike.scala:1190)\n\tat org.scalatest.wordspec.AnyWordSpecLike.run$(AnyWordSpecLike.scala:1188)\n\tat io.lenses.core.kafka.TopicCommandTest.org$scalatest$BeforeAndAfterAll$$super$run(TopicCommandTest.scala:53)\n\tat org.scalatest.BeforeAndAfterAll.liftedTree1$1(BeforeAndAfterAll.scala:213)\n\tat org.scalatest.BeforeAndAfterAll.run(BeforeAndAfterAll.scala:210)\n\tat org.scalatest.BeforeAndAfterAll.run$(BeforeAndAfterAll.scala:208)\n\tat io.lenses.core.kafka.TopicCommandTest.run(TopicCommandTest.scala:53)\n\tat org.scalatest.tools.Framework.org$scalatest$tools$Framework$$runSuite(Framework.scala:318)\n\tat org.scalatest.tools.Framework$ScalaTestTask.execute(Framework.scala:513)\n\tat sbt.TestRunner.runTest$1(TestFramework.scala:139)\n\tat sbt.TestRunner.run(TestFramework.scala:154)\n\tat sbt.TestFramework$$anon$3$$anonfun$$lessinit$greater$1.$anonfun$apply$1(TestFramework.scala:317)\n\tat sbt.TestFramework$.sbt$TestFramework$$withContextLoader(TestFramework.scala:277)\n\tat sbt.TestFramework$$anon$3$$anonfun$$lessinit$greater$1.apply(TestFramework.scala:317)\n\tat sbt.TestFramework$$anon$3$$anonfun$$lessinit$greater$1.apply(TestFramework.scala:317)\n\tat sbt.TestFunction.apply(TestFramework.scala:329)\n\tat sbt.Tests$.$anonfun$toTask$1(Tests.scala:311)\n\tat sbt.std.Transform$$anon$3.$anonfun$apply$2(Transform.scala:46)\n\tat sbt.std.Transform$$anon$4.work(Transform.scala:67)\n\tat sbt.Execute.$anonfun$submit$2(Execute.scala:281)\n\tat sbt.internal.util.ErrorHandling$.wideConvert(ErrorHandling.scala:19)\n\tat sbt.Execute.work(Execute.scala:290)\n\tat sbt.Execute.$anonfun$submit$1(Execute.scala:281)\n\tat sbt.ConcurrentRestrictions$$anon$4.$anonfun$submitValid$1(ConcurrentRestrictions.scala:178)\n\tat sbt.CompletionService$$anon$2.call(CompletionService.scala:37)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:748)"
          },
          "error": null,
          "skipped": false
        },
        {
          "name": "createTopic should update topic config, preserving default values",
          "classname": "io.lenses.core.kafka.TopicCommandTest",
          "time": 25044,
          "failure": {
            "message": null,
            "type": "java.util.concurrent.TimeoutException",
            "stackTrace": "java.util.concurrent.TimeoutException\n\tat org.apache.kafka.common.internals.KafkaFutureImpl$SingleWaiter.await(KafkaFutureImpl.java:108)\n\tat org.apache.kafka.common.internals.KafkaFutureImpl.get(KafkaFutureImpl.java:272)\n\tat io.lenses.core.kafka.TopicCommand$.$anonfun$createTopic$1(TopicCommand.scala:93)\n\tat io.lenses.domain.logging.MetricsSupport.timed(MetricsSupport.scala:22)\n\tat io.lenses.domain.logging.MetricsSupport.timed$(MetricsSupport.scala:20)\n\tat io.lenses.core.kafka.TopicCommand$.timed(TopicCommand.scala:47)\n\tat io.lenses.core.kafka.TopicCommand$.createTopic(TopicCommand.scala:58)\n\tat io.lenses.core.kafka.TopicCommandTest.$anonfun$new$19(TopicCommandTest.scala:145)\n\tat io.lenses.core.kafka.TopicCommandTest.withKafkaTableRepository(TopicCommandTest.scala:341)\n\tat io.lenses.core.kafka.TopicCommandTest.$anonfun$new$18(TopicCommandTest.scala:144)\n\tat io.lenses.core.kafka.TopicCommandTest.testEnvironment$1(TopicCommandTest.scala:67)\n\tat io.lenses.core.kafka.TopicCommandTest.$anonfun$new$16(TopicCommandTest.scala:138)\n\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n\tat org.scalatest.OutcomeOf.outcomeOf(OutcomeOf.scala:85)\n\tat org.scalatest.OutcomeOf.outcomeOf$(OutcomeOf.scala:83)\n\tat org.scalatest.OutcomeOf$.outcomeOf(OutcomeOf.scala:104)\n\tat org.scalatest.Transformer.apply(Transformer.scala:22)\n\tat org.scalatest.Transformer.apply(Transformer.scala:20)\n\tat org.scalatest.wordspec.AnyWordSpecLike$$anon$3.apply(AnyWordSpecLike.scala:1076)\n\tat org.scalatest.TestSuite.withFixture(TestSuite.scala:196)\n\tat org.scalatest.TestSuite.withFixture$(TestSuite.scala:195)\n\tat org.scalatest.wordspec.AnyWordSpec.withFixture(AnyWordSpec.scala:1879)\n\tat org.scalatest.wordspec.AnyWordSpecLike.invokeWithFixture$1(AnyWordSpecLike.scala:1074)\n\tat org.scalatest.wordspec.AnyWordSpecLike.$anonfun$runTest$1(AnyWordSpecLike.scala:1086)\n\tat org.scalatest.SuperEngine.runTestImpl(Engine.scala:306)\n\tat org.scalatest.wordspec.AnyWordSpecLike.runTest(AnyWordSpecLike.scala:1086)\n\tat org.scalatest.wordspec.AnyWordSpecLike.runTest$(AnyWordSpecLike.scala:1068)\n\tat org.scalatest.wordspec.AnyWordSpec.runTest(AnyWordSpec.scala:1879)\n\tat org.scalatest.wordspec.AnyWordSpecLike.$anonfun$runTests$1(AnyWordSpecLike.scala:1145)\n\tat org.scalatest.SuperEngine.$anonfun$runTestsInBranch$1(Engine.scala:413)\n\tat scala.collection.immutable.List.foreach(List.scala:392)\n\tat org.scalatest.SuperEngine.traverseSubNodes$1(Engine.scala:401)\n\tat org.scalatest.SuperEngine.runTestsInBranch(Engine.scala:390)\n\tat org.scalatest.SuperEngine.$anonfun$runTestsInBranch$1(Engine.scala:427)\n\tat scala.collection.immutable.List.foreach(List.scala:392)\n\tat org.scalatest.SuperEngine.traverseSubNodes$1(Engine.scala:401)\n\tat org.scalatest.SuperEngine.runTestsInBranch(Engine.scala:396)\n\tat org.scalatest.SuperEngine.runTestsImpl(Engine.scala:475)\n\tat org.scalatest.wordspec.AnyWordSpecLike.runTests(AnyWordSpecLike.scala:1145)\n\tat org.scalatest.wordspec.AnyWordSpecLike.runTests$(AnyWordSpecLike.scala:1144)\n\tat org.scalatest.wordspec.AnyWordSpec.runTests(AnyWordSpec.scala:1879)\n\tat org.scalatest.Suite.run(Suite.scala:1112)\n\tat org.scalatest.Suite.run$(Suite.scala:1094)\n\tat org.scalatest.wordspec.AnyWordSpec.org$scalatest$wordspec$AnyWordSpecLike$$super$run(AnyWordSpec.scala:1879)\n\tat org.scalatest.wordspec.AnyWordSpecLike.$anonfun$run$1(AnyWordSpecLike.scala:1190)\n\tat org.scalatest.SuperEngine.runImpl(Engine.scala:535)\n\tat org.scalatest.wordspec.AnyWordSpecLike.run(AnyWordSpecLike.scala:1190)\n\tat org.scalatest.wordspec.AnyWordSpecLike.run$(AnyWordSpecLike.scala:1188)\n\tat io.lenses.core.kafka.TopicCommandTest.org$scalatest$BeforeAndAfterAll$$super$run(TopicCommandTest.scala:53)\n\tat org.scalatest.BeforeAndAfterAll.liftedTree1$1(BeforeAndAfterAll.scala:213)\n\tat org.scalatest.BeforeAndAfterAll.run(BeforeAndAfterAll.scala:210)\n\tat org.scalatest.BeforeAndAfterAll.run$(BeforeAndAfterAll.scala:208)\n\tat io.lenses.core.kafka.TopicCommandTest.run(TopicCommandTest.scala:53)\n\tat org.scalatest.tools.Framework.org$scalatest$tools$Framework$$runSuite(Framework.scala:318)\n\tat org.scalatest.tools.Framework$ScalaTestTask.execute(Framework.scala:513)\n\tat sbt.TestRunner.runTest$1(TestFramework.scala:139)\n\tat sbt.TestRunner.run(TestFramework.scala:154)\n\tat sbt.TestFramework$$anon$3$$anonfun$$lessinit$greater$1.$anonfun$apply$1(TestFramework.scala:317)\n\tat sbt.TestFramework$.sbt$TestFramework$$withContextLoader(TestFramework.scala:277)\n\tat sbt.TestFramework$$anon$3$$anonfun$$lessinit$greater$1.apply(TestFramework.scala:317)\n\tat sbt.TestFramework$$anon$3$$anonfun$$lessinit$greater$1.apply(TestFramework.scala:317)\n\tat sbt.TestFunction.apply(TestFramework.scala:329)\n\tat sbt.Tests$.$anonfun$toTask$1(Tests.scala:311)\n\tat sbt.std.Transform$$anon$3.$anonfun$apply$2(Transform.scala:46)\n\tat sbt.std.Transform$$anon$4.work(Transform.scala:67)\n\tat sbt.Execute.$anonfun$submit$2(Execute.scala:281)\n\tat sbt.internal.util.ErrorHandling$.wideConvert(ErrorHandling.scala:19)\n\tat sbt.Execute.work(Execute.scala:290)\n\tat sbt.Execute.$anonfun$submit$1(Execute.scala:281)\n\tat sbt.ConcurrentRestrictions$$anon$4.$anonfun$submitValid$1(ConcurrentRestrictions.scala:178)\n\tat sbt.CompletionService$$anon$2.call(CompletionService.scala:37)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:748)"
          },
          "error": null,
          "skipped": false
        },
        {
          "name": "increasePartitionCount should return TopicNotFound if describeTopics doesn't return a value with the given topic",
          "classname": "io.lenses.core.kafka.TopicCommandTest",
          "time": 5,
          "failure": null,
          "error": null,
          "skipped": false
        },
        {
          "name": "increasePartitionCount should return TopicNotFound if describeTopics throws an exception",
          "classname": "io.lenses.core.kafka.TopicCommandTest",
          "time": 42,
          "failure": null,
          "error": null,
          "skipped": false
        },
        {
          "name": "increasePartitionCount should return failed Future if createPartitions doesn't return a result for the given topic (should never happen)",
          "classname": "io.lenses.core.kafka.TopicCommandTest",
          "time": 46,
          "failure": null,
          "error": null,
          "skipped": false
        },
        {
          "name": "increasePartitionCount should return PartitionsAdded with number of new partitions on success",
          "classname": "io.lenses.core.kafka.TopicCommandTest",
          "time": 47,
          "failure": null,
          "error": null,
          "skipped": false
        },
        {
          "name": "increasePartitionCount should pass failure to update topic on to caller",
          "classname": "io.lenses.core.kafka.TopicCommandTest",
          "time": 48,
          "failure": null,
          "error": null,
          "skipped": false
        },
        {
          "name": "increasePartitionCount should return InvalidNumberOfPartitions if number of partitions specified is less than existing number",
          "classname": "io.lenses.core.kafka.TopicCommandTest",
          "time": 45,
          "failure": null,
          "error": null,
          "skipped": false
        },
        {
          "name": "increasePartitionCount should return InvalidNumberOfPartitions if number of partitions specified is equal to existing number",
          "classname": "io.lenses.core.kafka.TopicCommandTest",
          "time": 46,
          "failure": null,
          "error": null,
          "skipped": false
        }
      ]
    },
    {
      "time": 1,
      "tests": 6,
      "failures": 0,
      "errors": 0,
      "skipped": 0,
      "name": "io.lenses.core.security.SecurityConfigTest",
      "timestamp": "2020-07-26T21:54:42",
      "testcase": [
        {
          "name": " returns an error",
          "classname": "io.lenses.core.security.SecurityConfigTest",
          "time": 1,
          "failure": null,
          "error": null,
          "skipped": false
        },
        {
          "name": "validating the admin password format for abc does return None",
          "classname": "io.lenses.core.security.SecurityConfigTest",
          "time": 0,
          "failure": null,
          "error": null,
          "skipped": false
        },
        {
          "name": "validating the admin password format for PLAIN:abc does return None",
          "classname": "io.lenses.core.security.SecurityConfigTest",
          "time": 0,
          "failure": null,
          "error": null,
          "skipped": false
        },
        {
          "name": "validating the admin password format for PLaIN:abc does return None",
          "classname": "io.lenses.core.security.SecurityConfigTest",
          "time": 0,
          "failure": null,
          "error": null,
          "skipped": false
        },
        {
          "name": "validating the admin password format for sha256:abc does return None",
          "classname": "io.lenses.core.security.SecurityConfigTest",
          "time": 0,
          "failure": null,
          "error": null,
          "skipped": false
        },
        {
          "name": "validating the admin password format for shA256:abc does return None",
          "classname": "io.lenses.core.security.SecurityConfigTest",
          "time": 0,
          "failure": null,
          "error": null,
          "skipped": false
        }
      ]
    },
    {
      "time": 317,
      "tests": 4,
      "failures": 0,
      "errors": 0,
      "skipped": 0,
      "name": "io.lenses.core.pagination.CollectionPaginationSpec",
      "timestamp": "2020-07-26T21:54:38",
      "testcase": [
        {
          "name": "slice should get list elements for page start and page end indexes being integers",
          "classname": "io.lenses.core.pagination.CollectionPaginationSpec",
          "time": 128,
          "failure": null,
          "error": null,
          "skipped": false
        },
        {
          "name": "slice should get last list elements for page page exceeding integer max",
          "classname": "io.lenses.core.pagination.CollectionPaginationSpec",
          "time": 99,
          "failure": null,
          "error": null,
          "skipped": false
        },
        {
          "name": "slice should get empty list for too high page start",
          "classname": "io.lenses.core.pagination.CollectionPaginationSpec",
          "time": 71,
          "failure": null,
          "error": null,
          "skipped": false
        },
        {
          "name": "slice should start from beginning of list for too first index < 0",
          "classname": "io.lenses.core.pagination.CollectionPaginationSpec",
          "time": 18,
          "failure": null,
          "error": null,
          "skipped": false
        }
      ]
    },
    {
      "time": 223,
      "tests": 21,
      "failures": 0,
      "errors": 0,
      "skipped": 0,
      "name": "io.lenses.core.kafka.consumer.KafkaConsumerServiceTest",
      "timestamp": "2020-07-26T21:54:44",
      "testcase": [
        {
          "name": "sets all offsets to start",
          "classname": "io.lenses.core.kafka.consumer.KafkaConsumerServiceTest",
          "time": 90,
          "failure": null,
          "error": null,
          "skipped": false
        },
        {
          "name": "sets all offsets to end",
          "classname": "io.lenses.core.kafka.consumer.KafkaConsumerServiceTest",
          "time": 3,
          "failure": null,
          "error": null,
          "skipped": false
        },
        {
          "name": "sets all offsets to particular timestamp",
          "classname": "io.lenses.core.kafka.consumer.KafkaConsumerServiceTest",
          "time": 11,
          "failure": null,
          "error": null,
          "skipped": false
        },
        {
          "name": "sets all offsets to particular timestamp, or end when passed timestamp exceeds all records",
          "classname": "io.lenses.core.kafka.consumer.KafkaConsumerServiceTest",
          "time": 11,
          "failure": null,
          "error": null,
          "skipped": false
        },
        {
          "name": "sets all offsets for to start (for subset of topics)",
          "classname": "io.lenses.core.kafka.consumer.KafkaConsumerServiceTest",
          "time": 10,
          "failure": null,
          "error": null,
          "skipped": false
        },
        {
          "name": "sets all offsets to end (for subset of topics)",
          "classname": "io.lenses.core.kafka.consumer.KafkaConsumerServiceTest",
          "time": 4,
          "failure": null,
          "error": null,
          "skipped": false
        },
        {
          "name": "sets all offsets to particular timestamp (for subset of topics)",
          "classname": "io.lenses.core.kafka.consumer.KafkaConsumerServiceTest",
          "time": 4,
          "failure": null,
          "error": null,
          "skipped": false
        },
        {
          "name": "sets a single offset to absolute value",
          "classname": "io.lenses.core.kafka.consumer.KafkaConsumerServiceTest",
          "time": 19,
          "failure": null,
          "error": null,
          "skipped": false
        },
        {
          "name": "sets a single offset to start",
          "classname": "io.lenses.core.kafka.consumer.KafkaConsumerServiceTest",
          "time": 5,
          "failure": null,
          "error": null,
          "skipped": false
        },
        {
          "name": "sets a single offset to end",
          "classname": "io.lenses.core.kafka.consumer.KafkaConsumerServiceTest",
          "time": 2,
          "failure": null,
          "error": null,
          "skipped": false
        },
        {
          "name": "fails to set offsets if group doesn't exist (state: Dead)",
          "classname": "io.lenses.core.kafka.consumer.KafkaConsumerServiceTest",
          "time": 21,
          "failure": null,
          "error": null,
          "skipped": false
        },
        {
          "name": "fails to set offsets if group doesn't exist (state: Unknown)",
          "classname": "io.lenses.core.kafka.consumer.KafkaConsumerServiceTest",
          "time": 8,
          "failure": null,
          "error": null,
          "skipped": false
        },
        {
          "name": "fails to set offsets if group doesn't exist (state: null)",
          "classname": "io.lenses.core.kafka.consumer.KafkaConsumerServiceTest",
          "time": 1,
          "failure": null,
          "error": null,
          "skipped": false
        },
        {
          "name": "fails to set offsets if group is active (state: CompletingRebalance)",
          "classname": "io.lenses.core.kafka.consumer.KafkaConsumerServiceTest",
          "time": 6,
          "failure": null,
          "error": null,
          "skipped": false
        },
        {
          "name": "fails to set offsets if group is active (state: PreparingRebalance)",
          "classname": "io.lenses.core.kafka.consumer.KafkaConsumerServiceTest",
          "time": 2,
          "failure": null,
          "error": null,
          "skipped": false
        },
        {
          "name": "fails to set offsets if group is active (state: Stable)",
          "classname": "io.lenses.core.kafka.consumer.KafkaConsumerServiceTest",
          "time": 1,
          "failure": null,
          "error": null,
          "skipped": false
        },
        {
          "name": "fails to set offsets if topic(s) not consumed by group",
          "classname": "io.lenses.core.kafka.consumer.KafkaConsumerServiceTest",
          "time": 5,
          "failure": null,
          "error": null,
          "skipped": false
        },
        {
          "name": "fails to set offsets if consumer group consumes no topics",
          "classname": "io.lenses.core.kafka.consumer.KafkaConsumerServiceTest",
          "time": 4,
          "failure": null,
          "error": null,
          "skipped": false
        },
        {
          "name": "fails to set offsets if offset retrieval fails",
          "classname": "io.lenses.core.kafka.consumer.KafkaConsumerServiceTest",
          "time": 8,
          "failure": null,
          "error": null,
          "skipped": false
        },
        {
          "name": "fails to set offset if topic partition is not found",
          "classname": "io.lenses.core.kafka.consumer.KafkaConsumerServiceTest",
          "time": 3,
          "failure": null,
          "error": null,
          "skipped": false
        },
        {
          "name": "fails to set offset if offset out of bounds",
          "classname": "io.lenses.core.kafka.consumer.KafkaConsumerServiceTest",
          "time": 5,
          "failure": null,
          "error": null,
          "skipped": false
        }
      ]
    },
    {
      "time": 750,
      "tests": 9,
      "failures": 0,
      "errors": 0,
      "skipped": 0,
      "name": "io.lenses.core.channels.publisher.pagerduty.PagerDutyClientTest",
      "timestamp": "2020-07-26T21:54:39",
      "testcase": [
        {
          "name": "PagerDutyClient should supplies the API token as a header",
          "classname": "io.lenses.core.channels.publisher.pagerduty.PagerDutyClientTest",
          "time": 581,
          "failure": null,
          "error": null,
          "skipped": false
        },
        {
          "name": "PagerDutyClient should supplies the form header",
          "classname": "io.lenses.core.channels.publisher.pagerduty.PagerDutyClientTest",
          "time": 6,
          "failure": null,
          "error": null,
          "skipped": false
        },
        {
          "name": "PagerDutyClient should raiseIncident should persist incidents in pager duty",
          "classname": "io.lenses.core.channels.publisher.pagerduty.PagerDutyClientTest",
          "time": 11,
          "failure": null,
          "error": null,
          "skipped": false
        },
        {
          "name": "PagerDutyClient should raiseIncident should gracefully handle the case where an incident has been already raised",
          "classname": "io.lenses.core.channels.publisher.pagerduty.PagerDutyClientTest",
          "time": 8,
          "failure": null,
          "error": null,
          "skipped": false
        },
        {
          "name": "PagerDutyClient should resolveIncident should set the incident status to resolved, gracefully handling the case where the incident has been already resolved",
          "classname": "io.lenses.core.channels.publisher.pagerduty.PagerDutyClientTest",
          "time": 40,
          "failure": null,
          "error": null,
          "skipped": false
        },
        {
          "name": "PagerDutyClient should allUnresolvedIncidents should returns an empty list if no data is present",
          "classname": "io.lenses.core.channels.publisher.pagerduty.PagerDutyClientTest",
          "time": 21,
          "failure": null,
          "error": null,
          "skipped": false
        },
        {
          "name": "PagerDutyClient should allUnresolvedIncidents should scan through multiple pages of results",
          "classname": "io.lenses.core.channels.publisher.pagerduty.PagerDutyClientTest",
          "time": 49,
          "failure": null,
          "error": null,
          "skipped": false
        },
        {
          "name": "PagerDutyClient should allUnresolvedIncidents should filter out all resolved incidents",
          "classname": "io.lenses.core.channels.publisher.pagerduty.PagerDutyClientTest",
          "time": 30,
          "failure": null,
          "error": null,
          "skipped": false
        },
        {
          "name": "PagerDutyClient should allUnresolvedIncidents should filter out results from other services",
          "classname": "io.lenses.core.channels.publisher.pagerduty.PagerDutyClientTest",
          "time": 4,
          "failure": null,
          "error": null,
          "skipped": false
        }
      ]
    },
    {
      "time": 1005,
      "tests": 1,
      "failures": 0,
      "errors": 0,
      "skipped": 0,
      "name": "io.lenses.core.audits.AuditLoggerTest",
      "timestamp": "2020-07-26T21:54:52",
      "testcase": [
        {
          "name": "AuditLogger should log audits to store and forward them to channels",
          "classname": "io.lenses.core.audits.AuditLoggerTest",
          "time": 1005,
          "failure": null,
          "error": null,
          "skipped": false
        }
      ]
    },
    {
      "time": 86,
      "tests": 11,
      "failures": 0,
      "errors": 0,
      "skipped": 0,
      "name": "io.lenses.core.migration.AlertRuleMigrationSpec",
      "timestamp": "2020-07-26T21:54:40",
      "testcase": [
        {
          "name": "AlertRuleMigration should toAlertRuleOp should succeed for fixed rule update",
          "classname": "io.lenses.core.migration.AlertRuleMigrationSpec",
          "time": 60,
          "failure": null,
          "error": null,
          "skipped": false
        },
        {
          "name": "AlertRuleMigration should toAlertRuleOp should succeed for condition add",
          "classname": "io.lenses.core.migration.AlertRuleMigrationSpec",
          "time": 16,
          "failure": null,
          "error": null,
          "skipped": false
        },
        {
          "name": "AlertRuleMigration should toAlertRuleOp should succeed for condition delete",
          "classname": "io.lenses.core.migration.AlertRuleMigrationSpec",
          "time": 1,
          "failure": null,
          "error": null,
          "skipped": false
        },
        {
          "name": "AlertRuleMigration should toAlertRuleOp should fail gracefully for null key",
          "classname": "io.lenses.core.migration.AlertRuleMigrationSpec",
          "time": 5,
          "failure": null,
          "error": null,
          "skipped": false
        },
        {
          "name": "AlertRuleMigration should toAlertRuleOp should fail for invalid key",
          "classname": "io.lenses.core.migration.AlertRuleMigrationSpec",
          "time": 1,
          "failure": null,
          "error": null,
          "skipped": false
        },
        {
          "name": "AlertRuleMigration should toAlertRuleOp should fail for fixed rule update of conditional rule",
          "classname": "io.lenses.core.migration.AlertRuleMigrationSpec",
          "time": 1,
          "failure": null,
          "error": null,
          "skipped": false
        },
        {
          "name": "AlertRuleMigration should toAlertRuleOp should fail for fixed rule update with no value",
          "classname": "io.lenses.core.migration.AlertRuleMigrationSpec",
          "time": 0,
          "failure": null,
          "error": null,
          "skipped": false
        },
        {
          "name": "AlertRuleMigration should toAlertRuleOp should fail for invalid fixed rule update value",
          "classname": "io.lenses.core.migration.AlertRuleMigrationSpec",
          "time": 1,
          "failure": null,
          "error": null,
          "skipped": false
        },
        {
          "name": "AlertRuleMigration should toAlertRuleOp should fail for conditional rule update of fixed rule",
          "classname": "io.lenses.core.migration.AlertRuleMigrationSpec",
          "time": 0,
          "failure": null,
          "error": null,
          "skipped": false
        },
        {
          "name": "AlertRuleMigration should toAlertRuleOp should fail for invalid condition ID",
          "classname": "io.lenses.core.migration.AlertRuleMigrationSpec",
          "time": 0,
          "failure": null,
          "error": null,
          "skipped": false
        },
        {
          "name": "AlertRuleMigration should toAlertRuleOp should fail for invalid condition DSL",
          "classname": "io.lenses.core.migration.AlertRuleMigrationSpec",
          "time": 1,
          "failure": null,
          "error": null,
          "skipped": false
        }
      ]
    },
    {
      "time": 1,
      "tests": 3,
      "failures": 0,
      "errors": 0,
      "skipped": 0,
      "name": "io.lenses.core.monitoring.actions.RaiseActiveControllersFnTest",
      "timestamp": "2020-07-26T21:54:53",
      "testcase": [
        {
          "name": "RaiseActiveControllersFn should raise an alert when active controllers is < 1",
          "classname": "io.lenses.core.monitoring.actions.RaiseActiveControllersFnTest",
          "time": 0,
          "failure": null,
          "error": null,
          "skipped": false
        },
        {
          "name": "RaiseActiveControllersFn should raise an alert when active controllers is > 1",
          "classname": "io.lenses.core.monitoring.actions.RaiseActiveControllersFnTest",
          "time": 1,
          "failure": null,
          "error": null,
          "skipped": false
        },
        {
          "name": "RaiseActiveControllersFn should raise an INFO alert when active controllers is = 1",
          "classname": "io.lenses.core.monitoring.actions.RaiseActiveControllersFnTest",
          "time": 0,
          "failure": null,
          "error": null,
          "skipped": false
        }
      ]
    },
    {
      "time": 617,
      "tests": 4,
      "failures": 0,
      "errors": 0,
      "skipped": 0,
      "name": "io.lenses.core.actors.ZookeeperDataAggregatorActorSpec",
      "timestamp": "2020-07-26T21:54:50",
      "testcase": [
        {
          "name": "ZookeeperDataAggregatorActor should send Zookeeper node status to ServicesActor on startup",
          "classname": "io.lenses.core.actors.ZookeeperDataAggregatorActorSpec",
          "time": 90,
          "failure": null,
          "error": null,
          "skipped": false
        },
        {
          "name": "LinkToOutputActor should send status of zookeeper(s) to subscribers",
          "classname": "io.lenses.core.actors.ZookeeperDataAggregatorActorSpec",
          "time": 90,
          "failure": null,
          "error": null,
          "skipped": false
        },
        {
          "name": "GetZookeeperMetricsResponse should only update with metrics if node is active",
          "classname": "io.lenses.core.actors.ZookeeperDataAggregatorActorSpec",
          "time": 334,
          "failure": null,
          "error": null,
          "skipped": false
        },
        {
          "name": "UpdateActivityStatus should set jmx to None if node is not active",
          "classname": "io.lenses.core.actors.ZookeeperDataAggregatorActorSpec",
          "time": 103,
          "failure": null,
          "error": null,
          "skipped": false
        }
      ]
    },
    {
      "time": 109,
      "tests": 2,
      "failures": 0,
      "errors": 0,
      "skipped": 0,
      "name": "io.lenses.core.audits.BackgroundAuditLoggerTest",
      "timestamp": "2020-07-26T21:54:49",
      "testcase": [
        {
          "name": "BackgroundAuditLogger should log audits in background",
          "classname": "io.lenses.core.audits.BackgroundAuditLoggerTest",
          "time": 58,
          "failure": null,
          "error": null,
          "skipped": false
        },
        {
          "name": "BackgroundAuditLogger should cancel if timeout exceeded",
          "classname": "io.lenses.core.audits.BackgroundAuditLoggerTest",
          "time": 51,
          "failure": null,
          "error": null,
          "skipped": false
        }
      ]
    },
    {
      "time": 4,
      "tests": 3,
      "failures": 0,
      "errors": 0,
      "skipped": 0,
      "name": "io.lenses.core.monitoring.actions.RaiseFailedProduceRequestsPerSecAlertsFnTest",
      "timestamp": "2020-07-26T21:54:53",
      "testcase": [
        {
          "name": "1",
          "classname": "io.lenses.core.monitoring.actions.RaiseFailedProduceRequestsPerSecAlertsFnTest",
          "time": 1,
          "failure": null,
          "error": null,
          "skipped": false
        },
        {
          "name": "RaiseFailedProduceRequestPerSecAlertsFn should raise a MEDIUM level alert when failed produce request percentage > 0",
          "classname": "io.lenses.core.monitoring.actions.RaiseFailedProduceRequestsPerSecAlertsFnTest",
          "time": 0,
          "failure": null,
          "error": null,
          "skipped": false
        },
        {
          "name": "RaiseFailedProduceRequestPerSecAlertsFn should raise an INFO alert when the failed produce request is back to 0 on brokers",
          "classname": "io.lenses.core.monitoring.actions.RaiseFailedProduceRequestsPerSecAlertsFnTest",
          "time": 3,
          "failure": null,
          "error": null,
          "skipped": false
        }
      ]
    },
    {
      "time": 120086,
      "tests": 6,
      "failures": 1,
      "errors": 0,
      "skipped": 0,
      "name": "io.lenses.core.lsql.JdbcRoutesControllerInsertStatementTest",
      "timestamp": "2020-07-26T21:54:39",
      "testcase": [
        {
          "name": "handlePrepareStatementData should return partition and offset info",
          "classname": "io.lenses.core.lsql.JdbcRoutesControllerInsertStatementTest",
          "time": 120068,
          "failure": {
            "message": "Topic myTopic not present in metadata after 60000 ms.",
            "type": "org.apache.kafka.common.errors.TimeoutException",
            "stackTrace": "org.apache.kafka.common.errors.TimeoutException: Topic myTopic not present in metadata after 60000 ms."
          },
          "error": null,
          "skipped": false
        },
        {
          "name": "handlePrepareStatementData should fail to insert data when metadata keyType is set to BYTES",
          "classname": "io.lenses.core.lsql.JdbcRoutesControllerInsertStatementTest",
          "time": 14,
          "failure": null,
          "error": null,
          "skipped": false
        },
        {
          "name": "handlePrepareStatementData should fail to insert data when metadata valueType is set to BYTES",
          "classname": "io.lenses.core.lsql.JdbcRoutesControllerInsertStatementTest",
          "time": 1,
          "failure": null,
          "error": null,
          "skipped": false
        },
        {
          "name": "handlePrepareStatementData should fail to insert data when metadata key type is not set",
          "classname": "io.lenses.core.lsql.JdbcRoutesControllerInsertStatementTest",
          "time": 0,
          "failure": null,
          "error": null,
          "skipped": false
        },
        {
          "name": "handlePrepareStatementData should fail to insert data when metadata value type is not set",
          "classname": "io.lenses.core.lsql.JdbcRoutesControllerInsertStatementTest",
          "time": 1,
          "failure": null,
          "error": null,
          "skipped": false
        },
        {
          "name": "handlePrepareStatementData should fail to insert data when neither metadata value type not key type is set",
          "classname": "io.lenses.core.lsql.JdbcRoutesControllerInsertStatementTest",
          "time": 2,
          "failure": null,
          "error": null,
          "skipped": false
        }
      ]
    },
    {
      "time": 10612,
      "tests": 12,
      "failures": 0,
      "errors": 0,
      "skipped": 0,
      "name": "io.lenses.core.actors.DashboardActorSpec",
      "timestamp": "2020-07-26T21:54:40",
      "testcase": [
        {
          "name": "RefreshTelemetryData should update UserLoginsTelemetry",
          "classname": "io.lenses.core.actors.DashboardActorSpec",
          "time": 241,
          "failure": null,
          "error": null,
          "skipped": false
        },
        {
          "name": "RefreshTelemetryData should update connections telemetry",
          "classname": "io.lenses.core.actors.DashboardActorSpec",
          "time": 167,
          "failure": null,
          "error": null,
          "skipped": false
        },
        {
          "name": "RefreshTelemetryData should update alerts telemetry",
          "classname": "io.lenses.core.actors.DashboardActorSpec",
          "time": 366,
          "failure": null,
          "error": null,
          "skipped": false
        },
        {
          "name": "RefreshTelemetryData should update audits telemetry",
          "classname": "io.lenses.core.actors.DashboardActorSpec",
          "time": 255,
          "failure": null,
          "error": null,
          "skipped": false
        },
        {
          "name": "RefreshTelemetryData should update external apps telemetry",
          "classname": "io.lenses.core.actors.DashboardActorSpec",
          "time": 147,
          "failure": null,
          "error": null,
          "skipped": false
        },
        {
          "name": "Audit should update audits list unless AuditResource is of type USER",
          "classname": "io.lenses.core.actors.DashboardActorSpec",
          "time": 483,
          "failure": null,
          "error": null,
          "skipped": false
        },
        {
          "name": "LinkActor and PublishUpdates should send data to subscriber, including audits if user has permission to view them",
          "classname": "io.lenses.core.actors.DashboardActorSpec",
          "time": 237,
          "failure": null,
          "error": null,
          "skipped": false
        },
        {
          "name": "LinkActor and PublishUpdates should send data to subscriber, excluding audits if user does not have permission to view them",
          "classname": "io.lenses.core.actors.DashboardActorSpec",
          "time": 143,
          "failure": null,
          "error": null,
          "skipped": false
        },
        {
          "name": "OnDashboardControllersData should raise a controller alert if the number of controllers drops down to zero",
          "classname": "io.lenses.core.actors.DashboardActorSpec",
          "time": 2112,
          "failure": null,
          "error": null,
          "skipped": false
        },
        {
          "name": "OnDashboardControllersData should not raise a controller alert if active controllers are back to normal after second check",
          "classname": "io.lenses.core.actors.DashboardActorSpec",
          "time": 2171,
          "failure": null,
          "error": null,
          "skipped": false
        },
        {
          "name": "OnDashboardControllersData should raise an offline partitions alert if there are some offline partitions",
          "classname": "io.lenses.core.actors.DashboardActorSpec",
          "time": 2164,
          "failure": null,
          "error": null,
          "skipped": false
        },
        {
          "name": "OnDashboardControllersData should not raise an offline partitions alert if offline partitions are back to normal after second check",
          "classname": "io.lenses.core.actors.DashboardActorSpec",
          "time": 2124,
          "failure": null,
          "error": null,
          "skipped": false
        }
      ]
    },
    {
      "time": 2,
      "tests": 6,
      "failures": 0,
      "errors": 0,
      "skipped": 0,
      "name": "io.lenses.core.utils.ExtractHostFromEndpointTest",
      "timestamp": "2020-07-26T21:54:41",
      "testcase": [
        {
          "name": "ExtractHostFromEndpoint should extract PLAINTEXT://miles:9092",
          "classname": "io.lenses.core.utils.ExtractHostFromEndpointTest",
          "time": 1,
          "failure": null,
          "error": null,
          "skipped": false
        },
        {
          "name": "30:9092",
          "classname": "io.lenses.core.utils.ExtractHostFromEndpointTest",
          "time": 0,
          "failure": null,
          "error": null,
          "skipped": false
        },
        {
          "name": "com:19092",
          "classname": "io.lenses.core.utils.ExtractHostFromEndpointTest",
          "time": 1,
          "failure": null,
          "error": null,
          "skipped": false
        },
        {
          "name": "com:19093",
          "classname": "io.lenses.core.utils.ExtractHostFromEndpointTest",
          "time": 0,
          "failure": null,
          "error": null,
          "skipped": false
        },
        {
          "name": "com:19094",
          "classname": "io.lenses.core.utils.ExtractHostFromEndpointTest",
          "time": 0,
          "failure": null,
          "error": null,
          "skipped": false
        },
        {
          "name": "com:19096",
          "classname": "io.lenses.core.utils.ExtractHostFromEndpointTest",
          "time": 0,
          "failure": null,
          "error": null,
          "skipped": false
        }
      ]
    },
    {
      "time": 69,
      "tests": 4,
      "failures": 0,
      "errors": 0,
      "skipped": 0,
      "name": "io.lenses.core.monitoring.actions.RaiseBrokerAlertsFnTest",
      "timestamp": "2020-07-26T21:54:37",
      "testcase": [
        {
          "name": "RaiseBrokersAlertsFn should raise an alert when the broker is down",
          "classname": "io.lenses.core.monitoring.actions.RaiseBrokerAlertsFnTest",
          "time": 64,
          "failure": null,
          "error": null,
          "skipped": false
        },
        {
          "name": "RaiseBrokersAlertsFn should not raise the alert twice",
          "classname": "io.lenses.core.monitoring.actions.RaiseBrokerAlertsFnTest",
          "time": 2,
          "failure": null,
          "error": null,
          "skipped": false
        },
        {
          "name": "RaiseBrokersAlertsFn should raise an alert when the broker is back online",
          "classname": "io.lenses.core.monitoring.actions.RaiseBrokerAlertsFnTest",
          "time": 1,
          "failure": null,
          "error": null,
          "skipped": false
        },
        {
          "name": "RaiseBrokersAlertsFn should raise an alert when one broker is down and the other one is back up",
          "classname": "io.lenses.core.monitoring.actions.RaiseBrokerAlertsFnTest",
          "time": 1,
          "failure": null,
          "error": null,
          "skipped": false
        }
      ]
    },
    {
      "time": 255755,
      "tests": 5,
      "failures": 4,
      "errors": 0,
      "skipped": 0,
      "name": "io.lenses.core.kafka.admin.KafkaAdminClientImplSpec",
      "timestamp": "2020-07-26T21:54:37",
      "testcase": [
        {
          "name": "describeCluster should returns the Kafka cluster description",
          "classname": "io.lenses.core.kafka.admin.KafkaAdminClientImplSpec",
          "time": 5728,
          "failure": {
            "message": "Timed out waiting for a node assignment.",
            "type": "org.apache.kafka.common.errors.TimeoutException",
            "stackTrace": "org.apache.kafka.common.errors.TimeoutException: Timed out waiting for a node assignment."
          },
          "error": null,
          "skipped": false
        },
        {
          "name": "describeLogDirs should returns logDir info by broker id",
          "classname": "io.lenses.core.kafka.admin.KafkaAdminClientImplSpec",
          "time": 5014,
          "failure": {
            "message": "Set() was not equal to Set(0)",
            "type": "org.scalatest.exceptions.TestFailedException",
            "stackTrace": "org.scalatest.exceptions.TestFailedException: Set() was not equal to Set(0)\n\tat org.scalatest.matchers.MatchersHelper$.indicateFailure(MatchersHelper.scala:339)\n\tat org.scalatest.matchers.should.Matchers$AnyShouldWrapper.shouldBe(Matchers.scala:6982)\n\tat io.lenses.core.kafka.admin.KafkaAdminClientImplSpec.$anonfun$new$8(KafkaAdminClientImplSpec.scala:34)\n\tat cats.effect.IO$Map.apply(IO.scala:1504)\n\tat cats.effect.IO$Map.apply(IO.scala:1502)\n\tat cats.effect.internals.IORunLoop$.cats$effect$internals$IORunLoop$$loop(IORunLoop.scala:142)\n\tat cats.effect.internals.IORunLoop$RestartCallback.signal(IORunLoop.scala:361)\n\tat cats.effect.internals.IORunLoop$RestartCallback.apply(IORunLoop.scala:380)\n\tat cats.effect.internals.IORunLoop$RestartCallback.apply(IORunLoop.scala:323)\n\tat cats.effect.internals.Callback$AsyncIdempotentCallback.run(Callback.scala:130)\n\tat cats.effect.internals.Trampoline.cats$effect$internals$Trampoline$$immediateLoop(Trampoline.scala:67)\n\tat cats.effect.internals.Trampoline.startLoop(Trampoline.scala:35)\n\tat cats.effect.internals.TrampolineEC$JVMTrampoline.super$startLoop(TrampolineEC.scala:89)\n\tat cats.effect.internals.TrampolineEC$JVMTrampoline.$anonfun$startLoop$1(TrampolineEC.scala:89)\n\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n\tat cats.effect.internals.TrampolineEC$JVMTrampoline.startLoop(TrampolineEC.scala:89)\n\tat cats.effect.internals.Trampoline.execute(Trampoline.scala:43)\n\tat cats.effect.internals.TrampolineEC.execute(TrampolineEC.scala:42)\n\tat cats.effect.internals.Callback$AsyncIdempotentCallback.apply(Callback.scala:136)\n\tat cats.effect.internals.Callback$AsyncIdempotentCallback.apply(Callback.scala:125)\n\tat io.lenses.core.kafka.admin.KafkaAdminClientImpl.$anonfun$describeLogDirs$8(KafkaAdminClientImpl.scala:145)\n\tat io.lenses.core.kafka.admin.KafkaAdminClientImpl.$anonfun$describeLogDirs$8$adapted(KafkaAdminClientImpl.scala:145)\n\tat io.lenses.core.kafka.KafkaFutureOps$Wrapper.$anonfun$asyncComplete$1(KafkaFutureOps.scala:14)\n\tat org.apache.kafka.common.internals.KafkaFutureImpl$WhenCompleteBiConsumer.accept(KafkaFutureImpl.java:175)\n\tat org.apache.kafka.common.internals.KafkaFutureImpl$WhenCompleteBiConsumer.accept(KafkaFutureImpl.java:162)\n\tat org.apache.kafka.common.internals.KafkaFutureImpl.completeExceptionally(KafkaFutureImpl.java:238)\n\tat org.apache.kafka.clients.admin.KafkaAdminClient.completeAllExceptionally(KafkaAdminClient.java:287)\n\tat org.apache.kafka.clients.admin.KafkaAdminClient.access$2300(KafkaAdminClient.java:181)\n\tat org.apache.kafka.clients.admin.KafkaAdminClient$14.handleFailure(KafkaAdminClient.java:2134)\n\tat org.apache.kafka.clients.admin.KafkaAdminClient$Call.fail(KafkaAdminClient.java:641)\n\tat org.apache.kafka.clients.admin.KafkaAdminClient$TimeoutProcessor.handleTimeouts(KafkaAdminClient.java:757)\n\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.timeoutPendingCalls(KafkaAdminClient.java:825)\n\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.run(KafkaAdminClient.java:1119)\n\tat java.lang.Thread.run(Thread.java:748)"
          },
          "error": null,
          "skipped": false
        },
        {
          "name": "describeLogDirs should omits the log dir info when a broker lookup fails",
          "classname": "io.lenses.core.kafka.admin.KafkaAdminClientImplSpec",
          "time": 5004,
          "failure": {
            "message": "Set() was not equal to Set(0)",
            "type": "org.scalatest.exceptions.TestFailedException",
            "stackTrace": "org.scalatest.exceptions.TestFailedException: Set() was not equal to Set(0)\n\tat org.scalatest.matchers.MatchersHelper$.indicateFailure(MatchersHelper.scala:339)\n\tat org.scalatest.matchers.should.Matchers$AnyShouldWrapper.shouldBe(Matchers.scala:6982)\n\tat io.lenses.core.kafka.admin.KafkaAdminClientImplSpec.$anonfun$new$11(KafkaAdminClientImplSpec.scala:41)\n\tat cats.effect.IO$Map.apply(IO.scala:1504)\n\tat cats.effect.IO$Map.apply(IO.scala:1502)\n\tat cats.effect.internals.IORunLoop$.cats$effect$internals$IORunLoop$$loop(IORunLoop.scala:142)\n\tat cats.effect.internals.IORunLoop$RestartCallback.signal(IORunLoop.scala:361)\n\tat cats.effect.internals.IORunLoop$RestartCallback.apply(IORunLoop.scala:380)\n\tat cats.effect.internals.IORunLoop$RestartCallback.apply(IORunLoop.scala:323)\n\tat cats.effect.internals.Callback$AsyncIdempotentCallback.run(Callback.scala:130)\n\tat cats.effect.internals.Trampoline.cats$effect$internals$Trampoline$$immediateLoop(Trampoline.scala:67)\n\tat cats.effect.internals.Trampoline.startLoop(Trampoline.scala:35)\n\tat cats.effect.internals.TrampolineEC$JVMTrampoline.super$startLoop(TrampolineEC.scala:89)\n\tat cats.effect.internals.TrampolineEC$JVMTrampoline.$anonfun$startLoop$1(TrampolineEC.scala:89)\n\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n\tat cats.effect.internals.TrampolineEC$JVMTrampoline.startLoop(TrampolineEC.scala:89)\n\tat cats.effect.internals.Trampoline.execute(Trampoline.scala:43)\n\tat cats.effect.internals.TrampolineEC.execute(TrampolineEC.scala:42)\n\tat cats.effect.internals.Callback$AsyncIdempotentCallback.apply(Callback.scala:136)\n\tat cats.effect.internals.Callback$AsyncIdempotentCallback.apply(Callback.scala:125)\n\tat io.lenses.core.kafka.admin.KafkaAdminClientImpl.$anonfun$describeLogDirs$8(KafkaAdminClientImpl.scala:145)\n\tat io.lenses.core.kafka.admin.KafkaAdminClientImpl.$anonfun$describeLogDirs$8$adapted(KafkaAdminClientImpl.scala:145)\n\tat io.lenses.core.kafka.KafkaFutureOps$Wrapper.$anonfun$asyncComplete$1(KafkaFutureOps.scala:14)\n\tat org.apache.kafka.common.internals.KafkaFutureImpl$WhenCompleteBiConsumer.accept(KafkaFutureImpl.java:175)\n\tat org.apache.kafka.common.internals.KafkaFutureImpl$WhenCompleteBiConsumer.accept(KafkaFutureImpl.java:162)\n\tat org.apache.kafka.common.internals.KafkaFutureImpl.completeExceptionally(KafkaFutureImpl.java:238)\n\tat org.apache.kafka.clients.admin.KafkaAdminClient.completeAllExceptionally(KafkaAdminClient.java:287)\n\tat org.apache.kafka.clients.admin.KafkaAdminClient.access$2300(KafkaAdminClient.java:181)\n\tat org.apache.kafka.clients.admin.KafkaAdminClient$14.handleFailure(KafkaAdminClient.java:2134)\n\tat org.apache.kafka.clients.admin.KafkaAdminClient$Call.fail(KafkaAdminClient.java:641)\n\tat org.apache.kafka.clients.admin.KafkaAdminClient$TimeoutProcessor.handleTimeouts(KafkaAdminClient.java:757)\n\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.timeoutPendingCalls(KafkaAdminClient.java:825)\n\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.run(KafkaAdminClient.java:1119)\n\tat java.lang.Thread.run(Thread.java:748)"
          },
          "error": null,
          "skipped": false
        },
        {
          "name": "describeTopics should return no keys for non-existing topic",
          "classname": "io.lenses.core.kafka.admin.KafkaAdminClientImplSpec",
          "time": 120003,
          "failure": null,
          "error": null,
          "skipped": false
        },
        {
          "name": "describeTopics should return a key for an existing topic",
          "classname": "io.lenses.core.kafka.admin.KafkaAdminClientImplSpec",
          "time": 120005,
          "failure": {
            "message": "false did not equal true",
            "type": "org.scalatest.exceptions.TestFailedException",
            "stackTrace": "org.scalatest.exceptions.TestFailedException: false did not equal true\n\tat org.scalatest.matchers.MatchersHelper$.indicateFailure(MatchersHelper.scala:344)\n\tat org.scalatest.matchers.should.Matchers$AnyShouldWrapper.shouldEqual(Matchers.scala:6860)\n\tat io.lenses.core.kafka.admin.KafkaAdminClientImplSpec.$anonfun$new$18(KafkaAdminClientImplSpec.scala:56)\n\tat scala.Function1.$anonfun$andThen$1(Function1.scala:57)\n\tat cats.effect.IO$Map.apply(IO.scala:1504)\n\tat cats.effect.IO$Map.apply(IO.scala:1502)\n\tat cats.effect.internals.IORunLoop$.cats$effect$internals$IORunLoop$$loop(IORunLoop.scala:142)\n\tat cats.effect.internals.IORunLoop$RestartCallback.signal(IORunLoop.scala:361)\n\tat cats.effect.internals.IORunLoop$RestartCallback.apply(IORunLoop.scala:380)\n\tat cats.effect.internals.IORunLoop$RestartCallback.apply(IORunLoop.scala:323)\n\tat cats.effect.internals.Callback$AsyncIdempotentCallback.run(Callback.scala:130)\n\tat cats.effect.internals.Trampoline.cats$effect$internals$Trampoline$$immediateLoop(Trampoline.scala:67)\n\tat cats.effect.internals.Trampoline.startLoop(Trampoline.scala:35)\n\tat cats.effect.internals.TrampolineEC$JVMTrampoline.super$startLoop(TrampolineEC.scala:89)\n\tat cats.effect.internals.TrampolineEC$JVMTrampoline.$anonfun$startLoop$1(TrampolineEC.scala:89)\n\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n\tat cats.effect.internals.TrampolineEC$JVMTrampoline.startLoop(TrampolineEC.scala:89)\n\tat cats.effect.internals.Trampoline.execute(Trampoline.scala:43)\n\tat cats.effect.internals.TrampolineEC.execute(TrampolineEC.scala:42)\n\tat cats.effect.internals.Callback$AsyncIdempotentCallback.apply(Callback.scala:136)\n\tat cats.effect.internals.Callback$AsyncIdempotentCallback.apply(Callback.scala:125)\n\tat io.lenses.core.kafka.admin.KafkaAdminClientImpl.$anonfun$describeTopics$3(KafkaAdminClientImpl.scala:114)\n\tat io.lenses.core.kafka.admin.KafkaAdminClientImpl.$anonfun$describeTopics$3$adapted(KafkaAdminClientImpl.scala:114)\n\tat io.lenses.core.kafka.KafkaFutureOps$Wrapper.$anonfun$asyncComplete$1(KafkaFutureOps.scala:14)\n\tat org.apache.kafka.common.internals.KafkaFutureImpl$WhenCompleteBiConsumer.accept(KafkaFutureImpl.java:175)\n\tat org.apache.kafka.common.internals.KafkaFutureImpl$WhenCompleteBiConsumer.accept(KafkaFutureImpl.java:162)\n\tat org.apache.kafka.common.internals.KafkaFutureImpl.completeExceptionally(KafkaFutureImpl.java:238)\n\tat org.apache.kafka.clients.admin.KafkaAdminClient.completeAllExceptionally(KafkaAdminClient.java:287)\n\tat org.apache.kafka.clients.admin.KafkaAdminClient.access$2300(KafkaAdminClient.java:181)\n\tat org.apache.kafka.clients.admin.KafkaAdminClient$4.handleFailure(KafkaAdminClient.java:1545)\n\tat org.apache.kafka.clients.admin.KafkaAdminClient$Call.fail(KafkaAdminClient.java:641)\n\tat org.apache.kafka.clients.admin.KafkaAdminClient$TimeoutProcessor.handleTimeouts(KafkaAdminClient.java:757)\n\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.timeoutPendingCalls(KafkaAdminClient.java:825)\n\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.run(KafkaAdminClient.java:1119)\n\tat java.lang.Thread.run(Thread.java:748)"
          },
          "error": null,
          "skipped": false
        }
      ]
    },
    {
      "time": 6899,
      "tests": 3,
      "failures": 0,
      "errors": 0,
      "skipped": 0,
      "name": "io.lenses.core.actors.BrokerDataAggregatorActorTest2",
      "timestamp": "2020-07-26T21:54:46",
      "testcase": [
        {
          "name": "BrokerDataAggregatorActor should raise a cpu alert for brokers in",
          "classname": "io.lenses.core.actors.BrokerDataAggregatorActorTest2",
          "time": 2323,
          "failure": null,
          "error": null,
          "skipped": false
        },
        {
          "name": "BrokerDataAggregatorActor should raise a failedFetchRequestPerSec alert for brokers in",
          "classname": "io.lenses.core.actors.BrokerDataAggregatorActorTest2",
          "time": 2292,
          "failure": null,
          "error": null,
          "skipped": false
        },
        {
          "name": "BrokerDataAggregatorActor should raise a failedProduceRequest alert for brokers in",
          "classname": "io.lenses.core.actors.BrokerDataAggregatorActorTest2",
          "time": 2283,
          "failure": null,
          "error": null,
          "skipped": false
        }
      ]
    },
    {
      "time": 998,
      "tests": 4,
      "failures": 0,
      "errors": 0,
      "skipped": 0,
      "name": "io.lenses.core.license.LicenseManagerImplTest",
      "timestamp": "2020-07-26T21:54:37",
      "testcase": [
        {
          "name": "updates the license is respected",
          "classname": "io.lenses.core.license.LicenseManagerImplTest",
          "time": 655,
          "failure": null,
          "error": null,
          "skipped": false
        },
        {
          "name": "fails if the store function files",
          "classname": "io.lenses.core.license.LicenseManagerImplTest",
          "time": 326,
          "failure": null,
          "error": null,
          "skipped": false
        },
        {
          "name": "fails if the license is not valid",
          "classname": "io.lenses.core.license.LicenseManagerImplTest",
          "time": 9,
          "failure": null,
          "error": null,
          "skipped": false
        },
        {
          "name": "updates the license",
          "classname": "io.lenses.core.license.LicenseManagerImplTest",
          "time": 8,
          "failure": null,
          "error": null,
          "skipped": false
        }
      ]
    },
    {
      "time": 7,
      "tests": 4,
      "failures": 0,
      "errors": 0,
      "skipped": 0,
      "name": "io.lenses.core.monitoring.actions.RaiseConnectWorkerAlertsFnTest",
      "timestamp": "2020-07-26T21:54:46",
      "testcase": [
        {
          "name": "RaiseConnectWorkersAlertsFn should raise an alert when a connect worker is down",
          "classname": "io.lenses.core.monitoring.actions.RaiseConnectWorkerAlertsFnTest",
          "time": 4,
          "failure": null,
          "error": null,
          "skipped": false
        },
        {
          "name": "RaiseConnectWorkersAlertsFn should not raise the alert twice",
          "classname": "io.lenses.core.monitoring.actions.RaiseConnectWorkerAlertsFnTest",
          "time": 1,
          "failure": null,
          "error": null,
          "skipped": false
        },
        {
          "name": "RaiseConnectWorkersAlertsFn should raise an alert when a connect worker is online",
          "classname": "io.lenses.core.monitoring.actions.RaiseConnectWorkerAlertsFnTest",
          "time": 1,
          "failure": null,
          "error": null,
          "skipped": false
        },
        {
          "name": "RaiseConnectWorkersAlertsFn should raise an alert when a connect worker is down and one worker is back online",
          "classname": "io.lenses.core.monitoring.actions.RaiseConnectWorkerAlertsFnTest",
          "time": 1,
          "failure": null,
          "error": null,
          "skipped": false
        }
      ]
    },
    {
      "time": 8,
      "tests": 2,
      "failures": 0,
      "errors": 0,
      "skipped": 0,
      "name": "io.lenses.core.monitoring.actions.RaiseConsumerLagFnTest",
      "timestamp": "2020-07-26T21:54:50",
      "testcase": [
        {
          "name": "RaiseConsumerLagFn should raise alert on consumer lag exceeded",
          "classname": "io.lenses.core.monitoring.actions.RaiseConsumerLagFnTest",
          "time": 7,
          "failure": null,
          "error": null,
          "skipped": false
        },
        {
          "name": "RaiseConsumerLagFn should raise one alert per group",
          "classname": "io.lenses.core.monitoring.actions.RaiseConsumerLagFnTest",
          "time": 1,
          "failure": null,
          "error": null,
          "skipped": false
        }
      ]
    },
    {
      "time": 670279,
      "tests": 1,
      "failures": 1,
      "errors": 0,
      "skipped": 0,
      "name": "io.lenses.core.migration.AuditMigrationIntegrationTest",
      "timestamp": "2020-07-26T21:54:37",
      "testcase": [
        {
          "name": "migrate audits to AuditStore",
          "classname": "io.lenses.core.migration.AuditMigrationIntegrationTest",
          "time": 670279,
          "failure": {
            "message": "java.lang.InterruptedException",
            "type": "org.apache.kafka.common.errors.InterruptException",
            "stackTrace": "org.apache.kafka.common.errors.InterruptException: java.lang.InterruptedException\n\tat org.apache.kafka.clients.producer.KafkaProducer.doSend(KafkaProducer.java:937)\n\tat org.apache.kafka.clients.producer.KafkaProducer.send(KafkaProducer.java:856)\n\tat org.apache.kafka.clients.producer.KafkaProducer.send(KafkaProducer.java:743)\n\tat io.lenses.core.migration.AuditMigrationIntegrationTest.$anonfun$new$2(AuditMigrationIntegrationTest.scala:67)\n\tat scala.collection.immutable.Stream.foreach(Stream.scala:533)\n\tat io.lenses.core.migration.AuditMigrationIntegrationTest.$anonfun$new$1(AuditMigrationIntegrationTest.scala:60)\n\tat org.scalatest.OutcomeOf.outcomeOf(OutcomeOf.scala:85)\n\tat org.scalatest.OutcomeOf.outcomeOf$(OutcomeOf.scala:83)\n\tat org.scalatest.OutcomeOf$.outcomeOf(OutcomeOf.scala:104)\n\tat org.scalatest.Transformer.apply(Transformer.scala:22)\n\tat org.scalatest.Transformer.apply(Transformer.scala:20)\n\tat org.scalatest.funsuite.AnyFunSuiteLike$$anon$1.apply(AnyFunSuiteLike.scala:189)\n\tat org.scalatest.TestSuite.withFixture(TestSuite.scala:196)\n\tat org.scalatest.TestSuite.withFixture$(TestSuite.scala:195)\n\tat org.scalatest.funsuite.AnyFunSuite.withFixture(AnyFunSuite.scala:1562)\n\tat org.scalatest.funsuite.AnyFunSuiteLike.invokeWithFixture$1(AnyFunSuiteLike.scala:187)\n\tat org.scalatest.funsuite.AnyFunSuiteLike.$anonfun$runTest$1(AnyFunSuiteLike.scala:199)\n\tat org.scalatest.SuperEngine.runTestImpl(Engine.scala:306)\n\tat org.scalatest.funsuite.AnyFunSuiteLike.runTest(AnyFunSuiteLike.scala:199)\n\tat org.scalatest.funsuite.AnyFunSuiteLike.runTest$(AnyFunSuiteLike.scala:181)\n\tat org.scalatest.funsuite.AnyFunSuite.runTest(AnyFunSuite.scala:1562)\n\tat org.scalatest.funsuite.AnyFunSuiteLike.$anonfun$runTests$1(AnyFunSuiteLike.scala:232)\n\tat org.scalatest.SuperEngine.$anonfun$runTestsInBranch$1(Engine.scala:413)\n\tat scala.collection.immutable.List.foreach(List.scala:392)\n\tat org.scalatest.SuperEngine.traverseSubNodes$1(Engine.scala:401)\n\tat org.scalatest.SuperEngine.runTestsInBranch(Engine.scala:396)\n\tat org.scalatest.SuperEngine.runTestsImpl(Engine.scala:475)\n\tat org.scalatest.funsuite.AnyFunSuiteLike.runTests(AnyFunSuiteLike.scala:232)\n\tat org.scalatest.funsuite.AnyFunSuiteLike.runTests$(AnyFunSuiteLike.scala:231)\n\tat org.scalatest.funsuite.AnyFunSuite.runTests(AnyFunSuite.scala:1562)\n\tat org.scalatest.Suite.run(Suite.scala:1112)\n\tat org.scalatest.Suite.run$(Suite.scala:1094)\n\tat org.scalatest.funsuite.AnyFunSuite.org$scalatest$funsuite$AnyFunSuiteLike$$super$run(AnyFunSuite.scala:1562)\n\tat org.scalatest.funsuite.AnyFunSuiteLike.$anonfun$run$1(AnyFunSuiteLike.scala:236)\n\tat org.scalatest.SuperEngine.runImpl(Engine.scala:535)\n\tat org.scalatest.funsuite.AnyFunSuiteLike.run(AnyFunSuiteLike.scala:236)\n\tat org.scalatest.funsuite.AnyFunSuiteLike.run$(AnyFunSuiteLike.scala:235)\n\tat org.scalatest.funsuite.AnyFunSuite.run(AnyFunSuite.scala:1562)\n\tat org.scalatest.tools.Framework.org$scalatest$tools$Framework$$runSuite(Framework.scala:318)\n\tat org.scalatest.tools.Framework$ScalaTestTask.execute(Framework.scala:513)\n\tat sbt.TestRunner.runTest$1(TestFramework.scala:139)\n\tat sbt.TestRunner.run(TestFramework.scala:154)\n\tat sbt.TestFramework$$anon$3$$anonfun$$lessinit$greater$1.$anonfun$apply$1(TestFramework.scala:317)\n\tat sbt.TestFramework$.sbt$TestFramework$$withContextLoader(TestFramework.scala:277)\n\tat sbt.TestFramework$$anon$3$$anonfun$$lessinit$greater$1.apply(TestFramework.scala:317)\n\tat sbt.TestFramework$$anon$3$$anonfun$$lessinit$greater$1.apply(TestFramework.scala:317)\n\tat sbt.TestFunction.apply(TestFramework.scala:329)\n\tat sbt.Tests$.$anonfun$toTask$1(Tests.scala:311)\n\tat sbt.std.Transform$$anon$3.$anonfun$apply$2(Transform.scala:46)\n\tat sbt.std.Transform$$anon$4.work(Transform.scala:67)\n\tat sbt.Execute.$anonfun$submit$2(Execute.scala:281)\n\tat sbt.internal.util.ErrorHandling$.wideConvert(ErrorHandling.scala:19)\n\tat sbt.Execute.work(Execute.scala:290)\n\tat sbt.Execute.$anonfun$submit$1(Execute.scala:281)\n\tat sbt.ConcurrentRestrictions$$anon$4.$anonfun$submitValid$1(ConcurrentRestrictions.scala:178)\n\tat sbt.CompletionService$$anon$2.call(CompletionService.scala:37)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:748)\nCaused by: java.lang.InterruptedException\n\tat java.lang.Object.wait(Native Method)\n\tat org.apache.kafka.common.utils.SystemTime.waitObject(SystemTime.java:60)\n\tat org.apache.kafka.clients.producer.internals.ProducerMetadata.awaitUpdate(ProducerMetadata.java:97)\n\tat org.apache.kafka.clients.producer.KafkaProducer.waitOnMetadata(KafkaProducer.java:999)\n\tat org.apache.kafka.clients.producer.KafkaProducer.doSend(KafkaProducer.java:876)\n\t... 61 more"
          },
          "error": null,
          "skipped": false
        }
      ]
    },
    {
      "time": 9763,
      "tests": 3,
      "failures": 0,
      "errors": 0,
      "skipped": 0,
      "name": "io.lenses.core.metrics.MetricValuesRetentionStreamsTest",
      "timestamp": "2020-07-26T21:54:37",
      "testcase": [
        {
          "name": "MetricValuesRetentionStreams should onInsertPipe should delete expired values according to policy",
          "classname": "io.lenses.core.metrics.MetricValuesRetentionStreamsTest",
          "time": 8137,
          "failure": null,
          "error": null,
          "skipped": false
        },
        {
          "name": "MetricValuesRetentionStreams should onInsertPipe should delete excess values even when earlier data points un-fulfilled",
          "classname": "io.lenses.core.metrics.MetricValuesRetentionStreamsTest",
          "time": 843,
          "failure": null,
          "error": null,
          "skipped": false
        },
        {
          "name": "MetricValuesRetentionStreams should hardDeleteStream should delete values before retention cutoff",
          "classname": "io.lenses.core.metrics.MetricValuesRetentionStreamsTest",
          "time": 783,
          "failure": null,
          "error": null,
          "skipped": false
        }
      ]
    },
    {
      "time": 492,
      "tests": 3,
      "failures": 0,
      "errors": 0,
      "skipped": 0,
      "name": "io.lenses.core.actors.AuditActorSpec",
      "timestamp": "2020-07-26T21:54:43",
      "testcase": [
        {
          "name": "AuditActor should log the audit and forward it to 'subscriber'",
          "classname": "io.lenses.core.actors.AuditActorSpec",
          "time": 36,
          "failure": null,
          "error": null,
          "skipped": false
        },
        {
          "name": "AuditActor should should not log the audit and forward it to 'subscriber' if license is disabling it",
          "classname": "io.lenses.core.actors.AuditActorSpec",
          "time": 262,
          "failure": null,
          "error": null,
          "skipped": false
        },
        {
          "name": "AuditActor should ignore failed audit and continue",
          "classname": "io.lenses.core.actors.AuditActorSpec",
          "time": 194,
          "failure": null,
          "error": null,
          "skipped": false
        }
      ]
    },
    {
      "time": 758,
      "tests": 3,
      "failures": 0,
      "errors": 0,
      "skipped": 0,
      "name": "io.lenses.core.channels.publisher.splunk.SplunkAuditPublisherTest",
      "timestamp": "2020-07-26T21:54:39",
      "testcase": [
        {
          "name": "SplunkAuditPublisher should raise an InitError when the supplied configuration is not valid",
          "classname": "io.lenses.core.channels.publisher.splunk.SplunkAuditPublisherTest",
          "time": 507,
          "failure": null,
          "error": null,
          "skipped": false
        },
        {
          "name": "SplunkAuditPublisher should publish audits using Splunk CIM schema",
          "classname": "io.lenses.core.channels.publisher.splunk.SplunkAuditPublisherTest",
          "time": 163,
          "failure": null,
          "error": null,
          "skipped": false
        },
        {
          "name": "SplunkAuditPublisher should raise a PublishError error if Splunk call fails",
          "classname": "io.lenses.core.channels.publisher.splunk.SplunkAuditPublisherTest",
          "time": 88,
          "failure": null,
          "error": null,
          "skipped": false
        }
      ]
    },
    {
      "time": 2088,
      "tests": 4,
      "failures": 0,
      "errors": 0,
      "skipped": 0,
      "name": "io.lenses.core.actors.BrokerDataAggregatorActorTest",
      "timestamp": "2020-07-26T21:54:40",
      "testcase": [
        {
          "name": "BrokerDataAggregatorActor should raise the openfile descriptor alert for broker 1",
          "classname": "io.lenses.core.actors.BrokerDataAggregatorActorTest",
          "time": 254,
          "failure": null,
          "error": null,
          "skipped": false
        },
        {
          "name": "BrokerDataAggregatorActor should raise the openfile descriptor alert for broker 1 and broker 2",
          "classname": "io.lenses.core.actors.BrokerDataAggregatorActorTest",
          "time": 365,
          "failure": null,
          "error": null,
          "skipped": false
        },
        {
          "name": "BrokerDataAggregatorActor should raise the openfile descriptor alert for broker 1 once it is not an issue",
          "classname": "io.lenses.core.actors.BrokerDataAggregatorActorTest",
          "time": 346,
          "failure": null,
          "error": null,
          "skipped": false
        },
        {
          "name": "BrokerDataAggregatorActor should raise the openfile descriptor alert for broker 1, 4 times",
          "classname": "io.lenses.core.actors.BrokerDataAggregatorActorTest",
          "time": 1123,
          "failure": null,
          "error": null,
          "skipped": false
        }
      ]
    },
    {
      "time": 2723,
      "tests": 5,
      "failures": 0,
      "errors": 0,
      "skipped": 0,
      "name": "io.lenses.core.metrics.data.kafka.MessageProducedMetricsCalculationServiceImplTest",
      "timestamp": "2020-07-26T21:54:51",
      "testcase": [
        {
          "name": "MessageProducedMetricsCalculationServiceImpl can calculate periodically metrics should successfully calculate",
          "classname": "io.lenses.core.metrics.data.kafka.MessageProducedMetricsCalculationServiceImplTest",
          "time": 604,
          "failure": null,
          "error": null,
          "skipped": false
        },
        {
          "name": "MessageProducedMetricsCalculationServiceImpl can calculate periodically metrics should successfully calculate filling missing data with nones",
          "classname": "io.lenses.core.metrics.data.kafka.MessageProducedMetricsCalculationServiceImplTest",
          "time": 600,
          "failure": null,
          "error": null,
          "skipped": false
        },
        {
          "name": "MessageProducedMetricsCalculationServiceImpl can calculate periodically metrics should successfully calculate filling missing middle periods",
          "classname": "io.lenses.core.metrics.data.kafka.MessageProducedMetricsCalculationServiceImplTest",
          "time": 645,
          "failure": null,
          "error": null,
          "skipped": false
        },
        {
          "name": "MessageProducedMetricsCalculationServiceImpl can calculate periodically metrics should successfully calculate grouping by period",
          "classname": "io.lenses.core.metrics.data.kafka.MessageProducedMetricsCalculationServiceImplTest",
          "time": 470,
          "failure": null,
          "error": null,
          "skipped": false
        },
        {
          "name": "MessageProducedMetricsCalculationServiceImpl can calculate periodically metrics should successfully calculate filling missing from and to periods hourly",
          "classname": "io.lenses.core.metrics.data.kafka.MessageProducedMetricsCalculationServiceImplTest",
          "time": 404,
          "failure": null,
          "error": null,
          "skipped": false
        }
      ]
    },
    {
      "time": 240015,
      "tests": 2,
      "failures": 2,
      "errors": 0,
      "skipped": 0,
      "name": "io.lenses.core.kafka.admin.KafkaAdminClientCreateAndDeleteSpec",
      "timestamp": "2020-07-26T21:54:39",
      "testcase": [
        {
          "name": "createTopics and deleteTopics should work as expected when all topics new",
          "classname": "io.lenses.core.kafka.admin.KafkaAdminClientCreateAndDeleteSpec",
          "time": 120008,
          "failure": {
            "message": "Timed out waiting for a node assignment.",
            "type": "org.apache.kafka.common.errors.TimeoutException",
            "stackTrace": "org.apache.kafka.common.errors.TimeoutException: Timed out waiting for a node assignment."
          },
          "error": null,
          "skipped": false
        },
        {
          "name": "createTopics and deleteTopics should fail creating topics that are already present",
          "classname": "io.lenses.core.kafka.admin.KafkaAdminClientCreateAndDeleteSpec",
          "time": 120007,
          "failure": {
            "message": "Timed out waiting for a node assignment.",
            "type": "org.apache.kafka.common.errors.TimeoutException",
            "stackTrace": "org.apache.kafka.common.errors.TimeoutException: Timed out waiting for a node assignment."
          },
          "error": null,
          "skipped": false
        }
      ]
    },
    {
      "time": 80,
      "tests": 5,
      "failures": 0,
      "errors": 0,
      "skipped": 0,
      "name": "io.lenses.core.channels.publisher.alertplugin.AlertPluginChannelPublisherTest",
      "timestamp": "2020-07-26T21:54:44",
      "testcase": [
        {
          "name": "AlertPluginChannelPublisherTest should pass configuration as Map[String, String]",
          "classname": "io.lenses.core.channels.publisher.alertplugin.AlertPluginChannelPublisherTest",
          "time": 51,
          "failure": null,
          "error": null,
          "skipped": false
        },
        {
          "name": "AlertPluginChannelPublisherTest should route alerts to correct plugin",
          "classname": "io.lenses.core.channels.publisher.alertplugin.AlertPluginChannelPublisherTest",
          "time": 8,
          "failure": null,
          "error": null,
          "skipped": false
        },
        {
          "name": "AlertPluginChannelPublisherTest should raise error if className missing",
          "classname": "io.lenses.core.channels.publisher.alertplugin.AlertPluginChannelPublisherTest",
          "time": 5,
          "failure": null,
          "error": null,
          "skipped": false
        },
        {
          "name": "AlertPluginChannelPublisherTest should raise initialisation errors",
          "classname": "io.lenses.core.channels.publisher.alertplugin.AlertPluginChannelPublisherTest",
          "time": 8,
          "failure": null,
          "error": null,
          "skipped": false
        },
        {
          "name": "AlertPluginChannelPublisherTest should raise publishing errors",
          "classname": "io.lenses.core.channels.publisher.alertplugin.AlertPluginChannelPublisherTest",
          "time": 8,
          "failure": null,
          "error": null,
          "skipped": false
        }
      ]
    },
    {
      "time": 0,
      "tests": 1,
      "failures": 0,
      "errors": 0,
      "skipped": 0,
      "name": "io.lenses.core.channels.publisher.webhook.loader.render.AlertTemplateRendererTest",
      "timestamp": "2020-07-26T21:54:46",
      "testcase": [
        {
          "name": "AlertTemplateRenderer should properly find variables",
          "classname": "io.lenses.core.channels.publisher.webhook.loader.render.AlertTemplateRendererTest",
          "time": 0,
          "failure": null,
          "error": null,
          "skipped": false
        }
      ]
    },
    {
      "time": 890,
      "tests": 3,
      "failures": 0,
      "errors": 0,
      "skipped": 0,
      "name": "io.lenses.core.yaml.YamlHelperTest",
      "timestamp": "2020-07-26T21:54:37",
      "testcase": [
        {
          "name": "YamlHelper should read a connect model from Yaml json",
          "classname": "io.lenses.core.yaml.YamlHelperTest",
          "time": 850,
          "failure": null,
          "error": null,
          "skipped": false
        },
        {
          "name": "YamlHelper should read a connect model from Yaml json with a default value being list",
          "classname": "io.lenses.core.yaml.YamlHelperTest",
          "time": 20,
          "failure": null,
          "error": null,
          "skipped": false
        },
        {
          "name": "YamlHelper should read the model from a Yaml",
          "classname": "io.lenses.core.yaml.YamlHelperTest",
          "time": 20,
          "failure": null,
          "error": null,
          "skipped": false
        }
      ]
    },
    {
      "time": 663080,
      "tests": 1,
      "failures": 1,
      "errors": 0,
      "skipped": 0,
      "name": "io.lenses.core.migration.AlertMigrationIntegrationTest",
      "timestamp": "2020-07-26T21:54:45",
      "testcase": [
        {
          "name": "migrate alerts to AlertStore",
          "classname": "io.lenses.core.migration.AlertMigrationIntegrationTest",
          "time": 663080,
          "failure": {
            "message": "java.lang.InterruptedException",
            "type": "org.apache.kafka.common.errors.InterruptException",
            "stackTrace": "org.apache.kafka.common.errors.InterruptException: java.lang.InterruptedException\n\tat org.apache.kafka.clients.producer.KafkaProducer.doSend(KafkaProducer.java:937)\n\tat org.apache.kafka.clients.producer.KafkaProducer.send(KafkaProducer.java:856)\n\tat org.apache.kafka.clients.producer.KafkaProducer.send(KafkaProducer.java:743)\n\tat io.lenses.core.migration.AlertMigrationIntegrationTest.$anonfun$new$2(AlertMigrationIntegrationTest.scala:70)\n\tat scala.collection.immutable.Stream.foreach(Stream.scala:533)\n\tat io.lenses.core.migration.AlertMigrationIntegrationTest.$anonfun$new$1(AlertMigrationIntegrationTest.scala:62)\n\tat org.scalatest.OutcomeOf.outcomeOf(OutcomeOf.scala:85)\n\tat org.scalatest.OutcomeOf.outcomeOf$(OutcomeOf.scala:83)\n\tat org.scalatest.OutcomeOf$.outcomeOf(OutcomeOf.scala:104)\n\tat org.scalatest.Transformer.apply(Transformer.scala:22)\n\tat org.scalatest.Transformer.apply(Transformer.scala:20)\n\tat org.scalatest.funsuite.AnyFunSuiteLike$$anon$1.apply(AnyFunSuiteLike.scala:189)\n\tat org.scalatest.TestSuite.withFixture(TestSuite.scala:196)\n\tat org.scalatest.TestSuite.withFixture$(TestSuite.scala:195)\n\tat org.scalatest.funsuite.AnyFunSuite.withFixture(AnyFunSuite.scala:1562)\n\tat org.scalatest.funsuite.AnyFunSuiteLike.invokeWithFixture$1(AnyFunSuiteLike.scala:187)\n\tat org.scalatest.funsuite.AnyFunSuiteLike.$anonfun$runTest$1(AnyFunSuiteLike.scala:199)\n\tat org.scalatest.SuperEngine.runTestImpl(Engine.scala:306)\n\tat org.scalatest.funsuite.AnyFunSuiteLike.runTest(AnyFunSuiteLike.scala:199)\n\tat org.scalatest.funsuite.AnyFunSuiteLike.runTest$(AnyFunSuiteLike.scala:181)\n\tat org.scalatest.funsuite.AnyFunSuite.runTest(AnyFunSuite.scala:1562)\n\tat org.scalatest.funsuite.AnyFunSuiteLike.$anonfun$runTests$1(AnyFunSuiteLike.scala:232)\n\tat org.scalatest.SuperEngine.$anonfun$runTestsInBranch$1(Engine.scala:413)\n\tat scala.collection.immutable.List.foreach(List.scala:392)\n\tat org.scalatest.SuperEngine.traverseSubNodes$1(Engine.scala:401)\n\tat org.scalatest.SuperEngine.runTestsInBranch(Engine.scala:396)\n\tat org.scalatest.SuperEngine.runTestsImpl(Engine.scala:475)\n\tat org.scalatest.funsuite.AnyFunSuiteLike.runTests(AnyFunSuiteLike.scala:232)\n\tat org.scalatest.funsuite.AnyFunSuiteLike.runTests$(AnyFunSuiteLike.scala:231)\n\tat org.scalatest.funsuite.AnyFunSuite.runTests(AnyFunSuite.scala:1562)\n\tat org.scalatest.Suite.run(Suite.scala:1112)\n\tat org.scalatest.Suite.run$(Suite.scala:1094)\n\tat org.scalatest.funsuite.AnyFunSuite.org$scalatest$funsuite$AnyFunSuiteLike$$super$run(AnyFunSuite.scala:1562)\n\tat org.scalatest.funsuite.AnyFunSuiteLike.$anonfun$run$1(AnyFunSuiteLike.scala:236)\n\tat org.scalatest.SuperEngine.runImpl(Engine.scala:535)\n\tat org.scalatest.funsuite.AnyFunSuiteLike.run(AnyFunSuiteLike.scala:236)\n\tat org.scalatest.funsuite.AnyFunSuiteLike.run$(AnyFunSuiteLike.scala:235)\n\tat org.scalatest.funsuite.AnyFunSuite.run(AnyFunSuite.scala:1562)\n\tat org.scalatest.tools.Framework.org$scalatest$tools$Framework$$runSuite(Framework.scala:318)\n\tat org.scalatest.tools.Framework$ScalaTestTask.execute(Framework.scala:513)\n\tat sbt.TestRunner.runTest$1(TestFramework.scala:139)\n\tat sbt.TestRunner.run(TestFramework.scala:154)\n\tat sbt.TestFramework$$anon$3$$anonfun$$lessinit$greater$1.$anonfun$apply$1(TestFramework.scala:317)\n\tat sbt.TestFramework$.sbt$TestFramework$$withContextLoader(TestFramework.scala:277)\n\tat sbt.TestFramework$$anon$3$$anonfun$$lessinit$greater$1.apply(TestFramework.scala:317)\n\tat sbt.TestFramework$$anon$3$$anonfun$$lessinit$greater$1.apply(TestFramework.scala:317)\n\tat sbt.TestFunction.apply(TestFramework.scala:329)\n\tat sbt.Tests$.$anonfun$toTask$1(Tests.scala:311)\n\tat sbt.std.Transform$$anon$3.$anonfun$apply$2(Transform.scala:46)\n\tat sbt.std.Transform$$anon$4.work(Transform.scala:67)\n\tat sbt.Execute.$anonfun$submit$2(Execute.scala:281)\n\tat sbt.internal.util.ErrorHandling$.wideConvert(ErrorHandling.scala:19)\n\tat sbt.Execute.work(Execute.scala:290)\n\tat sbt.Execute.$anonfun$submit$1(Execute.scala:281)\n\tat sbt.ConcurrentRestrictions$$anon$4.$anonfun$submitValid$1(ConcurrentRestrictions.scala:178)\n\tat sbt.CompletionService$$anon$2.call(CompletionService.scala:37)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:748)\nCaused by: java.lang.InterruptedException\n\tat java.lang.Object.wait(Native Method)\n\tat org.apache.kafka.common.utils.SystemTime.waitObject(SystemTime.java:60)\n\tat org.apache.kafka.clients.producer.internals.ProducerMetadata.awaitUpdate(ProducerMetadata.java:97)\n\tat org.apache.kafka.clients.producer.KafkaProducer.waitOnMetadata(KafkaProducer.java:999)\n\tat org.apache.kafka.clients.producer.KafkaProducer.doSend(KafkaProducer.java:876)\n\t... 61 more"
          },
          "error": null,
          "skipped": false
        }
      ]
    },
    {
      "time": 1,
      "tests": 3,
      "failures": 0,
      "errors": 0,
      "skipped": 0,
      "name": "io.lenses.core.monitoring.actions.RaiseFailedFetchRequestsPerSecAlertsFnTest",
      "timestamp": "2020-07-26T21:54:41",
      "testcase": [
        {
          "name": "1",
          "classname": "io.lenses.core.monitoring.actions.RaiseFailedFetchRequestsPerSecAlertsFnTest",
          "time": 1,
          "failure": null,
          "error": null,
          "skipped": false
        },
        {
          "name": "RaiseFailedFetchRequestPerSecAlertsFn should raise a MEDIUM level alert when failed fetch request percentage > 0",
          "classname": "io.lenses.core.monitoring.actions.RaiseFailedFetchRequestsPerSecAlertsFnTest",
          "time": 0,
          "failure": null,
          "error": null,
          "skipped": false
        },
        {
          "name": "RaiseFailedFetchRequestPerSecAlertsFn should raise an INfo alert when the failed fetch request is back to 0 on brokers",
          "classname": "io.lenses.core.monitoring.actions.RaiseFailedFetchRequestsPerSecAlertsFnTest",
          "time": 0,
          "failure": null,
          "error": null,
          "skipped": false
        }
      ]
    },
    {
      "time": 1710,
      "tests": 2,
      "failures": 0,
      "errors": 0,
      "skipped": 0,
      "name": "io.lenses.core.channels.forwarder.AlertChannelForwarderTest",
      "timestamp": "2020-07-26T21:54:40",
      "testcase": [
        {
          "name": "AlertChannelForwarder should route consumer lag alerts to channels configured for this setting",
          "classname": "io.lenses.core.channels.forwarder.AlertChannelForwarderTest",
          "time": 844,
          "failure": null,
          "error": null,
          "skipped": false
        },
        {
          "name": "AlertChannelForwarder should route 'fixed alerts' to channels configured for this setting",
          "classname": "io.lenses.core.channels.forwarder.AlertChannelForwarderTest",
          "time": 866,
          "failure": null,
          "error": null,
          "skipped": false
        }
      ]
    },
    {
      "time": 4935,
      "tests": 1,
      "failures": 0,
      "errors": 0,
      "skipped": 0,
      "name": "io.lenses.core.telemetry.FlowsBackedConnectionsTelemetrySpec",
      "timestamp": "2020-07-26T21:54:38",
      "testcase": [
        {
          "name": "connections telemetry should return info about all connection types",
          "classname": "io.lenses.core.telemetry.FlowsBackedConnectionsTelemetrySpec",
          "time": 4935,
          "failure": null,
          "error": null,
          "skipped": false
        }
      ]
    },
    {
      "time": 681,
      "tests": 3,
      "failures": 0,
      "errors": 0,
      "skipped": 0,
      "name": "io.lenses.core.channels.publisher.datadog.DataDogAlertPublisherTest",
      "timestamp": "2020-07-26T21:54:39",
      "testcase": [
        {
          "name": "DataDogAlertPublisher should throw an InitError when the supplied configuration is not valid",
          "classname": "io.lenses.core.channels.publisher.datadog.DataDogAlertPublisherTest",
          "time": 365,
          "failure": null,
          "error": null,
          "skipped": false
        },
        {
          "name": "DataDogAlertPublisher should aggregates consumer events by condition id",
          "classname": "io.lenses.core.channels.publisher.datadog.DataDogAlertPublisherTest",
          "time": 304,
          "failure": null,
          "error": null,
          "skipped": false
        },
        {
          "name": "DataDogAlertPublisher should aggregates broker events by condition id",
          "classname": "io.lenses.core.channels.publisher.datadog.DataDogAlertPublisherTest",
          "time": 12,
          "failure": null,
          "error": null,
          "skipped": false
        }
      ]
    },
    {
      "time": 1830,
      "tests": 3,
      "failures": 0,
      "errors": 0,
      "skipped": 0,
      "name": "io.lenses.core.migration.AsyncMigrationManagerTest",
      "timestamp": "2020-07-26T21:54:50",
      "testcase": [
        {
          "name": "handles empty task list",
          "classname": "io.lenses.core.migration.AsyncMigrationManagerTest",
          "time": 1003,
          "failure": null,
          "error": null,
          "skipped": false
        },
        {
          "name": "handles one migration task",
          "classname": "io.lenses.core.migration.AsyncMigrationManagerTest",
          "time": 422,
          "failure": null,
          "error": null,
          "skipped": false
        },
        {
          "name": "handles two migration task",
          "classname": "io.lenses.core.migration.AsyncMigrationManagerTest",
          "time": 405,
          "failure": null,
          "error": null,
          "skipped": false
        }
      ]
    },
    {
      "time": 7041,
      "tests": 1,
      "failures": 0,
      "errors": 0,
      "skipped": 0,
      "name": "io.lenses.core.utils.FileWatcherTest",
      "timestamp": "2020-07-26T21:54:37",
      "testcase": [
        {
          "name": "should raise a notification when file has changed",
          "classname": "io.lenses.core.utils.FileWatcherTest",
          "time": 7041,
          "failure": null,
          "error": null,
          "skipped": false
        }
      ]
    },
    {
      "time": 955,
      "tests": 4,
      "failures": 0,
      "errors": 0,
      "skipped": 0,
      "name": "io.lenses.core.channels.publisher.datadog.DataDogClientTest",
      "timestamp": "2020-07-26T21:54:37",
      "testcase": [
        {
          "name": "DataDogClient should successfully submit events to DataDog when site is correctly set",
          "classname": "io.lenses.core.channels.publisher.datadog.DataDogClientTest",
          "time": 910,
          "failure": null,
          "error": null,
          "skipped": false
        },
        {
          "name": "DataDogClient should submit no event to DataDog when region is misconfigured",
          "classname": "io.lenses.core.channels.publisher.datadog.DataDogClientTest",
          "time": 18,
          "failure": null,
          "error": null,
          "skipped": false
        },
        {
          "name": "DataDogClient should submit no event to DataDog when apiKey is misconfigured",
          "classname": "io.lenses.core.channels.publisher.datadog.DataDogClientTest",
          "time": 23,
          "failure": null,
          "error": null,
          "skipped": false
        },
        {
          "name": "DataDogClient should submit no event to DataDog when applicationKey is misconfigured",
          "classname": "io.lenses.core.channels.publisher.datadog.DataDogClientTest",
          "time": 4,
          "failure": null,
          "error": null,
          "skipped": false
        }
      ]
    },
    {
      "time": 18,
      "tests": 1,
      "failures": 0,
      "errors": 0,
      "skipped": 0,
      "name": "io.lenses.core.migration.KafkaOnePartitionTopicReaderTest",
      "timestamp": "2020-07-26T21:54:37",
      "testcase": [
        {
          "name": "returns hasNext true when not all data is read",
          "classname": "io.lenses.core.migration.KafkaOnePartitionTopicReaderTest",
          "time": 18,
          "failure": null,
          "error": null,
          "skipped": false
        }
      ]
    },
    {
      "time": 893,
      "tests": 2,
      "failures": 0,
      "errors": 0,
      "skipped": 0,
      "name": "io.lenses.core.actors.PayloadIdentifierTest",
      "timestamp": "2020-07-26T21:54:44",
      "testcase": [
        {
          "name": "KEY & VALUE type identification should work",
          "classname": "io.lenses.core.actors.PayloadIdentifierTest",
          "time": 489,
          "failure": null,
          "error": null,
          "skipped": false
        },
        {
          "name": "KEY & VALUE type identification should work for Serdes",
          "classname": "io.lenses.core.actors.PayloadIdentifierTest",
          "time": 404,
          "failure": null,
          "error": null,
          "skipped": false
        }
      ]
    },
    {
      "time": 10001,
      "tests": 1,
      "failures": 1,
      "errors": 0,
      "skipped": 0,
      "name": "io.lenses.core.kafka.FetcherWrapperTest",
      "timestamp": "2020-07-26T21:54:49",
      "testcase": [
        {
          "name": "should read last offset",
          "classname": "io.lenses.core.kafka.FetcherWrapperTest",
          "time": 10001,
          "failure": {
            "message": null,
            "type": "java.util.concurrent.TimeoutException",
            "stackTrace": "java.util.concurrent.TimeoutException\n\tat org.apache.kafka.common.internals.KafkaFutureImpl$SingleWaiter.await(KafkaFutureImpl.java:108)\n\tat org.apache.kafka.common.internals.KafkaFutureImpl.get(KafkaFutureImpl.java:272)\n\tat io.lenses.test.kafka.cluster.Cluster.createTopic(Cluster.scala:44)\n\tat io.lenses.test.kafka.cluster.Cluster.createTopic$(Cluster.scala:42)\n\tat io.lenses.core.kafka.FetcherWrapperTest.createTopic(FetcherWrapperTest.scala:24)\n\tat io.lenses.core.kafka.FetcherWrapperTest.$anonfun$new$1(FetcherWrapperTest.scala:37)\n\tat org.scalatest.OutcomeOf.outcomeOf(OutcomeOf.scala:85)\n\tat org.scalatest.OutcomeOf.outcomeOf$(OutcomeOf.scala:83)\n\tat org.scalatest.OutcomeOf$.outcomeOf(OutcomeOf.scala:104)\n\tat org.scalatest.Transformer.apply(Transformer.scala:22)\n\tat org.scalatest.Transformer.apply(Transformer.scala:20)\n\tat org.scalatest.wordspec.AnyWordSpecLike$$anon$3.apply(AnyWordSpecLike.scala:1076)\n\tat org.scalatest.TestSuite.withFixture(TestSuite.scala:196)\n\tat org.scalatest.TestSuite.withFixture$(TestSuite.scala:195)\n\tat io.lenses.core.kafka.FetcherWrapperTest.withFixture(FetcherWrapperTest.scala:24)\n\tat org.scalatest.wordspec.AnyWordSpecLike.invokeWithFixture$1(AnyWordSpecLike.scala:1074)\n\tat org.scalatest.wordspec.AnyWordSpecLike.$anonfun$runTest$1(AnyWordSpecLike.scala:1086)\n\tat org.scalatest.SuperEngine.runTestImpl(Engine.scala:306)\n\tat org.scalatest.wordspec.AnyWordSpecLike.runTest(AnyWordSpecLike.scala:1086)\n\tat org.scalatest.wordspec.AnyWordSpecLike.runTest$(AnyWordSpecLike.scala:1068)\n\tat io.lenses.core.kafka.FetcherWrapperTest.runTest(FetcherWrapperTest.scala:24)\n\tat org.scalatest.wordspec.AnyWordSpecLike.$anonfun$runTests$1(AnyWordSpecLike.scala:1145)\n\tat org.scalatest.SuperEngine.$anonfun$runTestsInBranch$1(Engine.scala:413)\n\tat scala.collection.immutable.List.foreach(List.scala:392)\n\tat org.scalatest.SuperEngine.traverseSubNodes$1(Engine.scala:401)\n\tat org.scalatest.SuperEngine.runTestsInBranch(Engine.scala:396)\n\tat org.scalatest.SuperEngine.runTestsImpl(Engine.scala:475)\n\tat org.scalatest.wordspec.AnyWordSpecLike.runTests(AnyWordSpecLike.scala:1145)\n\tat org.scalatest.wordspec.AnyWordSpecLike.runTests$(AnyWordSpecLike.scala:1144)\n\tat io.lenses.core.kafka.FetcherWrapperTest.runTests(FetcherWrapperTest.scala:24)\n\tat org.scalatest.Suite.run(Suite.scala:1112)\n\tat org.scalatest.Suite.run$(Suite.scala:1094)\n\tat io.lenses.core.kafka.FetcherWrapperTest.org$scalatest$wordspec$AnyWordSpecLike$$super$run(FetcherWrapperTest.scala:24)\n\tat org.scalatest.wordspec.AnyWordSpecLike.$anonfun$run$1(AnyWordSpecLike.scala:1190)\n\tat org.scalatest.SuperEngine.runImpl(Engine.scala:535)\n\tat org.scalatest.wordspec.AnyWordSpecLike.run(AnyWordSpecLike.scala:1190)\n\tat org.scalatest.wordspec.AnyWordSpecLike.run$(AnyWordSpecLike.scala:1188)\n\tat io.lenses.core.kafka.FetcherWrapperTest.org$scalatest$BeforeAndAfterAll$$super$run(FetcherWrapperTest.scala:24)\n\tat org.scalatest.BeforeAndAfterAll.liftedTree1$1(BeforeAndAfterAll.scala:213)\n\tat org.scalatest.BeforeAndAfterAll.run(BeforeAndAfterAll.scala:210)\n\tat org.scalatest.BeforeAndAfterAll.run$(BeforeAndAfterAll.scala:208)\n\tat io.lenses.core.kafka.FetcherWrapperTest.run(FetcherWrapperTest.scala:24)\n\tat org.scalatest.tools.Framework.org$scalatest$tools$Framework$$runSuite(Framework.scala:318)\n\tat org.scalatest.tools.Framework$ScalaTestTask.execute(Framework.scala:513)\n\tat sbt.TestRunner.runTest$1(TestFramework.scala:139)\n\tat sbt.TestRunner.run(TestFramework.scala:154)\n\tat sbt.TestFramework$$anon$3$$anonfun$$lessinit$greater$1.$anonfun$apply$1(TestFramework.scala:317)\n\tat sbt.TestFramework$.sbt$TestFramework$$withContextLoader(TestFramework.scala:277)\n\tat sbt.TestFramework$$anon$3$$anonfun$$lessinit$greater$1.apply(TestFramework.scala:317)\n\tat sbt.TestFramework$$anon$3$$anonfun$$lessinit$greater$1.apply(TestFramework.scala:317)\n\tat sbt.TestFunction.apply(TestFramework.scala:329)\n\tat sbt.Tests$.$anonfun$toTask$1(Tests.scala:311)\n\tat sbt.std.Transform$$anon$3.$anonfun$apply$2(Transform.scala:46)\n\tat sbt.std.Transform$$anon$4.work(Transform.scala:67)\n\tat sbt.Execute.$anonfun$submit$2(Execute.scala:281)\n\tat sbt.internal.util.ErrorHandling$.wideConvert(ErrorHandling.scala:19)\n\tat sbt.Execute.work(Execute.scala:290)\n\tat sbt.Execute.$anonfun$submit$1(Execute.scala:281)\n\tat sbt.ConcurrentRestrictions$$anon$4.$anonfun$submitValid$1(ConcurrentRestrictions.scala:178)\n\tat sbt.CompletionService$$anon$2.call(CompletionService.scala:37)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:748)"
          },
          "error": null,
          "skipped": false
        }
      ]
    },
    {
      "time": 4,
      "tests": 2,
      "failures": 0,
      "errors": 0,
      "skipped": 0,
      "name": "io.lenses.core.channels.forwarder.ConditionalChannelForwarderTest",
      "timestamp": "2020-07-26T21:54:43",
      "testcase": [
        {
          "name": "does not forward the event if it is not allowed",
          "classname": "io.lenses.core.channels.forwarder.ConditionalChannelForwarderTest",
          "time": 2,
          "failure": null,
          "error": null,
          "skipped": false
        },
        {
          "name": "forward the event if it is allowed",
          "classname": "io.lenses.core.channels.forwarder.ConditionalChannelForwarderTest",
          "time": 2,
          "failure": null,
          "error": null,
          "skipped": false
        }
      ]
    },
    {
      "time": 11976,
      "tests": 7,
      "failures": 0,
      "errors": 0,
      "skipped": 0,
      "name": "io.lenses.core.metrics.KafkaPartitionEndOffsetCollectorTest",
      "timestamp": "2020-07-26T21:54:37",
      "testcase": [
        {
          "name": "KafkaPartitionEndOffsetCollector should store offsets (and trigger event) when store is empty",
          "classname": "io.lenses.core.metrics.KafkaPartitionEndOffsetCollectorTest",
          "time": 8058,
          "failure": null,
          "error": null,
          "skipped": false
        },
        {
          "name": "KafkaPartitionEndOffsetCollector should only trigger event, when previous values after start of day",
          "classname": "io.lenses.core.metrics.KafkaPartitionEndOffsetCollectorTest",
          "time": 847,
          "failure": null,
          "error": null,
          "skipped": false
        },
        {
          "name": "KafkaPartitionEndOffsetCollector should store offsets if previously stored were before startOfDay",
          "classname": "io.lenses.core.metrics.KafkaPartitionEndOffsetCollectorTest",
          "time": 742,
          "failure": null,
          "error": null,
          "skipped": false
        },
        {
          "name": "KafkaPartitionEndOffsetCollector should store offsets for partitions that were missing in previous storage",
          "classname": "io.lenses.core.metrics.KafkaPartitionEndOffsetCollectorTest",
          "time": 616,
          "failure": null,
          "error": null,
          "skipped": false
        },
        {
          "name": "KafkaPartitionEndOffsetCollector should store offsets if collection duration becomes shorter",
          "classname": "io.lenses.core.metrics.KafkaPartitionEndOffsetCollectorTest",
          "time": 599,
          "failure": null,
          "error": null,
          "skipped": false
        },
        {
          "name": "KafkaPartitionEndOffsetCollector should fire correct summary events over time",
          "classname": "io.lenses.core.metrics.KafkaPartitionEndOffsetCollectorTest",
          "time": 616,
          "failure": null,
          "error": null,
          "skipped": false
        },
        {
          "name": "KafkaPartitionEndOffsetCollector should don't send events if invalid data detected",
          "classname": "io.lenses.core.metrics.KafkaPartitionEndOffsetCollectorTest",
          "time": 498,
          "failure": null,
          "error": null,
          "skipped": false
        }
      ]
    },
    {
      "time": 1094,
      "tests": 2,
      "failures": 0,
      "errors": 0,
      "skipped": 0,
      "name": "io.lenses.core.migration.ConsumerRecordConverterTest",
      "timestamp": "2020-07-26T21:54:45",
      "testcase": [
        {
          "name": "convert record to AlertV0",
          "classname": "io.lenses.core.migration.ConsumerRecordConverterTest",
          "time": 100,
          "failure": null,
          "error": null,
          "skipped": false
        },
        {
          "name": "convert ConsumerRecord to Audit",
          "classname": "io.lenses.core.migration.ConsumerRecordConverterTest",
          "time": 994,
          "failure": null,
          "error": null,
          "skipped": false
        }
      ]
    },
    {
      "time": 240505,
      "tests": 3,
      "failures": 2,
      "errors": 0,
      "skipped": 0,
      "name": "io.lenses.core.kafka.topics.TopicCreateServiceTest",
      "timestamp": "2020-07-26T21:54:38",
      "testcase": [
        {
          "name": "createTopic should be able to create a topic",
          "classname": "io.lenses.core.kafka.topics.TopicCreateServiceTest",
          "time": 120398,
          "failure": {
            "message": null,
            "type": "java.util.concurrent.TimeoutException",
            "stackTrace": "java.util.concurrent.TimeoutException\n\tat org.apache.kafka.common.internals.KafkaFutureImpl$SingleWaiter.await(KafkaFutureImpl.java:108)\n\tat org.apache.kafka.common.internals.KafkaFutureImpl.get(KafkaFutureImpl.java:272)\n\tat io.lenses.core.kafka.TopicCommand$.$anonfun$createTopic$1(TopicCommand.scala:93)\n\tat io.lenses.domain.logging.MetricsSupport.timed(MetricsSupport.scala:22)\n\tat io.lenses.domain.logging.MetricsSupport.timed$(MetricsSupport.scala:20)\n\tat io.lenses.core.kafka.TopicCommand$.timed(TopicCommand.scala:47)\n\tat io.lenses.core.kafka.TopicCommand$.createTopic(TopicCommand.scala:58)\n\tat io.lenses.core.kafka.topics.TopicCreateServiceImpl.$anonfun$createTopic$2(TopicCreateService.scala:79)\n\tat cats.effect.internals.IORunLoop$.cats$effect$internals$IORunLoop$$loop(IORunLoop.scala:87)\n\tat cats.effect.internals.IORunLoop$.startCancelable(IORunLoop.scala:41)\n\tat cats.effect.internals.IOBracket$BracketStart.run(IOBracket.scala:88)\n\tat cats.effect.internals.Trampoline.cats$effect$internals$Trampoline$$immediateLoop(Trampoline.scala:67)\n\tat cats.effect.internals.Trampoline.startLoop(Trampoline.scala:35)\n\tat cats.effect.internals.TrampolineEC$JVMTrampoline.super$startLoop(TrampolineEC.scala:89)\n\tat cats.effect.internals.TrampolineEC$JVMTrampoline.$anonfun$startLoop$1(TrampolineEC.scala:89)\n\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n\tat cats.effect.internals.TrampolineEC$JVMTrampoline.startLoop(TrampolineEC.scala:89)\n\tat cats.effect.internals.Trampoline.execute(Trampoline.scala:43)\n\tat cats.effect.internals.TrampolineEC.execute(TrampolineEC.scala:42)\n\tat cats.effect.internals.IOBracket$BracketStart.apply(IOBracket.scala:69)\n\tat cats.effect.internals.IOBracket$BracketStart.apply(IOBracket.scala:49)\n\tat cats.effect.internals.IORunLoop$.cats$effect$internals$IORunLoop$$loop(IORunLoop.scala:139)\n\tat cats.effect.internals.IORunLoop$RestartCallback.signal(IORunLoop.scala:359)\n\tat cats.effect.internals.IORunLoop$RestartCallback.apply(IORunLoop.scala:380)\n\tat cats.effect.internals.IORunLoop$RestartCallback.apply(IORunLoop.scala:323)\n\tat cats.effect.internals.IORunLoop$.cats$effect$internals$IORunLoop$$loop(IORunLoop.scala:139)\n\tat cats.effect.internals.IORunLoop$RestartCallback.signal(IORunLoop.scala:359)\n\tat cats.effect.internals.IORunLoop$RestartCallback.apply(IORunLoop.scala:380)\n\tat cats.effect.internals.IORunLoop$RestartCallback.apply(IORunLoop.scala:323)\n\tat cats.effect.internals.IOShift$Tick.run(IOShift.scala:35)\n\tat java.util.concurrent.ForkJoinTask$RunnableExecuteAction.exec(ForkJoinTask.java:1402)\n\tat java.util.concurrent.ForkJoinTask.doExec(ForkJoinTask.java:289)\n\tat java.util.concurrent.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1056)\n\tat java.util.concurrent.ForkJoinPool.runWorker(ForkJoinPool.java:1692)\n\tat java.util.concurrent.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:157)"
          },
          "error": null,
          "skipped": false
        },
        {
          "name": "createTopic should be unable to create topic due to InvalidReplicationFactorException",
          "classname": "io.lenses.core.kafka.topics.TopicCreateServiceTest",
          "time": 120106,
          "failure": {
            "message": null,
            "type": "java.util.concurrent.TimeoutException",
            "stackTrace": "java.util.concurrent.TimeoutException\n\tat org.apache.kafka.common.internals.KafkaFutureImpl$SingleWaiter.await(KafkaFutureImpl.java:108)\n\tat org.apache.kafka.common.internals.KafkaFutureImpl.get(KafkaFutureImpl.java:272)\n\tat io.lenses.core.kafka.TopicCommand$.$anonfun$createTopic$1(TopicCommand.scala:93)\n\tat io.lenses.domain.logging.MetricsSupport.timed(MetricsSupport.scala:22)\n\tat io.lenses.domain.logging.MetricsSupport.timed$(MetricsSupport.scala:20)\n\tat io.lenses.core.kafka.TopicCommand$.timed(TopicCommand.scala:47)\n\tat io.lenses.core.kafka.TopicCommand$.createTopic(TopicCommand.scala:58)\n\tat io.lenses.core.kafka.topics.TopicCreateServiceImpl.$anonfun$createTopic$2(TopicCreateService.scala:79)\n\tat cats.effect.internals.IORunLoop$.cats$effect$internals$IORunLoop$$loop(IORunLoop.scala:87)\n\tat cats.effect.internals.IORunLoop$.startCancelable(IORunLoop.scala:41)\n\tat cats.effect.internals.IOBracket$BracketStart.run(IOBracket.scala:88)\n\tat cats.effect.internals.Trampoline.cats$effect$internals$Trampoline$$immediateLoop(Trampoline.scala:67)\n\tat cats.effect.internals.Trampoline.startLoop(Trampoline.scala:35)\n\tat cats.effect.internals.TrampolineEC$JVMTrampoline.super$startLoop(TrampolineEC.scala:89)\n\tat cats.effect.internals.TrampolineEC$JVMTrampoline.$anonfun$startLoop$1(TrampolineEC.scala:89)\n\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n\tat cats.effect.internals.TrampolineEC$JVMTrampoline.startLoop(TrampolineEC.scala:89)\n\tat cats.effect.internals.Trampoline.execute(Trampoline.scala:43)\n\tat cats.effect.internals.TrampolineEC.execute(TrampolineEC.scala:42)\n\tat cats.effect.internals.IOBracket$BracketStart.apply(IOBracket.scala:69)\n\tat cats.effect.internals.IOBracket$BracketStart.apply(IOBracket.scala:49)\n\tat cats.effect.internals.IORunLoop$.cats$effect$internals$IORunLoop$$loop(IORunLoop.scala:139)\n\tat cats.effect.internals.IORunLoop$RestartCallback.signal(IORunLoop.scala:359)\n\tat cats.effect.internals.IORunLoop$RestartCallback.apply(IORunLoop.scala:380)\n\tat cats.effect.internals.IORunLoop$RestartCallback.apply(IORunLoop.scala:323)\n\tat cats.effect.internals.IORunLoop$.cats$effect$internals$IORunLoop$$loop(IORunLoop.scala:139)\n\tat cats.effect.internals.IORunLoop$RestartCallback.signal(IORunLoop.scala:359)\n\tat cats.effect.internals.IORunLoop$RestartCallback.apply(IORunLoop.scala:380)\n\tat cats.effect.internals.IORunLoop$RestartCallback.apply(IORunLoop.scala:323)\n\tat cats.effect.internals.IOShift$Tick.run(IOShift.scala:35)\n\tat java.util.concurrent.ForkJoinTask$RunnableExecuteAction.exec(ForkJoinTask.java:1402)\n\tat java.util.concurrent.ForkJoinTask.doExec(ForkJoinTask.java:289)\n\tat java.util.concurrent.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1056)\n\tat java.util.concurrent.ForkJoinPool.runWorker(ForkJoinPool.java:1692)\n\tat java.util.concurrent.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:157)"
          },
          "error": null,
          "skipped": false
        },
        {
          "name": "createTopic should be unable to create topic due to a TimeoutException",
          "classname": "io.lenses.core.kafka.topics.TopicCreateServiceTest",
          "time": 0,
          "failure": null,
          "error": null,
          "skipped": false
        }
      ]
    },
    {
      "time": 11,
      "tests": 2,
      "failures": 0,
      "errors": 0,
      "skipped": 0,
      "name": "io.lenses.core.license.LicenseFileUpdaterTest",
      "timestamp": "2020-07-26T21:54:51",
      "testcase": [
        {
          "name": "updates the license from the file",
          "classname": "io.lenses.core.license.LicenseFileUpdaterTest",
          "time": 10,
          "failure": null,
          "error": null,
          "skipped": false
        },
        {
          "name": "fails if the license content is invalid",
          "classname": "io.lenses.core.license.LicenseFileUpdaterTest",
          "time": 1,
          "failure": null,
          "error": null,
          "skipped": false
        }
      ]
    },
    {
      "time": 2221,
      "tests": 38,
      "failures": 0,
      "errors": 0,
      "skipped": 0,
      "name": "io.lenses.core.indexer.CatalogIndexTest",
      "timestamp": "2020-07-26T21:54:50",
      "testcase": [
        {
          "name": "CatalogIndex should return nothing when index empty",
          "classname": "io.lenses.core.indexer.CatalogIndexTest",
          "time": 302,
          "failure": null,
          "error": null,
          "skipped": false
        },
        {
          "name": "CatalogIndex should return result for Kafka topic with primitive schemas",
          "classname": "io.lenses.core.indexer.CatalogIndexTest",
          "time": 283,
          "failure": null,
          "error": null,
          "skipped": false
        },
        {
          "name": "CatalogIndex should should not match when the query does not match",
          "classname": "io.lenses.core.indexer.CatalogIndexTest",
          "time": 97,
          "failure": null,
          "error": null,
          "skipped": false
        },
        {
          "name": "CatalogIndex should include/exclude system entities with keyword: Some(table)",
          "classname": "io.lenses.core.indexer.CatalogIndexTest",
          "time": 41,
          "failure": null,
          "error": null,
          "skipped": false
        },
        {
          "name": "CatalogIndex should include/exclude system entities with keyword: None",
          "classname": "io.lenses.core.indexer.CatalogIndexTest",
          "time": 31,
          "failure": null,
          "error": null,
          "skipped": false
        },
        {
          "name": "CatalogIndex should sort Kafka topics by num records",
          "classname": "io.lenses.core.indexer.CatalogIndexTest",
          "time": 78,
          "failure": null,
          "error": null,
          "skipped": false
        },
        {
          "name": "CatalogIndex should sort Kafka topics by name",
          "classname": "io.lenses.core.indexer.CatalogIndexTest",
          "time": 73,
          "failure": null,
          "error": null,
          "skipped": false
        },
        {
          "name": "CatalogIndex should sort Kafka topics by name descending",
          "classname": "io.lenses.core.indexer.CatalogIndexTest",
          "time": 67,
          "failure": null,
          "error": null,
          "skipped": false
        },
        {
          "name": "CatalogIndex should sort datasets by sourceType",
          "classname": "io.lenses.core.indexer.CatalogIndexTest",
          "time": 75,
          "failure": null,
          "error": null,
          "skipped": false
        },
        {
          "name": "CatalogIndex should match fields (includeMetadata true)",
          "classname": "io.lenses.core.indexer.CatalogIndexTest",
          "time": 85,
          "failure": null,
          "error": null,
          "skipped": false
        },
        {
          "name": "CatalogIndex should match fields (includeMetadata false)",
          "classname": "io.lenses.core.indexer.CatalogIndexTest",
          "time": 32,
          "failure": null,
          "error": null,
          "skipped": false
        },
        {
          "name": "CatalogIndex should separate key/value fields with ancestors",
          "classname": "io.lenses.core.indexer.CatalogIndexTest",
          "time": 53,
          "failure": null,
          "error": null,
          "skipped": false
        },
        {
          "name": "CatalogIndex should pagination",
          "classname": "io.lenses.core.indexer.CatalogIndexTest",
          "time": 129,
          "failure": null,
          "error": null,
          "skipped": false
        },
        {
          "name": "CatalogIndex should combination of Kafka and ElasticSearch records, including policy matches",
          "classname": "io.lenses.core.indexer.CatalogIndexTest",
          "time": 50,
          "failure": null,
          "error": null,
          "skipped": false
        },
        {
          "name": "CatalogIndex should DatasetRemoved",
          "classname": "io.lenses.core.indexer.CatalogIndexTest",
          "time": 58,
          "failure": null,
          "error": null,
          "skipped": false
        },
        {
          "name": "CatalogIndex should ConnectionRemoved",
          "classname": "io.lenses.core.indexer.CatalogIndexTest",
          "time": 58,
          "failure": null,
          "error": null,
          "skipped": false
        },
        {
          "name": "CatalogIndex should DatasetChanged",
          "classname": "io.lenses.core.indexer.CatalogIndexTest",
          "time": 61,
          "failure": null,
          "error": null,
          "skipped": false
        },
        {
          "name": "CatalogIndex should filter by connection excludes connections that don't match filter",
          "classname": "io.lenses.core.indexer.CatalogIndexTest",
          "time": 54,
          "failure": null,
          "error": null,
          "skipped": false
        },
        {
          "name": "CatalogIndex should empty query returns all tables",
          "classname": "io.lenses.core.indexer.CatalogIndexTest",
          "time": 82,
          "failure": null,
          "error": null,
          "skipped": false
        },
        {
          "name": "CatalogIndex should return source types for entire search, not just current page",
          "classname": "io.lenses.core.indexer.CatalogIndexTest",
          "time": 64,
          "failure": null,
          "error": null,
          "skipped": false
        },
        {
          "name": "CatalogIndex should matching multi-word string",
          "classname": "io.lenses.core.indexer.CatalogIndexTest",
          "time": 47,
          "failure": null,
          "error": null,
          "skipped": false
        },
        {
          "name": "CatalogIndex should Table name camelCaseText matches query camel",
          "classname": "io.lenses.core.indexer.CatalogIndexTest",
          "time": 60,
          "failure": null,
          "error": null,
          "skipped": false
        },
        {
          "name": "CatalogIndex should Table name camelCaseText matches query case",
          "classname": "io.lenses.core.indexer.CatalogIndexTest",
          "time": 15,
          "failure": null,
          "error": null,
          "skipped": false
        },
        {
          "name": "CatalogIndex should Table name camelCaseText matches query text",
          "classname": "io.lenses.core.indexer.CatalogIndexTest",
          "time": 17,
          "failure": null,
          "error": null,
          "skipped": false
        },
        {
          "name": "CatalogIndex should Table name camelCaseText matches query camelCaseText",
          "classname": "io.lenses.core.indexer.CatalogIndexTest",
          "time": 23,
          "failure": null,
          "error": null,
          "skipped": false
        },
        {
          "name": "CatalogIndex should Table name camelCaseText matches query caseText",
          "classname": "io.lenses.core.indexer.CatalogIndexTest",
          "time": 17,
          "failure": null,
          "error": null,
          "skipped": false
        },
        {
          "name": "CatalogIndex should Table name dash-separated-text matches query dash",
          "classname": "io.lenses.core.indexer.CatalogIndexTest",
          "time": 15,
          "failure": null,
          "error": null,
          "skipped": false
        },
        {
          "name": "CatalogIndex should Table name dash-separated-text matches query separated",
          "classname": "io.lenses.core.indexer.CatalogIndexTest",
          "time": 19,
          "failure": null,
          "error": null,
          "skipped": false
        },
        {
          "name": "CatalogIndex should Table name dash-separated-text matches query text",
          "classname": "io.lenses.core.indexer.CatalogIndexTest",
          "time": 19,
          "failure": null,
          "error": null,
          "skipped": false
        },
        {
          "name": "CatalogIndex should Table name dash-separated-text matches query dash-separated-text",
          "classname": "io.lenses.core.indexer.CatalogIndexTest",
          "time": 21,
          "failure": null,
          "error": null,
          "skipped": false
        },
        {
          "name": "CatalogIndex should Table name dash-separated-text matches query separated-text",
          "classname": "io.lenses.core.indexer.CatalogIndexTest",
          "time": 18,
          "failure": null,
          "error": null,
          "skipped": false
        },
        {
          "name": "elastic matches query hidden",
          "classname": "io.lenses.core.indexer.CatalogIndexTest",
          "time": 14,
          "failure": null,
          "error": null,
          "skipped": false
        },
        {
          "name": "elastic matches query like",
          "classname": "io.lenses.core.indexer.CatalogIndexTest",
          "time": 14,
          "failure": null,
          "error": null,
          "skipped": false
        },
        {
          "name": "elastic matches query elastic",
          "classname": "io.lenses.core.indexer.CatalogIndexTest",
          "time": 16,
          "failure": null,
          "error": null,
          "skipped": false
        },
        {
          "name": "elastic",
          "classname": "io.lenses.core.indexer.CatalogIndexTest",
          "time": 31,
          "failure": null,
          "error": null,
          "skipped": false
        },
        {
          "name": "LIKE",
          "classname": "io.lenses.core.indexer.CatalogIndexTest",
          "time": 19,
          "failure": null,
          "error": null,
          "skipped": false
        },
        {
          "name": "CatalogIndex should Table name wildcard\\escape*char?test matches query wildcard\\escape*char?test",
          "classname": "io.lenses.core.indexer.CatalogIndexTest",
          "time": 40,
          "failure": null,
          "error": null,
          "skipped": false
        },
        {
          "name": "CatalogIndex should permissions",
          "classname": "io.lenses.core.indexer.CatalogIndexTest",
          "time": 42,
          "failure": null,
          "error": null,
          "skipped": false
        }
      ]
    },
    {
      "time": 141,
      "tests": 12,
      "failures": 0,
      "errors": 0,
      "skipped": 0,
      "name": "io.lenses.core.channels.publisher.webhook.loader.domain.WebHookChannelTest",
      "timestamp": "2020-07-26T21:54:41",
      "testcase": [
        {
          "name": "WebHookChannel should hasInsecureSSLConfig should should be true when `useHttps` and `insecure` are set",
          "classname": "io.lenses.core.channels.publisher.webhook.loader.domain.WebHookChannelTest",
          "time": 1,
          "failure": null,
          "error": null,
          "skipped": false
        },
        {
          "name": "WebHookChannel should hasInsecureSSLConfig should should be false when `insecure` is set but `useHttps` isn't",
          "classname": "io.lenses.core.channels.publisher.webhook.loader.domain.WebHookChannelTest",
          "time": 1,
          "failure": null,
          "error": null,
          "skipped": false
        },
        {
          "name": "WebHookChannel should hasInsecureSSLConfig should should be false `useHttps` is set but `insecure` is false",
          "classname": "io.lenses.core.channels.publisher.webhook.loader.domain.WebHookChannelTest",
          "time": 0,
          "failure": null,
          "error": null,
          "skipped": false
        },
        {
          "name": "RequestGeneration should forward error from path rendering",
          "classname": "io.lenses.core.channels.publisher.webhook.loader.domain.WebHookChannelTest",
          "time": 1,
          "failure": null,
          "error": null,
          "skipped": false
        },
        {
          "name": "RequestGeneration should forward error from body rendering",
          "classname": "io.lenses.core.channels.publisher.webhook.loader.domain.WebHookChannelTest",
          "time": 1,
          "failure": null,
          "error": null,
          "skipped": false
        },
        {
          "name": "RequestGeneration should forward error from headers rendering",
          "classname": "io.lenses.core.channels.publisher.webhook.loader.domain.WebHookChannelTest",
          "time": 2,
          "failure": null,
          "error": null,
          "skipped": false
        },
        {
          "name": "RequestGeneration should sets the https scheme when the web hook secure parameter is set to true",
          "classname": "io.lenses.core.channels.publisher.webhook.loader.domain.WebHookChannelTest",
          "time": 4,
          "failure": null,
          "error": null,
          "skipped": false
        },
        {
          "name": "RequestGeneration should sets the http scheme when the web hook secure parameter is set to false",
          "classname": "io.lenses.core.channels.publisher.webhook.loader.domain.WebHookChannelTest",
          "time": 0,
          "failure": null,
          "error": null,
          "skipped": false
        },
        {
          "name": "RequestGeneration should sets the port number when present",
          "classname": "io.lenses.core.channels.publisher.webhook.loader.domain.WebHookChannelTest",
          "time": 2,
          "failure": null,
          "error": null,
          "skipped": false
        },
        {
          "name": "RequestGeneration should sets the expected HTTP method",
          "classname": "io.lenses.core.channels.publisher.webhook.loader.domain.WebHookChannelTest",
          "time": 1,
          "failure": null,
          "error": null,
          "skipped": false
        },
        {
          "name": "RequestGeneration should sets the headers, with content type set at the entity level",
          "classname": "io.lenses.core.channels.publisher.webhook.loader.domain.WebHookChannelTest",
          "time": 126,
          "failure": null,
          "error": null,
          "skipped": false
        },
        {
          "name": "RequestGeneration should sets the supplied body",
          "classname": "io.lenses.core.channels.publisher.webhook.loader.domain.WebHookChannelTest",
          "time": 2,
          "failure": null,
          "error": null,
          "skipped": false
        }
      ]
    },
    {
      "time": 5,
      "tests": 3,
      "failures": 0,
      "errors": 0,
      "skipped": 0,
      "name": "io.lenses.core.kafka.consumer.KafkaConsumerImplTest",
      "timestamp": "2020-07-26T21:54:50",
      "testcase": [
        {
          "name": "beginningOffsets should translate properly",
          "classname": "io.lenses.core.kafka.consumer.KafkaConsumerImplTest",
          "time": 2,
          "failure": null,
          "error": null,
          "skipped": false
        },
        {
          "name": "endOffsets should translate properly",
          "classname": "io.lenses.core.kafka.consumer.KafkaConsumerImplTest",
          "time": 2,
          "failure": null,
          "error": null,
          "skipped": false
        },
        {
          "name": "offsetsForTimes should translate properly",
          "classname": "io.lenses.core.kafka.consumer.KafkaConsumerImplTest",
          "time": 1,
          "failure": null,
          "error": null,
          "skipped": false
        }
      ]
    },
    {
      "time": 89,
      "tests": 5,
      "failures": 0,
      "errors": 0,
      "skipped": 0,
      "name": "io.lenses.core.actors.BrokersStatusActorSpec",
      "timestamp": "2020-07-26T21:54:52",
      "testcase": [
        {
          "name": "GetBrokerState should discover new brokers when they are added to the cluster",
          "classname": "io.lenses.core.actors.BrokersStatusActorSpec",
          "time": 34,
          "failure": null,
          "error": null,
          "skipped": false
        },
        {
          "name": "GetBrokerState should notifies the broker data aggregator when a new broker is discovered",
          "classname": "io.lenses.core.actors.BrokersStatusActorSpec",
          "time": 12,
          "failure": null,
          "error": null,
          "skipped": false
        },
        {
          "name": "GetBrokerState should mark all brokers as inactive if the cluster is not reachable",
          "classname": "io.lenses.core.actors.BrokersStatusActorSpec",
          "time": 13,
          "failure": null,
          "error": null,
          "skipped": false
        },
        {
          "name": "GetBrokerState should remove brokers when these are no longer reachable",
          "classname": "io.lenses.core.actors.BrokersStatusActorSpec",
          "time": 17,
          "failure": null,
          "error": null,
          "skipped": false
        },
        {
          "name": "GetBrokerState should notifies the broker data aggregator when a new broker is no longer reachable",
          "classname": "io.lenses.core.actors.BrokersStatusActorSpec",
          "time": 13,
          "failure": null,
          "error": null,
          "skipped": false
        }
      ]
    },
    {
      "time": 864,
      "tests": 4,
      "failures": 0,
      "errors": 0,
      "skipped": 0,
      "name": "io.lenses.core.actors.ConnectDataAggregatorActorTest",
      "timestamp": "2020-07-26T21:54:43",
      "testcase": [
        {
          "name": "JMX state does not get set if isAlive is not true",
          "classname": "io.lenses.core.actors.ConnectDataAggregatorActorTest",
          "time": 122,
          "failure": null,
          "error": null,
          "skipped": false
        },
        {
          "name": "JMX state is set when isAlive is true",
          "classname": "io.lenses.core.actors.ConnectDataAggregatorActorTest",
          "time": 110,
          "failure": null,
          "error": null,
          "skipped": false
        },
        {
          "name": "receive all data on subscribe",
          "classname": "io.lenses.core.actors.ConnectDataAggregatorActorTest",
          "time": 250,
          "failure": null,
          "error": null,
          "skipped": false
        },
        {
          "name": "receive all data updates",
          "classname": "io.lenses.core.actors.ConnectDataAggregatorActorTest",
          "time": 381,
          "failure": null,
          "error": null,
          "skipped": false
        }
      ]
    },
    {
      "time": 160,
      "tests": 6,
      "failures": 0,
      "errors": 0,
      "skipped": 0,
      "name": "io.lenses.core.datasets.RepositoryDifferTest",
      "timestamp": "2020-07-26T21:54:43",
      "testcase": [
        {
          "name": "connectionEvents should emit ConnectDeleted events when previously existing connections are removed",
          "classname": "io.lenses.core.datasets.RepositoryDifferTest",
          "time": 50,
          "failure": null,
          "error": null,
          "skipped": false
        },
        {
          "name": "datasetEvents should emit DatasetRemoved events when previously seen tables are removed",
          "classname": "io.lenses.core.datasets.RepositoryDifferTest",
          "time": 53,
          "failure": null,
          "error": null,
          "skipped": false
        },
        {
          "name": "datasetEvents should not remove tables with the same name if they belong to another connection",
          "classname": "io.lenses.core.datasets.RepositoryDifferTest",
          "time": 19,
          "failure": null,
          "error": null,
          "skipped": false
        },
        {
          "name": "datasetEvents should emit NewDataset events when new tables are added",
          "classname": "io.lenses.core.datasets.RepositoryDifferTest",
          "time": 7,
          "failure": null,
          "error": null,
          "skipped": false
        },
        {
          "name": "datasetEvents should emit DatasetChanged events when relevant table properties change",
          "classname": "io.lenses.core.datasets.RepositoryDifferTest",
          "time": 26,
          "failure": null,
          "error": null,
          "skipped": false
        },
        {
          "name": "datasetEvents should emit no DatasetChanged events when Diff[T] instance is overriden to disregard certain fields",
          "classname": "io.lenses.core.datasets.RepositoryDifferTest",
          "time": 5,
          "failure": null,
          "error": null,
          "skipped": false
        }
      ]
    },
    {
      "time": 121,
      "tests": 10,
      "failures": 0,
      "errors": 0,
      "skipped": 0,
      "name": "io.lenses.core.alerting.AlertRuleServiceSpec",
      "timestamp": "2020-07-26T21:54:42",
      "testcase": [
        {
          "name": "AlertRuleService should getAlertRuleConditions should provide decoded conditions",
          "classname": "io.lenses.core.alerting.AlertRuleServiceSpec",
          "time": 32,
          "failure": null,
          "error": null,
          "skipped": false
        },
        {
          "name": "AlertRuleService should getAlertRuleConditions should provide no data produced conditions if license prohibits data SLA",
          "classname": "io.lenses.core.alerting.AlertRuleServiceSpec",
          "time": 17,
          "failure": null,
          "error": null,
          "skipped": false
        },
        {
          "name": "AlertRuleService should getRules should provide no data produced conditions if license prohibits data SLA",
          "classname": "io.lenses.core.alerting.AlertRuleServiceSpec",
          "time": 36,
          "failure": null,
          "error": null,
          "skipped": false
        },
        {
          "name": "AlertRuleService should does not return License alert",
          "classname": "io.lenses.core.alerting.AlertRuleServiceSpec",
          "time": 1,
          "failure": null,
          "error": null,
          "skipped": false
        },
        {
          "name": "AlertRuleService should does not return Connect related alert settings on empty connect cluster",
          "classname": "io.lenses.core.alerting.AlertRuleServiceSpec",
          "time": 2,
          "failure": null,
          "error": null,
          "skipped": false
        },
        {
          "name": "AlertRuleService should returns Connect related alert settings on non empty connect cluster",
          "classname": "io.lenses.core.alerting.AlertRuleServiceSpec",
          "time": 2,
          "failure": null,
          "error": null,
          "skipped": false
        },
        {
          "name": "AlertRuleService should return all the settings",
          "classname": "io.lenses.core.alerting.AlertRuleServiceSpec",
          "time": 1,
          "failure": null,
          "error": null,
          "skipped": false
        },
        {
          "name": "AlertRuleService should disable/enable setting",
          "classname": "io.lenses.core.alerting.AlertRuleServiceSpec",
          "time": 7,
          "failure": null,
          "error": null,
          "skipped": false
        },
        {
          "name": "AlertRuleService should add/remove condition",
          "classname": "io.lenses.core.alerting.AlertRuleServiceSpec",
          "time": 19,
          "failure": null,
          "error": null,
          "skipped": false
        },
        {
          "name": "AlertRuleService should validate state is preserved",
          "classname": "io.lenses.core.alerting.AlertRuleServiceSpec",
          "time": 4,
          "failure": null,
          "error": null,
          "skipped": false
        }
      ]
    },
    {
      "time": 10,
      "tests": 3,
      "failures": 0,
      "errors": 0,
      "skipped": 0,
      "name": "io.lenses.core.monitoring.actions.RaiseRequestHandlerAvgIdlePercentAlertsFnTest",
      "timestamp": "2020-07-26T21:54:38",
      "testcase": [
        {
          "name": "RaiseRequestHandlerAvgIdlePercentAlertsFn should raise a CRITICAL level alert when percentage is < 2%",
          "classname": "io.lenses.core.monitoring.actions.RaiseRequestHandlerAvgIdlePercentAlertsFnTest",
          "time": 9,
          "failure": null,
          "error": null,
          "skipped": false
        },
        {
          "name": "RaiseRequestHandlerAvgIdlePercentAlertsFn should raise a HIGH level alert when percentage is < 10%",
          "classname": "io.lenses.core.monitoring.actions.RaiseRequestHandlerAvgIdlePercentAlertsFnTest",
          "time": 0,
          "failure": null,
          "error": null,
          "skipped": false
        },
        {
          "name": "RaiseRequestHandlerAvgIdlePercentAlertsFn should raise an INFO alert then the idle percentage is ok on brokers",
          "classname": "io.lenses.core.monitoring.actions.RaiseRequestHandlerAvgIdlePercentAlertsFnTest",
          "time": 1,
          "failure": null,
          "error": null,
          "skipped": false
        }
      ]
    },
    {
      "time": 7,
      "tests": 3,
      "failures": 0,
      "errors": 0,
      "skipped": 0,
      "name": "io.lenses.core.monitoring.actions.RaiseSchemaRegistryAlertsFnTest",
      "timestamp": "2020-07-26T21:54:46",
      "testcase": [
        {
          "name": "RaiseSchemaRegistryAlertsFn should raise an alert when the sr is down",
          "classname": "io.lenses.core.monitoring.actions.RaiseSchemaRegistryAlertsFnTest",
          "time": 4,
          "failure": null,
          "error": null,
          "skipped": false
        },
        {
          "name": "RaiseSchemaRegistryAlertsFn should not raise an alert again",
          "classname": "io.lenses.core.monitoring.actions.RaiseSchemaRegistryAlertsFnTest",
          "time": 2,
          "failure": null,
          "error": null,
          "skipped": false
        },
        {
          "name": "RaiseSchemaRegistryAlertsFn should raise an alert when the sr is online and another one is down",
          "classname": "io.lenses.core.monitoring.actions.RaiseSchemaRegistryAlertsFnTest",
          "time": 1,
          "failure": null,
          "error": null,
          "skipped": false
        }
      ]
    },
    {
      "time": 6,
      "tests": 3,
      "failures": 0,
      "errors": 0,
      "skipped": 0,
      "name": "io.lenses.core.monitoring.actions.RaiseFileOpenDescriptorsAlertsFnTest",
      "timestamp": "2020-07-26T21:54:38",
      "testcase": [
        {
          "name": "RaiseFileOpenDescriptorsAlertsFn should raise a CRITICAL level alert when File-open descriptors > 90% of capacity on brokers",
          "classname": "io.lenses.core.monitoring.actions.RaiseFileOpenDescriptorsAlertsFnTest",
          "time": 3,
          "failure": null,
          "error": null,
          "skipped": false
        },
        {
          "name": "RaiseFileOpenDescriptorsAlertsFn should raise a HIGH level alert when File-open descriptors > 80% of capacity on brokers",
          "classname": "io.lenses.core.monitoring.actions.RaiseFileOpenDescriptorsAlertsFnTest",
          "time": 1,
          "failure": null,
          "error": null,
          "skipped": false
        },
        {
          "name": "RaiseFileOpenDescriptorsAlertsFn should raise an INFO alert when File-open descriptors is ok of capacity on brokers",
          "classname": "io.lenses.core.monitoring.actions.RaiseFileOpenDescriptorsAlertsFnTest",
          "time": 2,
          "failure": null,
          "error": null,
          "skipped": false
        }
      ]
    },
    {
      "time": 645,
      "tests": 6,
      "failures": 0,
      "errors": 0,
      "skipped": 1,
      "name": "io.lenses.core.actors.AlertActorSpec",
      "timestamp": "2020-07-26T21:54:42",
      "testcase": [
        {
          "name": "AlertsActor should keep last 100 alerts only",
          "classname": "io.lenses.core.actors.AlertActorSpec",
          "time": 59,
          "failure": null,
          "error": null,
          "skipped": false
        },
        {
          "name": "AlertsActor should give all the messages received only",
          "classname": "io.lenses.core.actors.AlertActorSpec",
          "time": 1,
          "failure": null,
          "error": null,
          "skipped": true
        },
        {
          "name": "AlertsActor should forward the alert to 'subscriber'",
          "classname": "io.lenses.core.actors.AlertActorSpec",
          "time": 17,
          "failure": null,
          "error": null,
          "skipped": false
        },
        {
          "name": "AlertsActor should does not forward the alert to 'subscriber' if alerts are disabled",
          "classname": "io.lenses.core.actors.AlertActorSpec",
          "time": 263,
          "failure": null,
          "error": null,
          "skipped": false
        },
        {
          "name": "AlertsActor should forward the alert to alerting system if configured",
          "classname": "io.lenses.core.actors.AlertActorSpec",
          "time": 43,
          "failure": null,
          "error": null,
          "skipped": false
        },
        {
          "name": "AlertsActor should does not forward the alert to alerting system if alerts disabled",
          "classname": "io.lenses.core.actors.AlertActorSpec",
          "time": 264,
          "failure": null,
          "error": null,
          "skipped": false
        }
      ]
    },
    {
      "time": 45214,
      "tests": 4,
      "failures": 3,
      "errors": 0,
      "skipped": 0,
      "name": "io.lenses.core.kafka.topics.TopicMessageResenderTest",
      "timestamp": "2020-07-26T21:54:37",
      "testcase": [
        {
          "name": "resend should copy existing String message",
          "classname": "io.lenses.core.kafka.topics.TopicMessageResenderTest",
          "time": 10163,
          "failure": {
            "message": null,
            "type": "java.util.concurrent.TimeoutException",
            "stackTrace": "java.util.concurrent.TimeoutException\n\tat org.apache.kafka.common.internals.KafkaFutureImpl$SingleWaiter.await(KafkaFutureImpl.java:108)\n\tat org.apache.kafka.common.internals.KafkaFutureImpl.get(KafkaFutureImpl.java:272)\n\tat io.lenses.test.kafka.cluster.Cluster.createTopic(Cluster.scala:44)\n\tat io.lenses.test.kafka.cluster.Cluster.createTopic$(Cluster.scala:42)\n\tat io.lenses.core.kafka.topics.TopicMessageResenderTest.createTopic(TopicMessageResenderTest.scala:30)\n\tat io.lenses.core.kafka.topics.TopicMessageResenderTest.createUniqueTopic(TopicMessageResenderTest.scala:112)\n\tat io.lenses.core.kafka.topics.TopicMessageResenderTest.$anonfun$new$1(TopicMessageResenderTest.scala:48)\n\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n\tat org.scalatest.OutcomeOf.outcomeOf(OutcomeOf.scala:85)\n\tat org.scalatest.OutcomeOf.outcomeOf$(OutcomeOf.scala:83)\n\tat org.scalatest.OutcomeOf$.outcomeOf(OutcomeOf.scala:104)\n\tat org.scalatest.Transformer.apply(Transformer.scala:22)\n\tat org.scalatest.Transformer.apply(Transformer.scala:20)\n\tat org.scalatest.flatspec.AnyFlatSpecLike$$anon$5.apply(AnyFlatSpecLike.scala:1683)\n\tat org.scalatest.TestSuite.withFixture(TestSuite.scala:196)\n\tat org.scalatest.TestSuite.withFixture$(TestSuite.scala:195)\n\tat org.scalatest.flatspec.AnyFlatSpec.withFixture(AnyFlatSpec.scala:1685)\n\tat org.scalatest.flatspec.AnyFlatSpecLike.invokeWithFixture$1(AnyFlatSpecLike.scala:1681)\n\tat org.scalatest.flatspec.AnyFlatSpecLike.$anonfun$runTest$1(AnyFlatSpecLike.scala:1693)\n\tat org.scalatest.SuperEngine.runTestImpl(Engine.scala:306)\n\tat org.scalatest.flatspec.AnyFlatSpecLike.runTest(AnyFlatSpecLike.scala:1693)\n\tat org.scalatest.flatspec.AnyFlatSpecLike.runTest$(AnyFlatSpecLike.scala:1675)\n\tat org.scalatest.flatspec.AnyFlatSpec.runTest(AnyFlatSpec.scala:1685)\n\tat org.scalatest.flatspec.AnyFlatSpecLike.$anonfun$runTests$1(AnyFlatSpecLike.scala:1751)\n\tat org.scalatest.SuperEngine.$anonfun$runTestsInBranch$1(Engine.scala:413)\n\tat scala.collection.immutable.List.foreach(List.scala:392)\n\tat org.scalatest.SuperEngine.traverseSubNodes$1(Engine.scala:401)\n\tat org.scalatest.SuperEngine.runTestsInBranch(Engine.scala:390)\n\tat org.scalatest.SuperEngine.$anonfun$runTestsInBranch$1(Engine.scala:427)\n\tat scala.collection.immutable.List.foreach(List.scala:392)\n\tat org.scalatest.SuperEngine.traverseSubNodes$1(Engine.scala:401)\n\tat org.scalatest.SuperEngine.runTestsInBranch(Engine.scala:396)\n\tat org.scalatest.SuperEngine.runTestsImpl(Engine.scala:475)\n\tat org.scalatest.flatspec.AnyFlatSpecLike.runTests(AnyFlatSpecLike.scala:1751)\n\tat org.scalatest.flatspec.AnyFlatSpecLike.runTests$(AnyFlatSpecLike.scala:1750)\n\tat org.scalatest.flatspec.AnyFlatSpec.runTests(AnyFlatSpec.scala:1685)\n\tat org.scalatest.Suite.run(Suite.scala:1112)\n\tat org.scalatest.Suite.run$(Suite.scala:1094)\n\tat org.scalatest.flatspec.AnyFlatSpec.org$scalatest$flatspec$AnyFlatSpecLike$$super$run(AnyFlatSpec.scala:1685)\n\tat org.scalatest.flatspec.AnyFlatSpecLike.$anonfun$run$1(AnyFlatSpecLike.scala:1796)\n\tat org.scalatest.SuperEngine.runImpl(Engine.scala:535)\n\tat org.scalatest.flatspec.AnyFlatSpecLike.run(AnyFlatSpecLike.scala:1796)\n\tat org.scalatest.flatspec.AnyFlatSpecLike.run$(AnyFlatSpecLike.scala:1794)\n\tat org.scalatest.flatspec.AnyFlatSpec.run(AnyFlatSpec.scala:1685)\n\tat org.scalatest.tools.Framework.org$scalatest$tools$Framework$$runSuite(Framework.scala:318)\n\tat org.scalatest.tools.Framework$ScalaTestTask.execute(Framework.scala:513)\n\tat sbt.TestRunner.runTest$1(TestFramework.scala:139)\n\tat sbt.TestRunner.run(TestFramework.scala:154)\n\tat sbt.TestFramework$$anon$3$$anonfun$$lessinit$greater$1.$anonfun$apply$1(TestFramework.scala:317)\n\tat sbt.TestFramework$.sbt$TestFramework$$withContextLoader(TestFramework.scala:277)\n\tat sbt.TestFramework$$anon$3$$anonfun$$lessinit$greater$1.apply(TestFramework.scala:317)\n\tat sbt.TestFramework$$anon$3$$anonfun$$lessinit$greater$1.apply(TestFramework.scala:317)\n\tat sbt.TestFunction.apply(TestFramework.scala:329)\n\tat sbt.Tests$.$anonfun$toTask$1(Tests.scala:311)\n\tat sbt.std.Transform$$anon$3.$anonfun$apply$2(Transform.scala:46)\n\tat sbt.std.Transform$$anon$4.work(Transform.scala:67)\n\tat sbt.Execute.$anonfun$submit$2(Execute.scala:281)\n\tat sbt.internal.util.ErrorHandling$.wideConvert(ErrorHandling.scala:19)\n\tat sbt.Execute.work(Execute.scala:290)\n\tat sbt.Execute.$anonfun$submit$1(Execute.scala:281)\n\tat sbt.ConcurrentRestrictions$$anon$4.$anonfun$submitValid$1(ConcurrentRestrictions.scala:178)\n\tat sbt.CompletionService$$anon$2.call(CompletionService.scala:37)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:748)"
          },
          "error": null,
          "skipped": false
        },
        {
          "name": "resend should fail when topic does not exist",
          "classname": "io.lenses.core.kafka.topics.TopicMessageResenderTest",
          "time": 15047,
          "failure": null,
          "error": null,
          "skipped": false
        },
        {
          "name": "resend should fail when partition does not exist",
          "classname": "io.lenses.core.kafka.topics.TopicMessageResenderTest",
          "time": 10003,
          "failure": {
            "message": null,
            "type": "java.util.concurrent.TimeoutException",
            "stackTrace": "java.util.concurrent.TimeoutException\n\tat org.apache.kafka.common.internals.KafkaFutureImpl$SingleWaiter.await(KafkaFutureImpl.java:108)\n\tat org.apache.kafka.common.internals.KafkaFutureImpl.get(KafkaFutureImpl.java:272)\n\tat io.lenses.test.kafka.cluster.Cluster.createTopic(Cluster.scala:44)\n\tat io.lenses.test.kafka.cluster.Cluster.createTopic$(Cluster.scala:42)\n\tat io.lenses.core.kafka.topics.TopicMessageResenderTest.createTopic(TopicMessageResenderTest.scala:30)\n\tat io.lenses.core.kafka.topics.TopicMessageResenderTest.createUniqueTopic(TopicMessageResenderTest.scala:112)\n\tat io.lenses.core.kafka.topics.TopicMessageResenderTest.$anonfun$new$5(TopicMessageResenderTest.scala:78)\n\tat org.scalatest.OutcomeOf.outcomeOf(OutcomeOf.scala:85)\n\tat org.scalatest.OutcomeOf.outcomeOf$(OutcomeOf.scala:83)\n\tat org.scalatest.OutcomeOf$.outcomeOf(OutcomeOf.scala:104)\n\tat org.scalatest.Transformer.apply(Transformer.scala:22)\n\tat org.scalatest.Transformer.apply(Transformer.scala:20)\n\tat org.scalatest.flatspec.AnyFlatSpecLike$$anon$5.apply(AnyFlatSpecLike.scala:1683)\n\tat org.scalatest.TestSuite.withFixture(TestSuite.scala:196)\n\tat org.scalatest.TestSuite.withFixture$(TestSuite.scala:195)\n\tat org.scalatest.flatspec.AnyFlatSpec.withFixture(AnyFlatSpec.scala:1685)\n\tat org.scalatest.flatspec.AnyFlatSpecLike.invokeWithFixture$1(AnyFlatSpecLike.scala:1681)\n\tat org.scalatest.flatspec.AnyFlatSpecLike.$anonfun$runTest$1(AnyFlatSpecLike.scala:1693)\n\tat org.scalatest.SuperEngine.runTestImpl(Engine.scala:306)\n\tat org.scalatest.flatspec.AnyFlatSpecLike.runTest(AnyFlatSpecLike.scala:1693)\n\tat org.scalatest.flatspec.AnyFlatSpecLike.runTest$(AnyFlatSpecLike.scala:1675)\n\tat org.scalatest.flatspec.AnyFlatSpec.runTest(AnyFlatSpec.scala:1685)\n\tat org.scalatest.flatspec.AnyFlatSpecLike.$anonfun$runTests$1(AnyFlatSpecLike.scala:1751)\n\tat org.scalatest.SuperEngine.$anonfun$runTestsInBranch$1(Engine.scala:413)\n\tat scala.collection.immutable.List.foreach(List.scala:392)\n\tat org.scalatest.SuperEngine.traverseSubNodes$1(Engine.scala:401)\n\tat org.scalatest.SuperEngine.runTestsInBranch(Engine.scala:390)\n\tat org.scalatest.SuperEngine.$anonfun$runTestsInBranch$1(Engine.scala:427)\n\tat scala.collection.immutable.List.foreach(List.scala:392)\n\tat org.scalatest.SuperEngine.traverseSubNodes$1(Engine.scala:401)\n\tat org.scalatest.SuperEngine.runTestsInBranch(Engine.scala:396)\n\tat org.scalatest.SuperEngine.runTestsImpl(Engine.scala:475)\n\tat org.scalatest.flatspec.AnyFlatSpecLike.runTests(AnyFlatSpecLike.scala:1751)\n\tat org.scalatest.flatspec.AnyFlatSpecLike.runTests$(AnyFlatSpecLike.scala:1750)\n\tat org.scalatest.flatspec.AnyFlatSpec.runTests(AnyFlatSpec.scala:1685)\n\tat org.scalatest.Suite.run(Suite.scala:1112)\n\tat org.scalatest.Suite.run$(Suite.scala:1094)\n\tat org.scalatest.flatspec.AnyFlatSpec.org$scalatest$flatspec$AnyFlatSpecLike$$super$run(AnyFlatSpec.scala:1685)\n\tat org.scalatest.flatspec.AnyFlatSpecLike.$anonfun$run$1(AnyFlatSpecLike.scala:1796)\n\tat org.scalatest.SuperEngine.runImpl(Engine.scala:535)\n\tat org.scalatest.flatspec.AnyFlatSpecLike.run(AnyFlatSpecLike.scala:1796)\n\tat org.scalatest.flatspec.AnyFlatSpecLike.run$(AnyFlatSpecLike.scala:1794)\n\tat org.scalatest.flatspec.AnyFlatSpec.run(AnyFlatSpec.scala:1685)\n\tat org.scalatest.tools.Framework.org$scalatest$tools$Framework$$runSuite(Framework.scala:318)\n\tat org.scalatest.tools.Framework$ScalaTestTask.execute(Framework.scala:513)\n\tat sbt.TestRunner.runTest$1(TestFramework.scala:139)\n\tat sbt.TestRunner.run(TestFramework.scala:154)\n\tat sbt.TestFramework$$anon$3$$anonfun$$lessinit$greater$1.$anonfun$apply$1(TestFramework.scala:317)\n\tat sbt.TestFramework$.sbt$TestFramework$$withContextLoader(TestFramework.scala:277)\n\tat sbt.TestFramework$$anon$3$$anonfun$$lessinit$greater$1.apply(TestFramework.scala:317)\n\tat sbt.TestFramework$$anon$3$$anonfun$$lessinit$greater$1.apply(TestFramework.scala:317)\n\tat sbt.TestFunction.apply(TestFramework.scala:329)\n\tat sbt.Tests$.$anonfun$toTask$1(Tests.scala:311)\n\tat sbt.std.Transform$$anon$3.$anonfun$apply$2(Transform.scala:46)\n\tat sbt.std.Transform$$anon$4.work(Transform.scala:67)\n\tat sbt.Execute.$anonfun$submit$2(Execute.scala:281)\n\tat sbt.internal.util.ErrorHandling$.wideConvert(ErrorHandling.scala:19)\n\tat sbt.Execute.work(Execute.scala:290)\n\tat sbt.Execute.$anonfun$submit$1(Execute.scala:281)\n\tat sbt.ConcurrentRestrictions$$anon$4.$anonfun$submitValid$1(ConcurrentRestrictions.scala:178)\n\tat sbt.CompletionService$$anon$2.call(CompletionService.scala:37)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:748)"
          },
          "error": null,
          "skipped": false
        },
        {
          "name": "resend should fail when offset out of bounds",
          "classname": "io.lenses.core.kafka.topics.TopicMessageResenderTest",
          "time": 10001,
          "failure": {
            "message": null,
            "type": "java.util.concurrent.TimeoutException",
            "stackTrace": "java.util.concurrent.TimeoutException\n\tat org.apache.kafka.common.internals.KafkaFutureImpl$SingleWaiter.await(KafkaFutureImpl.java:108)\n\tat org.apache.kafka.common.internals.KafkaFutureImpl.get(KafkaFutureImpl.java:272)\n\tat io.lenses.test.kafka.cluster.Cluster.createTopic(Cluster.scala:44)\n\tat io.lenses.test.kafka.cluster.Cluster.createTopic$(Cluster.scala:42)\n\tat io.lenses.core.kafka.topics.TopicMessageResenderTest.createTopic(TopicMessageResenderTest.scala:30)\n\tat io.lenses.core.kafka.topics.TopicMessageResenderTest.createUniqueTopic(TopicMessageResenderTest.scala:112)\n\tat io.lenses.core.kafka.topics.TopicMessageResenderTest.$anonfun$new$7(TopicMessageResenderTest.scala:91)\n\tat org.scalatest.OutcomeOf.outcomeOf(OutcomeOf.scala:85)\n\tat org.scalatest.OutcomeOf.outcomeOf$(OutcomeOf.scala:83)\n\tat org.scalatest.OutcomeOf$.outcomeOf(OutcomeOf.scala:104)\n\tat org.scalatest.Transformer.apply(Transformer.scala:22)\n\tat org.scalatest.Transformer.apply(Transformer.scala:20)\n\tat org.scalatest.flatspec.AnyFlatSpecLike$$anon$5.apply(AnyFlatSpecLike.scala:1683)\n\tat org.scalatest.TestSuite.withFixture(TestSuite.scala:196)\n\tat org.scalatest.TestSuite.withFixture$(TestSuite.scala:195)\n\tat org.scalatest.flatspec.AnyFlatSpec.withFixture(AnyFlatSpec.scala:1685)\n\tat org.scalatest.flatspec.AnyFlatSpecLike.invokeWithFixture$1(AnyFlatSpecLike.scala:1681)\n\tat org.scalatest.flatspec.AnyFlatSpecLike.$anonfun$runTest$1(AnyFlatSpecLike.scala:1693)\n\tat org.scalatest.SuperEngine.runTestImpl(Engine.scala:306)\n\tat org.scalatest.flatspec.AnyFlatSpecLike.runTest(AnyFlatSpecLike.scala:1693)\n\tat org.scalatest.flatspec.AnyFlatSpecLike.runTest$(AnyFlatSpecLike.scala:1675)\n\tat org.scalatest.flatspec.AnyFlatSpec.runTest(AnyFlatSpec.scala:1685)\n\tat org.scalatest.flatspec.AnyFlatSpecLike.$anonfun$runTests$1(AnyFlatSpecLike.scala:1751)\n\tat org.scalatest.SuperEngine.$anonfun$runTestsInBranch$1(Engine.scala:413)\n\tat scala.collection.immutable.List.foreach(List.scala:392)\n\tat org.scalatest.SuperEngine.traverseSubNodes$1(Engine.scala:401)\n\tat org.scalatest.SuperEngine.runTestsInBranch(Engine.scala:390)\n\tat org.scalatest.SuperEngine.$anonfun$runTestsInBranch$1(Engine.scala:427)\n\tat scala.collection.immutable.List.foreach(List.scala:392)\n\tat org.scalatest.SuperEngine.traverseSubNodes$1(Engine.scala:401)\n\tat org.scalatest.SuperEngine.runTestsInBranch(Engine.scala:396)\n\tat org.scalatest.SuperEngine.runTestsImpl(Engine.scala:475)\n\tat org.scalatest.flatspec.AnyFlatSpecLike.runTests(AnyFlatSpecLike.scala:1751)\n\tat org.scalatest.flatspec.AnyFlatSpecLike.runTests$(AnyFlatSpecLike.scala:1750)\n\tat org.scalatest.flatspec.AnyFlatSpec.runTests(AnyFlatSpec.scala:1685)\n\tat org.scalatest.Suite.run(Suite.scala:1112)\n\tat org.scalatest.Suite.run$(Suite.scala:1094)\n\tat org.scalatest.flatspec.AnyFlatSpec.org$scalatest$flatspec$AnyFlatSpecLike$$super$run(AnyFlatSpec.scala:1685)\n\tat org.scalatest.flatspec.AnyFlatSpecLike.$anonfun$run$1(AnyFlatSpecLike.scala:1796)\n\tat org.scalatest.SuperEngine.runImpl(Engine.scala:535)\n\tat org.scalatest.flatspec.AnyFlatSpecLike.run(AnyFlatSpecLike.scala:1796)\n\tat org.scalatest.flatspec.AnyFlatSpecLike.run$(AnyFlatSpecLike.scala:1794)\n\tat org.scalatest.flatspec.AnyFlatSpec.run(AnyFlatSpec.scala:1685)\n\tat org.scalatest.tools.Framework.org$scalatest$tools$Framework$$runSuite(Framework.scala:318)\n\tat org.scalatest.tools.Framework$ScalaTestTask.execute(Framework.scala:513)\n\tat sbt.TestRunner.runTest$1(TestFramework.scala:139)\n\tat sbt.TestRunner.run(TestFramework.scala:154)\n\tat sbt.TestFramework$$anon$3$$anonfun$$lessinit$greater$1.$anonfun$apply$1(TestFramework.scala:317)\n\tat sbt.TestFramework$.sbt$TestFramework$$withContextLoader(TestFramework.scala:277)\n\tat sbt.TestFramework$$anon$3$$anonfun$$lessinit$greater$1.apply(TestFramework.scala:317)\n\tat sbt.TestFramework$$anon$3$$anonfun$$lessinit$greater$1.apply(TestFramework.scala:317)\n\tat sbt.TestFunction.apply(TestFramework.scala:329)\n\tat sbt.Tests$.$anonfun$toTask$1(Tests.scala:311)\n\tat sbt.std.Transform$$anon$3.$anonfun$apply$2(Transform.scala:46)\n\tat sbt.std.Transform$$anon$4.work(Transform.scala:67)\n\tat sbt.Execute.$anonfun$submit$2(Execute.scala:281)\n\tat sbt.internal.util.ErrorHandling$.wideConvert(ErrorHandling.scala:19)\n\tat sbt.Execute.work(Execute.scala:290)\n\tat sbt.Execute.$anonfun$submit$1(Execute.scala:281)\n\tat sbt.ConcurrentRestrictions$$anon$4.$anonfun$submitValid$1(ConcurrentRestrictions.scala:178)\n\tat sbt.CompletionService$$anon$2.call(CompletionService.scala:37)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:748)"
          },
          "error": null,
          "skipped": false
        }
      ]
    },
    {
      "time": 3,
      "tests": 1,
      "failures": 0,
      "errors": 0,
      "skipped": 0,
      "name": "io.lenses.core.monitoring.actions.RaiseLeaderImbalanceAlertFnTest",
      "timestamp": "2020-07-26T21:54:52",
      "testcase": [
        {
          "name": "RaiseLeaderImbalanceAlert should Send an info alert",
          "classname": "io.lenses.core.monitoring.actions.RaiseLeaderImbalanceAlertFnTest",
          "time": 3,
          "failure": null,
          "error": null,
          "skipped": false
        }
      ]
    },
    {
      "time": 648077,
      "tests": 2,
      "failures": 1,
      "errors": 0,
      "skipped": 0,
      "name": "io.lenses.core.kafka.KafkaBrokersMetadataSpec",
      "timestamp": "2020-07-26T21:54:45",
      "testcase": [
        {
          "name": "returns the broker information from zookeeper",
          "classname": "io.lenses.core.kafka.KafkaBrokersMetadataSpec",
          "time": 648044,
          "failure": {
            "message": "KeeperErrorCode = ConnectionLoss for /brokers/ids",
            "type": "org.apache.zookeeper.KeeperException$ConnectionLossException",
            "stackTrace": "org.apache.zookeeper.KeeperException$ConnectionLossException: KeeperErrorCode = ConnectionLoss for /brokers/ids\n\tat org.apache.zookeeper.KeeperException.create(KeeperException.java:99)\n\tat org.apache.zookeeper.KeeperException.create(KeeperException.java:51)\n\tat org.apache.zookeeper.ZooKeeper.getChildren(ZooKeeper.java:2595)\n\tat org.apache.curator.framework.imps.GetChildrenBuilderImpl$3.call(GetChildrenBuilderImpl.java:242)\n\tat org.apache.curator.framework.imps.GetChildrenBuilderImpl$3.call(GetChildrenBuilderImpl.java:231)\n\tat org.apache.curator.connection.StandardConnectionHandlingPolicy.callWithRetry(StandardConnectionHandlingPolicy.java:64)\n\tat org.apache.curator.RetryLoop.callWithRetry(RetryLoop.java:100)\n\tat org.apache.curator.framework.imps.GetChildrenBuilderImpl.pathInForeground(GetChildrenBuilderImpl.java:228)\n\tat org.apache.curator.framework.imps.GetChildrenBuilderImpl.forPath(GetChildrenBuilderImpl.java:219)\n\tat org.apache.curator.framework.imps.GetChildrenBuilderImpl.forPath(GetChildrenBuilderImpl.java:41)\n\tat io.lenses.core.kafka.KafkaBrokersMetadata$.getBrokers(KafkaBrokersMetadata.scala:42)\n\tat io.lenses.core.kafka.KafkaBrokersMetadataSpec.$anonfun$new$1(KafkaBrokersMetadataSpec.scala:35)\n\tat org.scalatest.OutcomeOf.outcomeOf(OutcomeOf.scala:85)\n\tat org.scalatest.OutcomeOf.outcomeOf$(OutcomeOf.scala:83)\n\tat org.scalatest.OutcomeOf$.outcomeOf(OutcomeOf.scala:104)\n\tat org.scalatest.Transformer.apply(Transformer.scala:22)\n\tat org.scalatest.Transformer.apply(Transformer.scala:20)\n\tat org.scalatest.funsuite.AnyFunSuiteLike$$anon$1.apply(AnyFunSuiteLike.scala:189)\n\tat org.scalatest.TestSuite.withFixture(TestSuite.scala:196)\n\tat org.scalatest.TestSuite.withFixture$(TestSuite.scala:195)\n\tat org.scalatest.funsuite.AnyFunSuite.withFixture(AnyFunSuite.scala:1562)\n\tat org.scalatest.funsuite.AnyFunSuiteLike.invokeWithFixture$1(AnyFunSuiteLike.scala:187)\n\tat org.scalatest.funsuite.AnyFunSuiteLike.$anonfun$runTest$1(AnyFunSuiteLike.scala:199)\n\tat org.scalatest.SuperEngine.runTestImpl(Engine.scala:306)\n\tat org.scalatest.funsuite.AnyFunSuiteLike.runTest(AnyFunSuiteLike.scala:199)\n\tat org.scalatest.funsuite.AnyFunSuiteLike.runTest$(AnyFunSuiteLike.scala:181)\n\tat org.scalatest.funsuite.AnyFunSuite.runTest(AnyFunSuite.scala:1562)\n\tat org.scalatest.funsuite.AnyFunSuiteLike.$anonfun$runTests$1(AnyFunSuiteLike.scala:232)\n\tat org.scalatest.SuperEngine.$anonfun$runTestsInBranch$1(Engine.scala:413)\n\tat scala.collection.immutable.List.foreach(List.scala:392)\n\tat org.scalatest.SuperEngine.traverseSubNodes$1(Engine.scala:401)\n\tat org.scalatest.SuperEngine.runTestsInBranch(Engine.scala:396)\n\tat org.scalatest.SuperEngine.runTestsImpl(Engine.scala:475)\n\tat org.scalatest.funsuite.AnyFunSuiteLike.runTests(AnyFunSuiteLike.scala:232)\n\tat org.scalatest.funsuite.AnyFunSuiteLike.runTests$(AnyFunSuiteLike.scala:231)\n\tat org.scalatest.funsuite.AnyFunSuite.runTests(AnyFunSuite.scala:1562)\n\tat org.scalatest.Suite.run(Suite.scala:1112)\n\tat org.scalatest.Suite.run$(Suite.scala:1094)\n\tat org.scalatest.funsuite.AnyFunSuite.org$scalatest$funsuite$AnyFunSuiteLike$$super$run(AnyFunSuite.scala:1562)\n\tat org.scalatest.funsuite.AnyFunSuiteLike.$anonfun$run$1(AnyFunSuiteLike.scala:236)\n\tat org.scalatest.SuperEngine.runImpl(Engine.scala:535)\n\tat org.scalatest.funsuite.AnyFunSuiteLike.run(AnyFunSuiteLike.scala:236)\n\tat org.scalatest.funsuite.AnyFunSuiteLike.run$(AnyFunSuiteLike.scala:235)\n\tat io.lenses.core.kafka.KafkaBrokersMetadataSpec.org$scalatest$BeforeAndAfterAll$$super$run(KafkaBrokersMetadataSpec.scala:18)\n\tat org.scalatest.BeforeAndAfterAll.liftedTree1$1(BeforeAndAfterAll.scala:213)\n\tat org.scalatest.BeforeAndAfterAll.run(BeforeAndAfterAll.scala:210)\n\tat org.scalatest.BeforeAndAfterAll.run$(BeforeAndAfterAll.scala:208)\n\tat io.lenses.core.kafka.KafkaBrokersMetadataSpec.run(KafkaBrokersMetadataSpec.scala:18)\n\tat org.scalatest.tools.Framework.org$scalatest$tools$Framework$$runSuite(Framework.scala:318)\n\tat org.scalatest.tools.Framework$ScalaTestTask.execute(Framework.scala:513)\n\tat sbt.TestRunner.runTest$1(TestFramework.scala:139)\n\tat sbt.TestRunner.run(TestFramework.scala:154)\n\tat sbt.TestFramework$$anon$3$$anonfun$$lessinit$greater$1.$anonfun$apply$1(TestFramework.scala:317)\n\tat sbt.TestFramework$.sbt$TestFramework$$withContextLoader(TestFramework.scala:277)\n\tat sbt.TestFramework$$anon$3$$anonfun$$lessinit$greater$1.apply(TestFramework.scala:317)\n\tat sbt.TestFramework$$anon$3$$anonfun$$lessinit$greater$1.apply(TestFramework.scala:317)\n\tat sbt.TestFunction.apply(TestFramework.scala:329)\n\tat sbt.Tests$.$anonfun$toTask$1(Tests.scala:311)\n\tat sbt.std.Transform$$anon$3.$anonfun$apply$2(Transform.scala:46)\n\tat sbt.std.Transform$$anon$4.work(Transform.scala:67)\n\tat sbt.Execute.$anonfun$submit$2(Execute.scala:281)\n\tat sbt.internal.util.ErrorHandling$.wideConvert(ErrorHandling.scala:19)\n\tat sbt.Execute.work(Execute.scala:290)\n\tat sbt.Execute.$anonfun$submit$1(Execute.scala:281)\n\tat sbt.ConcurrentRestrictions$$anon$4.$anonfun$submitValid$1(ConcurrentRestrictions.scala:178)\n\tat sbt.CompletionService$$anon$2.call(CompletionService.scala:37)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:748)"
          },
          "error": null,
          "skipped": false
        },
        {
          "name": "deserielize broker metadata information from zookeeper",
          "classname": "io.lenses.core.kafka.KafkaBrokersMetadataSpec",
          "time": 33,
          "failure": null,
          "error": null,
          "skipped": false
        }
      ]
    },
    {
      "time": 1,
      "tests": 1,
      "failures": 0,
      "errors": 0,
      "skipped": 0,
      "name": "io.lenses.core.channels.publisher.webhook.loader.parser.AuditVariablesParserTest",
      "timestamp": "2020-07-26T21:54:38",
      "testcase": [
        {
          "name": "AuditVariablesParser should properly parse variable",
          "classname": "io.lenses.core.channels.publisher.webhook.loader.parser.AuditVariablesParserTest",
          "time": 1,
          "failure": null,
          "error": null,
          "skipped": false
        }
      ]
    },
    {
      "time": 15,
      "tests": 4,
      "failures": 0,
      "errors": 0,
      "skipped": 0,
      "name": "io.lenses.core.monitoring.actions.RaiseMultipleBrokerVersionsFnTest",
      "timestamp": "2020-07-26T21:54:45",
      "testcase": [
        {
          "name": "RaiseMultipleBrokerVersionsFn should raise no alert if no brokers are available",
          "classname": "io.lenses.core.monitoring.actions.RaiseMultipleBrokerVersionsFnTest",
          "time": 3,
          "failure": null,
          "error": null,
          "skipped": false
        },
        {
          "name": "RaiseMultipleBrokerVersionsFn should raise an alert when brokers have different versions",
          "classname": "io.lenses.core.monitoring.actions.RaiseMultipleBrokerVersionsFnTest",
          "time": 9,
          "failure": null,
          "error": null,
          "skipped": false
        },
        {
          "name": "RaiseMultipleBrokerVersionsFn should do not raise the alert more than once when brokers have different versions",
          "classname": "io.lenses.core.monitoring.actions.RaiseMultipleBrokerVersionsFnTest",
          "time": 2,
          "failure": null,
          "error": null,
          "skipped": false
        },
        {
          "name": "RaiseMultipleBrokerVersionsFn should raise an INFO alert when brokers are of the same version",
          "classname": "io.lenses.core.monitoring.actions.RaiseMultipleBrokerVersionsFnTest",
          "time": 1,
          "failure": null,
          "error": null,
          "skipped": false
        }
      ]
    },
    {
      "time": 4,
      "tests": 15,
      "failures": 0,
      "errors": 0,
      "skipped": 0,
      "name": "io.lenses.core.channels.validation.PluginConfigResolverTest",
      "timestamp": "2020-07-26T21:54:53",
      "testcase": [
        {
          "name": "PluginConfigResolver should resolveConfigToMap should resolve a single config from plugin should with string value",
          "classname": "io.lenses.core.channels.validation.PluginConfigResolverTest",
          "time": 0,
          "failure": null,
          "error": null,
          "skipped": false
        },
        {
          "name": "PluginConfigResolver should resolveConfigToMap should resolve a single config from plugin should with decimal value",
          "classname": "io.lenses.core.channels.validation.PluginConfigResolverTest",
          "time": 1,
          "failure": null,
          "error": null,
          "skipped": false
        },
        {
          "name": "PluginConfigResolver should resolveConfigToMap should resolve a single config from plugin should with int value",
          "classname": "io.lenses.core.channels.validation.PluginConfigResolverTest",
          "time": 0,
          "failure": null,
          "error": null,
          "skipped": false
        },
        {
          "name": "PluginConfigResolver should resolveConfigToMap should resolve a single config from plugin should with boolean value",
          "classname": "io.lenses.core.channels.validation.PluginConfigResolverTest",
          "time": 0,
          "failure": null,
          "error": null,
          "skipped": false
        },
        {
          "name": "PluginConfigResolver should resolveConfigToMap should resolve a single config from plugin should with array value",
          "classname": "io.lenses.core.channels.validation.PluginConfigResolverTest",
          "time": 0,
          "failure": null,
          "error": null,
          "skipped": false
        },
        {
          "name": "PluginConfigResolver should resolveConfigToMap should resolve a single config from connection should with string value",
          "classname": "io.lenses.core.channels.validation.PluginConfigResolverTest",
          "time": 0,
          "failure": null,
          "error": null,
          "skipped": false
        },
        {
          "name": "PluginConfigResolver should resolveConfigToMap should resolve a single config from connection should with decimal value",
          "classname": "io.lenses.core.channels.validation.PluginConfigResolverTest",
          "time": 1,
          "failure": null,
          "error": null,
          "skipped": false
        },
        {
          "name": "PluginConfigResolver should resolveConfigToMap should resolve a single config from connection should with int value",
          "classname": "io.lenses.core.channels.validation.PluginConfigResolverTest",
          "time": 0,
          "failure": null,
          "error": null,
          "skipped": false
        },
        {
          "name": "PluginConfigResolver should resolveConfigToMap should resolve a single config from connection should with boolean value",
          "classname": "io.lenses.core.channels.validation.PluginConfigResolverTest",
          "time": 0,
          "failure": null,
          "error": null,
          "skipped": false
        },
        {
          "name": "PluginConfigResolver should resolveConfigToMap should resolve a single config from connection should with array value",
          "classname": "io.lenses.core.channels.validation.PluginConfigResolverTest",
          "time": 0,
          "failure": null,
          "error": null,
          "skipped": false
        },
        {
          "name": "PluginConfigResolver should resolveConfigToMap should resolve multiple values",
          "classname": "io.lenses.core.channels.validation.PluginConfigResolverTest",
          "time": 0,
          "failure": null,
          "error": null,
          "skipped": false
        },
        {
          "name": "PluginConfigResolver should resolveConfigToMap should ignore missing configs if not required",
          "classname": "io.lenses.core.channels.validation.PluginConfigResolverTest",
          "time": 0,
          "failure": null,
          "error": null,
          "skipped": false
        },
        {
          "name": "PluginConfigResolver should resolveConfigToMap should ignore missing connection configs if not required",
          "classname": "io.lenses.core.channels.validation.PluginConfigResolverTest",
          "time": 1,
          "failure": null,
          "error": null,
          "skipped": false
        },
        {
          "name": "PluginConfigResolver should resolveConfigToMap should fail if required config not defined for plugin",
          "classname": "io.lenses.core.channels.validation.PluginConfigResolverTest",
          "time": 0,
          "failure": null,
          "error": null,
          "skipped": false
        },
        {
          "name": "PluginConfigResolver should resolveConfigToMap should fail if required config not defined for connection",
          "classname": "io.lenses.core.channels.validation.PluginConfigResolverTest",
          "time": 1,
          "failure": null,
          "error": null,
          "skipped": false
        }
      ]
    },
    {
      "time": 27,
      "tests": 1,
      "failures": 0,
      "errors": 0,
      "skipped": 0,
      "name": "io.lenses.core.json.DomainFormatsSpec",
      "timestamp": "2020-07-26T21:54:46",
      "testcase": [
        {
          "name": "KafkaTopicActionFormat should write action as json string with value equal to the action class name",
          "classname": "io.lenses.core.json.DomainFormatsSpec",
          "time": 27,
          "failure": null,
          "error": null,
          "skipped": false
        }
      ]
    },
    {
      "time": 37,
      "tests": 1,
      "failures": 0,
      "errors": 0,
      "skipped": 0,
      "name": "io.lenses.core.license.NTPDateTimeRetrieverTests",
      "timestamp": "2020-07-26T21:54:43",
      "testcase": [
        {
          "name": "NTPDateTimeRetriever should retrieve current time",
          "classname": "io.lenses.core.license.NTPDateTimeRetrieverTests",
          "time": 37,
          "failure": null,
          "error": null,
          "skipped": false
        }
      ]
    },
    {
      "time": 940,
      "tests": 4,
      "failures": 0,
      "errors": 0,
      "skipped": 0,
      "name": "io.lenses.core.security.TableInfoSecuritySpec",
      "timestamp": "2020-07-26T21:54:38",
      "testcase": [
        {
          "name": "isAuthorizedToShow should allow to see table only when user has ShowTopicAction privilege",
          "classname": "io.lenses.core.security.TableInfoSecuritySpec",
          "time": 373,
          "failure": null,
          "error": null,
          "skipped": false
        },
        {
          "name": "isAuthorizedToShow should do not allow to see table ShowTopicAction privilege for different table",
          "classname": "io.lenses.core.security.TableInfoSecuritySpec",
          "time": 161,
          "failure": null,
          "error": null,
          "skipped": false
        },
        {
          "name": "isAuthorizedToShow should do not allow to see table when there is no ShowTopicAction privilege for the table",
          "classname": "io.lenses.core.security.TableInfoSecuritySpec",
          "time": 161,
          "failure": null,
          "error": null,
          "skipped": false
        },
        {
          "name": "authorizedActionsFor should return all actions for which table is authorized",
          "classname": "io.lenses.core.security.TableInfoSecuritySpec",
          "time": 245,
          "failure": null,
          "error": null,
          "skipped": false
        }
      ]
    },
    {
      "time": 125,
      "tests": 2,
      "failures": 0,
      "errors": 0,
      "skipped": 0,
      "name": "io.lenses.core.actors.UserProfileManagerTest",
      "timestamp": "2020-07-26T21:54:37",
      "testcase": [
        {
          "name": "UserProfileManager should should load the state from the kafka topic",
          "classname": "io.lenses.core.actors.UserProfileManagerTest",
          "time": 111,
          "failure": null,
          "error": null,
          "skipped": false
        },
        {
          "name": "UserProfileManager should add and remove topics and load the state",
          "classname": "io.lenses.core.actors.UserProfileManagerTest",
          "time": 14,
          "failure": null,
          "error": null,
          "skipped": false
        }
      ]
    },
    {
      "time": 3,
      "tests": 2,
      "failures": 0,
      "errors": 0,
      "skipped": 0,
      "name": "io.lenses.core.monitoring.actions.RaiseUnderReplicatedPartitionsFnTest",
      "timestamp": "2020-07-26T21:54:50",
      "testcase": [
        {
          "name": "RaiseUnderReplicatedPartitionsFn should raise an alert when there are under replicated partitions",
          "classname": "io.lenses.core.monitoring.actions.RaiseUnderReplicatedPartitionsFnTest",
          "time": 2,
          "failure": null,
          "error": null,
          "skipped": false
        },
        {
          "name": "RaiseUnderReplicatedPartitionsFn should raise an INFO alert when there no more offline partitions",
          "classname": "io.lenses.core.monitoring.actions.RaiseUnderReplicatedPartitionsFnTest",
          "time": 1,
          "failure": null,
          "error": null,
          "skipped": false
        }
      ]
    },
    {
      "time": 3063,
      "tests": 3,
      "failures": 0,
      "errors": 0,
      "skipped": 1,
      "name": "io.lenses.core.datasets.RepositoryEventEmitterTest",
      "timestamp": "2020-07-26T21:54:47",
      "testcase": [
        {
          "name": "RepositoryEventEmitterTest should emit the expected event sequence for the ElasticSearch and Kafka table repositories",
          "classname": "io.lenses.core.datasets.RepositoryEventEmitterTest",
          "time": 40,
          "failure": null,
          "error": null,
          "skipped": true
        },
        {
          "name": "RepositoryEventEmitterTest should scope tables by repository and connection",
          "classname": "io.lenses.core.datasets.RepositoryEventEmitterTest",
          "time": 1514,
          "failure": null,
          "error": null,
          "skipped": false
        },
        {
          "name": "RepositoryEventEmitterTest should emit connectionRemoved events when a connection disappears from the metarepo",
          "classname": "io.lenses.core.datasets.RepositoryEventEmitterTest",
          "time": 1508,
          "failure": null,
          "error": null,
          "skipped": false
        }
      ]
    },
    {
      "time": 18,
      "tests": 6,
      "failures": 0,
      "errors": 0,
      "skipped": 0,
      "name": "io.lenses.core.channels.publisher.webhook.loader.render.TemplateRendererTest",
      "timestamp": "2020-07-26T21:54:37",
      "testcase": [
        {
          "name": "TemplateRendererImpl should forward error in case of unknown variable",
          "classname": "io.lenses.core.channels.publisher.webhook.loader.render.TemplateRendererTest",
          "time": 4,
          "failure": null,
          "error": null,
          "skipped": false
        },
        {
          "name": "TemplateRendererImpl should properly render string without template variables",
          "classname": "io.lenses.core.channels.publisher.webhook.loader.render.TemplateRendererTest",
          "time": 1,
          "failure": null,
          "error": null,
          "skipped": false
        },
        {
          "name": "TemplateRendererImpl should properly render string with one variable",
          "classname": "io.lenses.core.channels.publisher.webhook.loader.render.TemplateRendererTest",
          "time": 1,
          "failure": null,
          "error": null,
          "skipped": false
        },
        {
          "name": "TemplateRendererImpl should properly render string with multiple variables",
          "classname": "io.lenses.core.channels.publisher.webhook.loader.render.TemplateRendererTest",
          "time": 1,
          "failure": null,
          "error": null,
          "skipped": false
        },
        {
          "name": "TemplateRendererImpl should properly render alert",
          "classname": "io.lenses.core.channels.publisher.webhook.loader.render.TemplateRendererTest",
          "time": 7,
          "failure": null,
          "error": null,
          "skipped": false
        },
        {
          "name": "TemplateRendererImpl should properly render audit",
          "classname": "io.lenses.core.channels.publisher.webhook.loader.render.TemplateRendererTest",
          "time": 4,
          "failure": null,
          "error": null,
          "skipped": false
        }
      ]
    },
    {
      "time": 49,
      "tests": 4,
      "failures": 0,
      "errors": 0,
      "skipped": 0,
      "name": "io.lenses.core.pagination.PaginationSpec",
      "timestamp": "2020-07-26T21:54:52",
      "testcase": [
        {
          "name": "readPage should return paged values in reverse order",
          "classname": "io.lenses.core.pagination.PaginationSpec",
          "time": 20,
          "failure": null,
          "error": null,
          "skipped": false
        },
        {
          "name": "readPage should support data source returning other amount of values than requested",
          "classname": "io.lenses.core.pagination.PaginationSpec",
          "time": 23,
          "failure": null,
          "error": null,
          "skipped": false
        },
        {
          "name": "readPage should stop reading the page data when getting empty records list",
          "classname": "io.lenses.core.pagination.PaginationSpec",
          "time": 4,
          "failure": null,
          "error": null,
          "skipped": false
        },
        {
          "name": "readPage should return amount of total pages",
          "classname": "io.lenses.core.pagination.PaginationSpec",
          "time": 2,
          "failure": null,
          "error": null,
          "skipped": false
        }
      ]
    },
    {
      "time": 3,
      "tests": 4,
      "failures": 0,
      "errors": 0,
      "skipped": 0,
      "name": "io.lenses.core.datasets.DatasetMapperTest",
      "timestamp": "2020-07-26T21:54:53",
      "testcase": [
        {
          "name": "DatasetMapper should return a parsing error when the key schema is not valid avro",
          "classname": "io.lenses.core.datasets.DatasetMapperTest",
          "time": 1,
          "failure": null,
          "error": null,
          "skipped": false
        },
        {
          "name": "DatasetMapper should return a parsing error when the value schema is not valid avro",
          "classname": "io.lenses.core.datasets.DatasetMapperTest",
          "time": 0,
          "failure": null,
          "error": null,
          "skipped": false
        },
        {
          "name": "DatasetMapper should handle record names starting with numbers (against the avro spec)",
          "classname": "io.lenses.core.datasets.DatasetMapperTest",
          "time": 1,
          "failure": null,
          "error": null,
          "skipped": false
        },
        {
          "name": "DatasetMapper should return a dataset when the schema can be parsed",
          "classname": "io.lenses.core.datasets.DatasetMapperTest",
          "time": 1,
          "failure": null,
          "error": null,
          "skipped": false
        }
      ]
    },
    {
      "time": 426,
      "tests": 14,
      "failures": 0,
      "errors": 0,
      "skipped": 0,
      "name": "io.lenses.core.avro.AvroFieldsFlattenerTest",
      "timestamp": "2020-07-26T21:54:41",
      "testcase": [
        {
          "name": "AvroFieldsFlattener should not return any fields when an INT primitive type is involved",
          "classname": "io.lenses.core.avro.AvroFieldsFlattenerTest",
          "time": 292,
          "failure": null,
          "error": null,
          "skipped": false
        },
        {
          "name": "AvroFieldsFlattener should not return any fields when an INT primitive type is involved with prefix",
          "classname": "io.lenses.core.avro.AvroFieldsFlattenerTest",
          "time": 0,
          "failure": null,
          "error": null,
          "skipped": false
        },
        {
          "name": "AvroFieldsFlattener should not return any fields when a optional n INT primitive type is involved",
          "classname": "io.lenses.core.avro.AvroFieldsFlattenerTest",
          "time": 6,
          "failure": null,
          "error": null,
          "skipped": false
        },
        {
          "name": "AvroFieldsFlattener should not return any fields when a STRING primitive type is involved",
          "classname": "io.lenses.core.avro.AvroFieldsFlattenerTest",
          "time": 1,
          "failure": null,
          "error": null,
          "skipped": false
        },
        {
          "name": "AvroFieldsFlattener should not return any fields when a STRING primitive type is involved with prefix",
          "classname": "io.lenses.core.avro.AvroFieldsFlattenerTest",
          "time": 0,
          "failure": null,
          "error": null,
          "skipped": false
        },
        {
          "name": "AvroFieldsFlattener should not return any fields when a MAP type with private value is involved",
          "classname": "io.lenses.core.avro.AvroFieldsFlattenerTest",
          "time": 4,
          "failure": null,
          "error": null,
          "skipped": false
        },
        {
          "name": "AvroFieldsFlattener should not return any fields when a MAP type with a struct value involved",
          "classname": "io.lenses.core.avro.AvroFieldsFlattenerTest",
          "time": 35,
          "failure": null,
          "error": null,
          "skipped": false
        },
        {
          "name": "AvroFieldsFlattener should return the fields for CreditCard",
          "classname": "io.lenses.core.avro.AvroFieldsFlattenerTest",
          "time": 4,
          "failure": null,
          "error": null,
          "skipped": false
        },
        {
          "name": "AvroFieldsFlattener should return the fields for LocalPizza",
          "classname": "io.lenses.core.avro.AvroFieldsFlattenerTest",
          "time": 5,
          "failure": null,
          "error": null,
          "skipped": false
        },
        {
          "name": "AvroFieldsFlattener should return the fields for Person",
          "classname": "io.lenses.core.avro.AvroFieldsFlattenerTest",
          "time": 25,
          "failure": null,
          "error": null,
          "skipped": false
        },
        {
          "name": "AvroFieldsFlattener should return the fields for Person with prefix '_key'",
          "classname": "io.lenses.core.avro.AvroFieldsFlattenerTest",
          "time": 9,
          "failure": null,
          "error": null,
          "skipped": false
        },
        {
          "name": "AvroFieldsFlattener should flatten array schema",
          "classname": "io.lenses.core.avro.AvroFieldsFlattenerTest",
          "time": 38,
          "failure": null,
          "error": null,
          "skipped": false
        },
        {
          "name": "AvroFieldsFlattener should work on antwnis schema",
          "classname": "io.lenses.core.avro.AvroFieldsFlattenerTest",
          "time": 6,
          "failure": null,
          "error": null,
          "skipped": false
        },
        {
          "name": "AvroFieldsFlattener should recursive case",
          "classname": "io.lenses.core.avro.AvroFieldsFlattenerTest",
          "time": 1,
          "failure": null,
          "error": null,
          "skipped": false
        }
      ]
    },
    {
      "time": 976,
      "tests": 3,
      "failures": 0,
      "errors": 0,
      "skipped": 1,
      "name": "io.lenses.core.actors.ConsumersActorTest",
      "timestamp": "2020-07-26T21:54:40",
      "testcase": [
        {
          "name": "ConsumersActor should periodically fetch the consumer group details",
          "classname": "io.lenses.core.actors.ConsumersActorTest",
          "time": 598,
          "failure": null,
          "error": null,
          "skipped": false
        },
        {
          "name": "ConsumersActor should recover from temporarely failures",
          "classname": "io.lenses.core.actors.ConsumersActorTest",
          "time": 377,
          "failure": null,
          "error": null,
          "skipped": false
        },
        {
          "name": "ConsumersActor should raise alerts when consumer lag is above threshold",
          "classname": "io.lenses.core.actors.ConsumersActorTest",
          "time": 1,
          "failure": null,
          "error": null,
          "skipped": true
        }
      ]
    },
    {
      "time": 472,
      "tests": 7,
      "failures": 0,
      "errors": 0,
      "skipped": 0,
      "name": "io.lenses.core.metrics.MetricsSubscriptionServiceImplTest",
      "timestamp": "2020-07-26T21:54:39",
      "testcase": [
        {
          "name": "MetricsSubscriptionServiceImpl should quietly do nothing after updating data on channel no one listen to",
          "classname": "io.lenses.core.metrics.MetricsSubscriptionServiceImplTest",
          "time": 13,
          "failure": null,
          "error": null,
          "skipped": false
        },
        {
          "name": "MetricsSubscriptionServiceImpl should create topic after subscription",
          "classname": "io.lenses.core.metrics.MetricsSubscriptionServiceImplTest",
          "time": 105,
          "failure": null,
          "error": null,
          "skipped": false
        },
        {
          "name": "MetricsSubscriptionServiceImpl should provide channel with initial message after subscription",
          "classname": "io.lenses.core.metrics.MetricsSubscriptionServiceImplTest",
          "time": 239,
          "failure": null,
          "error": null,
          "skipped": false
        },
        {
          "name": "MetricsSubscriptionServiceImpl should get published messages",
          "classname": "io.lenses.core.metrics.MetricsSubscriptionServiceImplTest",
          "time": 42,
          "failure": null,
          "error": null,
          "skipped": false
        },
        {
          "name": "MetricsSubscriptionServiceImpl should get latest message after subscribing",
          "classname": "io.lenses.core.metrics.MetricsSubscriptionServiceImplTest",
          "time": 54,
          "failure": null,
          "error": null,
          "skipped": false
        },
        {
          "name": "MetricsSubscriptionServiceImpl should get latest message after subscribing2",
          "classname": "io.lenses.core.metrics.MetricsSubscriptionServiceImplTest",
          "time": 17,
          "failure": null,
          "error": null,
          "skipped": false
        },
        {
          "name": "MetricsSubscriptionServiceImpl should fail subscribing to connection we dont have metrics provider for",
          "classname": "io.lenses.core.metrics.MetricsSubscriptionServiceImplTest",
          "time": 2,
          "failure": null,
          "error": null,
          "skipped": false
        }
      ]
    },
    {
      "time": 29,
      "tests": 10,
      "failures": 0,
      "errors": 0,
      "skipped": 0,
      "name": "io.lenses.core.channels.publisher.splunk.SplunkChannelTest",
      "timestamp": "2020-07-26T21:54:45",
      "testcase": [
        {
          "name": "fromConfigMap should succeed for valid config",
          "classname": "io.lenses.core.channels.publisher.splunk.SplunkChannelTest",
          "time": 1,
          "failure": null,
          "error": null,
          "skipped": false
        },
        {
          "name": "fromConfigMap should fail for non-string host",
          "classname": "io.lenses.core.channels.publisher.splunk.SplunkChannelTest",
          "time": 7,
          "failure": null,
          "error": null,
          "skipped": false
        },
        {
          "name": "fromConfigMap should fail for invalid host",
          "classname": "io.lenses.core.channels.publisher.splunk.SplunkChannelTest",
          "time": 7,
          "failure": null,
          "error": null,
          "skipped": false
        },
        {
          "name": "fromConfigMap should fail for non-numeric port",
          "classname": "io.lenses.core.channels.publisher.splunk.SplunkChannelTest",
          "time": 2,
          "failure": null,
          "error": null,
          "skipped": false
        },
        {
          "name": "fromConfigMap should fail for invalid port",
          "classname": "io.lenses.core.channels.publisher.splunk.SplunkChannelTest",
          "time": 2,
          "failure": null,
          "error": null,
          "skipped": false
        },
        {
          "name": "fromConfigMap should fail for non-string token",
          "classname": "io.lenses.core.channels.publisher.splunk.SplunkChannelTest",
          "time": 2,
          "failure": null,
          "error": null,
          "skipped": false
        },
        {
          "name": "fromConfigMap should fail for invalid token",
          "classname": "io.lenses.core.channels.publisher.splunk.SplunkChannelTest",
          "time": 2,
          "failure": null,
          "error": null,
          "skipped": false
        },
        {
          "name": "fromConfigMap should fail for non-boolean useHttps",
          "classname": "io.lenses.core.channels.publisher.splunk.SplunkChannelTest",
          "time": 2,
          "failure": null,
          "error": null,
          "skipped": false
        },
        {
          "name": "fromConfigMap should fail for non-boolean insecure",
          "classname": "io.lenses.core.channels.publisher.splunk.SplunkChannelTest",
          "time": 2,
          "failure": null,
          "error": null,
          "skipped": false
        },
        {
          "name": "fromConfigMap should fail for non-string source",
          "classname": "io.lenses.core.channels.publisher.splunk.SplunkChannelTest",
          "time": 2,
          "failure": null,
          "error": null,
          "skipped": false
        }
      ]
    },
    {
      "time": 21066,
      "tests": 3,
      "failures": 2,
      "errors": 0,
      "skipped": 0,
      "name": "io.lenses.core.actors.KafkaTopicsActorSpec",
      "timestamp": "2020-07-26T21:54:37",
      "testcase": [
        {
          "name": "ScheduleTopicPartitionsStatistics should send DashboardTopicsData to dashboardActor",
          "classname": "io.lenses.core.actors.KafkaTopicsActorSpec",
          "time": 680,
          "failure": null,
          "error": null,
          "skipped": false
        },
        {
          "name": "ScheduleTopicPartitionsStatistics should handle DeleteFromTopicToOffset message for compacting topics by preventing deletion",
          "classname": "io.lenses.core.actors.KafkaTopicsActorSpec",
          "time": 10251,
          "failure": {
            "message": null,
            "type": "java.util.concurrent.TimeoutException",
            "stackTrace": "java.util.concurrent.TimeoutException\n\tat org.apache.kafka.common.internals.KafkaFutureImpl$SingleWaiter.await(KafkaFutureImpl.java:108)\n\tat org.apache.kafka.common.internals.KafkaFutureImpl.get(KafkaFutureImpl.java:272)\n\tat io.lenses.test.kafka.cluster.Cluster.createTopic(Cluster.scala:44)\n\tat io.lenses.test.kafka.cluster.Cluster.createTopic$(Cluster.scala:42)\n\tat io.lenses.core.actors.KafkaTopicsActorSpec.createTopic(KafkaTopicsActorSpec.scala:61)\n\tat io.lenses.core.actors.KafkaTopicsActorSpec.io$lenses$core$actors$KafkaTopicsActorSpec$$createTopicAndSetConfiguration(KafkaTopicsActorSpec.scala:206)\n\tat io.lenses.core.actors.KafkaTopicsActorSpec$$anon$3.$anonfun$new$7(KafkaTopicsActorSpec.scala:129)\n\tat io.lenses.core.actors.KafkaTopicsActorSpec$TestContext.$anonfun$withActor$2(KafkaTopicsActorSpec.scala:263)\n\tat cats.effect.internals.IORunLoop$.cats$effect$internals$IORunLoop$$loop(IORunLoop.scala:87)\n\tat cats.effect.internals.IORunLoop$.startCancelable(IORunLoop.scala:41)\n\tat cats.effect.internals.IOBracket$BracketStart.run(IOBracket.scala:88)\n\tat cats.effect.internals.Trampoline.cats$effect$internals$Trampoline$$immediateLoop(Trampoline.scala:67)\n\tat cats.effect.internals.Trampoline.startLoop(Trampoline.scala:35)\n\tat cats.effect.internals.TrampolineEC$JVMTrampoline.super$startLoop(TrampolineEC.scala:89)\n\tat cats.effect.internals.TrampolineEC$JVMTrampoline.$anonfun$startLoop$1(TrampolineEC.scala:89)\n\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n\tat cats.effect.internals.TrampolineEC$JVMTrampoline.startLoop(TrampolineEC.scala:89)\n\tat cats.effect.internals.Trampoline.execute(Trampoline.scala:43)\n\tat cats.effect.internals.TrampolineEC.execute(TrampolineEC.scala:42)\n\tat cats.effect.internals.IOBracket$BracketStart.apply(IOBracket.scala:69)\n\tat cats.effect.internals.IOBracket$BracketStart.apply(IOBracket.scala:49)\n\tat cats.effect.internals.IORunLoop$.cats$effect$internals$IORunLoop$$loop(IORunLoop.scala:139)\n\tat cats.effect.internals.IORunLoop$RestartCallback.signal(IORunLoop.scala:359)\n\tat cats.effect.internals.IORunLoop$RestartCallback.apply(IORunLoop.scala:380)\n\tat cats.effect.internals.IORunLoop$RestartCallback.apply(IORunLoop.scala:323)\n\tat cats.effect.internals.IORunLoop$.cats$effect$internals$IORunLoop$$loop(IORunLoop.scala:139)\n\tat cats.effect.internals.IORunLoop$RestartCallback.signal(IORunLoop.scala:359)\n\tat cats.effect.internals.IORunLoop$RestartCallback.apply(IORunLoop.scala:380)\n\tat cats.effect.internals.IORunLoop$RestartCallback.apply(IORunLoop.scala:323)\n\tat cats.effect.internals.IOShift$Tick.run(IOShift.scala:35)\n\tat akka.dispatch.TaskInvocation.run(AbstractDispatcher.scala:47)\n\tat akka.dispatch.ForkJoinExecutorConfigurator$AkkaForkJoinTask.exec(ForkJoinExecutorConfigurator.scala:47)\n\tat java.util.concurrent.ForkJoinTask.doExec(ForkJoinTask.java:289)\n\tat java.util.concurrent.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1056)\n\tat java.util.concurrent.ForkJoinPool.runWorker(ForkJoinPool.java:1692)\n\tat java.util.concurrent.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:157)"
          },
          "error": null,
          "skipped": false
        },
        {
          "name": "ScheduleTopicPartitionsStatistics should handle DeleteFromTopicToOffset message for non-compacting topics by allowing deletion",
          "classname": "io.lenses.core.actors.KafkaTopicsActorSpec",
          "time": 10135,
          "failure": {
            "message": null,
            "type": "java.util.concurrent.TimeoutException",
            "stackTrace": "java.util.concurrent.TimeoutException\n\tat org.apache.kafka.common.internals.KafkaFutureImpl$SingleWaiter.await(KafkaFutureImpl.java:108)\n\tat org.apache.kafka.common.internals.KafkaFutureImpl.get(KafkaFutureImpl.java:272)\n\tat io.lenses.test.kafka.cluster.Cluster.createTopic(Cluster.scala:44)\n\tat io.lenses.test.kafka.cluster.Cluster.createTopic$(Cluster.scala:42)\n\tat io.lenses.core.actors.KafkaTopicsActorSpec.createTopic(KafkaTopicsActorSpec.scala:61)\n\tat io.lenses.core.actors.KafkaTopicsActorSpec.io$lenses$core$actors$KafkaTopicsActorSpec$$createTopicAndSetConfiguration(KafkaTopicsActorSpec.scala:206)\n\tat io.lenses.core.actors.KafkaTopicsActorSpec$$anon$4.$anonfun$new$10(KafkaTopicsActorSpec.scala:155)\n\tat io.lenses.core.actors.KafkaTopicsActorSpec$TestContext.$anonfun$withActor$2(KafkaTopicsActorSpec.scala:263)\n\tat cats.effect.internals.IORunLoop$.cats$effect$internals$IORunLoop$$loop(IORunLoop.scala:87)\n\tat cats.effect.internals.IORunLoop$.startCancelable(IORunLoop.scala:41)\n\tat cats.effect.internals.IOBracket$BracketStart.run(IOBracket.scala:88)\n\tat cats.effect.internals.Trampoline.cats$effect$internals$Trampoline$$immediateLoop(Trampoline.scala:67)\n\tat cats.effect.internals.Trampoline.startLoop(Trampoline.scala:35)\n\tat cats.effect.internals.TrampolineEC$JVMTrampoline.super$startLoop(TrampolineEC.scala:89)\n\tat cats.effect.internals.TrampolineEC$JVMTrampoline.$anonfun$startLoop$1(TrampolineEC.scala:89)\n\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n\tat cats.effect.internals.TrampolineEC$JVMTrampoline.startLoop(TrampolineEC.scala:89)\n\tat cats.effect.internals.Trampoline.execute(Trampoline.scala:43)\n\tat cats.effect.internals.TrampolineEC.execute(TrampolineEC.scala:42)\n\tat cats.effect.internals.IOBracket$BracketStart.apply(IOBracket.scala:69)\n\tat cats.effect.internals.IOBracket$BracketStart.apply(IOBracket.scala:49)\n\tat cats.effect.internals.IORunLoop$.cats$effect$internals$IORunLoop$$loop(IORunLoop.scala:139)\n\tat cats.effect.internals.IORunLoop$RestartCallback.signal(IORunLoop.scala:359)\n\tat cats.effect.internals.IORunLoop$RestartCallback.apply(IORunLoop.scala:380)\n\tat cats.effect.internals.IORunLoop$RestartCallback.apply(IORunLoop.scala:323)\n\tat cats.effect.internals.IORunLoop$.cats$effect$internals$IORunLoop$$loop(IORunLoop.scala:139)\n\tat cats.effect.internals.IORunLoop$RestartCallback.signal(IORunLoop.scala:359)\n\tat cats.effect.internals.IORunLoop$RestartCallback.apply(IORunLoop.scala:380)\n\tat cats.effect.internals.IORunLoop$RestartCallback.apply(IORunLoop.scala:323)\n\tat cats.effect.internals.IOShift$Tick.run(IOShift.scala:35)\n\tat akka.dispatch.TaskInvocation.run(AbstractDispatcher.scala:47)\n\tat akka.dispatch.ForkJoinExecutorConfigurator$AkkaForkJoinTask.exec(ForkJoinExecutorConfigurator.scala:47)\n\tat java.util.concurrent.ForkJoinTask.doExec(ForkJoinTask.java:289)\n\tat java.util.concurrent.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1056)\n\tat java.util.concurrent.ForkJoinPool.runWorker(ForkJoinPool.java:1692)\n\tat java.util.concurrent.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:157)"
          },
          "error": null,
          "skipped": false
        }
      ]
    },
    {
      "time": 573,
      "tests": 26,
      "failures": 0,
      "errors": 0,
      "skipped": 0,
      "name": "io.lenses.core.channels.ChannelServiceTest",
      "timestamp": "2020-07-26T21:54:44",
      "testcase": [
        {
          "name": "getAll should return a paginated list of all existing alert channels",
          "classname": "io.lenses.core.channels.ChannelServiceTest",
          "time": 161,
          "failure": null,
          "error": null,
          "skipped": false
        },
        {
          "name": "getAll should sorts the paginated list according to the supplied order",
          "classname": "io.lenses.core.channels.ChannelServiceTest",
          "time": 12,
          "failure": null,
          "error": null,
          "skipped": false
        },
        {
          "name": "get should return None when the supplied id is not found",
          "classname": "io.lenses.core.channels.ChannelServiceTest",
          "time": 4,
          "failure": null,
          "error": null,
          "skipped": false
        },
        {
          "name": "get should return the specified channel",
          "classname": "io.lenses.core.channels.ChannelServiceTest",
          "time": 13,
          "failure": null,
          "error": null,
          "skipped": false
        },
        {
          "name": "delete should return an error when the supplied id is not found",
          "classname": "io.lenses.core.channels.ChannelServiceTest",
          "time": 44,
          "failure": null,
          "error": null,
          "skipped": false
        },
        {
          "name": "delete should remove the record and log the deletion in the audit log",
          "classname": "io.lenses.core.channels.ChannelServiceTest",
          "time": 7,
          "failure": null,
          "error": null,
          "skipped": false
        },
        {
          "name": "add should persist a valid channel",
          "classname": "io.lenses.core.channels.ChannelServiceTest",
          "time": 7,
          "failure": null,
          "error": null,
          "skipped": false
        },
        {
          "name": "add should return error details when the supplied connection id is not present",
          "classname": "io.lenses.core.channels.ChannelServiceTest",
          "time": 10,
          "failure": null,
          "error": null,
          "skipped": false
        },
        {
          "name": "add should return error details when one or more fields are not valid",
          "classname": "io.lenses.core.channels.ChannelServiceTest",
          "time": 13,
          "failure": null,
          "error": null,
          "skipped": false
        },
        {
          "name": "add should a web-hook channel should return field errors if undefined variables are supplied in a templates field",
          "classname": "io.lenses.core.channels.ChannelServiceTest",
          "time": 94,
          "failure": null,
          "error": null,
          "skipped": false
        },
        {
          "name": "add should a web-hook channel should return field errors if the supplied headers list is not parsable as key value pairs",
          "classname": "io.lenses.core.channels.ChannelServiceTest",
          "time": 12,
          "failure": null,
          "error": null,
          "skipped": false
        },
        {
          "name": "add should a web-hook channel should persist a valid channel when no creds field is set in the connection",
          "classname": "io.lenses.core.channels.ChannelServiceTest",
          "time": 21,
          "failure": null,
          "error": null,
          "skipped": false
        },
        {
          "name": "add should a web-hook channel should persist a valid channel when no path field is set in the connection",
          "classname": "io.lenses.core.channels.ChannelServiceTest",
          "time": 4,
          "failure": null,
          "error": null,
          "skipped": false
        },
        {
          "name": "add should a web-hook channel should persist a valid channel",
          "classname": "io.lenses.core.channels.ChannelServiceTest",
          "time": 11,
          "failure": null,
          "error": null,
          "skipped": false
        },
        {
          "name": "update should return error details when one or more property values are not valid",
          "classname": "io.lenses.core.channels.ChannelServiceTest",
          "time": 13,
          "failure": null,
          "error": null,
          "skipped": false
        },
        {
          "name": "update should return error details when the supplied connection is not valid",
          "classname": "io.lenses.core.channels.ChannelServiceTest",
          "time": 25,
          "failure": null,
          "error": null,
          "skipped": false
        },
        {
          "name": "update should persist a valid channel update",
          "classname": "io.lenses.core.channels.ChannelServiceTest",
          "time": 15,
          "failure": null,
          "error": null,
          "skipped": false
        },
        {
          "name": "update should allow setting a different connection",
          "classname": "io.lenses.core.channels.ChannelServiceTest",
          "time": 10,
          "failure": null,
          "error": null,
          "skipped": false
        },
        {
          "name": "update should a web-hook channel should returns validation errors when an invalid update is supplied",
          "classname": "io.lenses.core.channels.ChannelServiceTest",
          "time": 9,
          "failure": null,
          "error": null,
          "skipped": false
        },
        {
          "name": "update should a web-hook channel should persist a valid update",
          "classname": "io.lenses.core.channels.ChannelServiceTest",
          "time": 11,
          "failure": null,
          "error": null,
          "skipped": false
        },
        {
          "name": "patch should return error details when one or more property values are not valid",
          "classname": "io.lenses.core.channels.ChannelServiceTest",
          "time": 9,
          "failure": null,
          "error": null,
          "skipped": false
        },
        {
          "name": "patch should return error details when the supplied connection is not valid",
          "classname": "io.lenses.core.channels.ChannelServiceTest",
          "time": 6,
          "failure": null,
          "error": null,
          "skipped": false
        },
        {
          "name": "patch should persist a valid channel patch",
          "classname": "io.lenses.core.channels.ChannelServiceTest",
          "time": 16,
          "failure": null,
          "error": null,
          "skipped": false
        },
        {
          "name": "patch should allow setting a different connection",
          "classname": "io.lenses.core.channels.ChannelServiceTest",
          "time": 27,
          "failure": null,
          "error": null,
          "skipped": false
        },
        {
          "name": "patch should a web-hook channel should returns validation errors when an invalid patch is supplied",
          "classname": "io.lenses.core.channels.ChannelServiceTest",
          "time": 9,
          "failure": null,
          "error": null,
          "skipped": false
        },
        {
          "name": "patch should a web-hook channel should persist a valid patch",
          "classname": "io.lenses.core.channels.ChannelServiceTest",
          "time": 10,
          "failure": null,
          "error": null,
          "skipped": false
        }
      ]
    },
    {
      "time": 37,
      "tests": 4,
      "failures": 0,
      "errors": 0,
      "skipped": 0,
      "name": "io.lenses.core.avro.AvroStringFormatterTest",
      "timestamp": "2020-07-26T21:54:50",
      "testcase": [
        {
          "name": "AvroStringFormatter should handle null",
          "classname": "io.lenses.core.avro.AvroStringFormatterTest",
          "time": 1,
          "failure": null,
          "error": null,
          "skipped": false
        },
        {
          "name": "AvroStringFormatter should handle null value for NonRecordContainer",
          "classname": "io.lenses.core.avro.AvroStringFormatterTest",
          "time": 1,
          "failure": null,
          "error": null,
          "skipped": false
        },
        {
          "name": "AvroStringFormatter should format NonRecordContainer for a double",
          "classname": "io.lenses.core.avro.AvroStringFormatterTest",
          "time": 0,
          "failure": null,
          "error": null,
          "skipped": false
        },
        {
          "name": "AvroStringFormatter should format a GenericRecord",
          "classname": "io.lenses.core.avro.AvroStringFormatterTest",
          "time": 35,
          "failure": null,
          "error": null,
          "skipped": false
        }
      ]
    },
    {
      "time": 30,
      "tests": 3,
      "failures": 0,
      "errors": 0,
      "skipped": 0,
      "name": "io.lenses.core.metrics.PartitionEndOffsetRetentionTest",
      "timestamp": "2020-07-26T21:54:41",
      "testcase": [
        {
          "name": "PartitionEndOffsetRetention should always retain 30 daily values",
          "classname": "io.lenses.core.metrics.PartitionEndOffsetRetentionTest",
          "time": 23,
          "failure": null,
          "error": null,
          "skipped": false
        },
        {
          "name": "PartitionEndOffsetRetention should hard limit 30 days ago",
          "classname": "io.lenses.core.metrics.PartitionEndOffsetRetentionTest",
          "time": 2,
          "failure": null,
          "error": null,
          "skipped": false
        },
        {
          "name": "PartitionEndOffsetRetention should retain values as per alert duration",
          "classname": "io.lenses.core.metrics.PartitionEndOffsetRetentionTest",
          "time": 5,
          "failure": null,
          "error": null,
          "skipped": false
        }
      ]
    },
    {
      "time": 6,
      "tests": 4,
      "failures": 0,
      "errors": 0,
      "skipped": 0,
      "name": "io.lenses.core.channels.publisher.ChannelPublisherFactoryTest",
      "timestamp": "2020-07-26T21:54:53",
      "testcase": [
        {
          "name": "ChannelPublisherFactory should return publisher by template name",
          "classname": "io.lenses.core.channels.publisher.ChannelPublisherFactoryTest",
          "time": 1,
          "failure": null,
          "error": null,
          "skipped": false
        },
        {
          "name": "ChannelPublisherFactory should return publisher by class name",
          "classname": "io.lenses.core.channels.publisher.ChannelPublisherFactoryTest",
          "time": 4,
          "failure": null,
          "error": null,
          "skipped": false
        },
        {
          "name": "ChannelPublisherFactory should raise error if no fallback publisher by class name",
          "classname": "io.lenses.core.channels.publisher.ChannelPublisherFactoryTest",
          "time": 0,
          "failure": null,
          "error": null,
          "skipped": false
        },
        {
          "name": "ChannelPublisherFactory should raise error if no class name",
          "classname": "io.lenses.core.channels.publisher.ChannelPublisherFactoryTest",
          "time": 1,
          "failure": null,
          "error": null,
          "skipped": false
        }
      ]
    },
    {
      "time": 462,
      "tests": 1,
      "failures": 0,
      "errors": 0,
      "skipped": 0,
      "name": "io.lenses.core.actors.SchemaRegistryDataAggregatorActorSpec",
      "timestamp": "2020-07-26T21:54:40",
      "testcase": [
        {
          "name": "SchemaRegistryNodesStatusResponse should send status to subscribers with activity status reflecting activity of registries",
          "classname": "io.lenses.core.actors.SchemaRegistryDataAggregatorActorSpec",
          "time": 462,
          "failure": null,
          "error": null,
          "skipped": false
        }
      ]
    },
    {
      "time": 541,
      "tests": 1,
      "failures": 0,
      "errors": 0,
      "skipped": 0,
      "name": "io.lenses.core.channels.publisher.webhook.loader.parser.AlertVariablesParserTest",
      "timestamp": "2020-07-26T21:54:37",
      "testcase": [
        {
          "name": "AlertVariablesParser should properly parse variable",
          "classname": "io.lenses.core.channels.publisher.webhook.loader.parser.AlertVariablesParserTest",
          "time": 541,
          "failure": null,
          "error": null,
          "skipped": false
        }
      ]
    },
    {
      "time": 176,
      "tests": 4,
      "failures": 0,
      "errors": 0,
      "skipped": 0,
      "name": "io.lenses.core.channels.publisher.pagerduty.PagerDutyAlertPublisherTest",
      "timestamp": "2020-07-26T21:54:43",
      "testcase": [
        {
          "name": "PagerDutyAlertPublisher should publish should fail when not all the mandatory field are supplied",
          "classname": "io.lenses.core.channels.publisher.pagerduty.PagerDutyAlertPublisherTest",
          "time": 38,
          "failure": null,
          "error": null,
          "skipped": false
        },
        {
          "name": "PagerDutyAlertPublisher should publish should trigger and then resolve incidents for alerts raised by a 'fixed' alert rule",
          "classname": "io.lenses.core.channels.publisher.pagerduty.PagerDutyAlertPublisherTest",
          "time": 68,
          "failure": null,
          "error": null,
          "skipped": false
        },
        {
          "name": "PagerDutyAlertPublisher should publish should trigger and then resolve incidents for alerts raised by consumer lag rules",
          "classname": "io.lenses.core.channels.publisher.pagerduty.PagerDutyAlertPublisherTest",
          "time": 7,
          "failure": null,
          "error": null,
          "skipped": false
        },
        {
          "name": "PagerDutyAlertPublisher should publish should avoid triggering incidents for ignored alerts",
          "classname": "io.lenses.core.channels.publisher.pagerduty.PagerDutyAlertPublisherTest",
          "time": 63,
          "failure": null,
          "error": null,
          "skipped": false
        }
      ]
    },
    {
      "time": 17,
      "tests": 3,
      "failures": 0,
      "errors": 0,
      "skipped": 0,
      "name": "io.lenses.core.monitoring.actions.RaiseBrokerDiskUsageAlertFnTest",
      "timestamp": "2020-07-26T21:54:53",
      "testcase": [
        {
          "name": "RaiseBrokerDiskUsageAlertFn should Raise no alert when disk usage is close to average for all brokers in the cluster",
          "classname": "io.lenses.core.monitoring.actions.RaiseBrokerDiskUsageAlertFnTest",
          "time": 10,
          "failure": null,
          "error": null,
          "skipped": false
        },
        {
          "name": "RaiseBrokerDiskUsageAlertFn should Raise a MEDIUM level alert when a broker's disk usage is 25% greater than the cluster average",
          "classname": "io.lenses.core.monitoring.actions.RaiseBrokerDiskUsageAlertFnTest",
          "time": 5,
          "failure": null,
          "error": null,
          "skipped": false
        },
        {
          "name": "RaiseBrokerDiskUsageAlertFn should Raise an INFO level alert when everything is back to normal",
          "classname": "io.lenses.core.monitoring.actions.RaiseBrokerDiskUsageAlertFnTest",
          "time": 2,
          "failure": null,
          "error": null,
          "skipped": false
        }
      ]
    },
    {
      "time": 210,
      "tests": 3,
      "failures": 0,
      "errors": 0,
      "skipped": 0,
      "name": "io.lenses.core.json.JsonWriterSupportSpec",
      "timestamp": "2020-07-26T21:54:43",
      "testcase": [
        {
          "name": "flatteningWriter should add json object to original json if the latter is json object using provided key",
          "classname": "io.lenses.core.json.JsonWriterSupportSpec",
          "time": 151,
          "failure": null,
          "error": null,
          "skipped": false
        },
        {
          "name": "flatteningWriter should add json value to original json if the latter is json array",
          "classname": "io.lenses.core.json.JsonWriterSupportSpec",
          "time": 10,
          "failure": null,
          "error": null,
          "skipped": false
        },
        {
          "name": "listWriter should convert list to Json",
          "classname": "io.lenses.core.json.JsonWriterSupportSpec",
          "time": 49,
          "failure": null,
          "error": null,
          "skipped": false
        }
      ]
    },
    {
      "time": 537,
      "tests": 1,
      "failures": 0,
      "errors": 0,
      "skipped": 0,
      "name": "io.lenses.core.channels.publisher.webhook.loader.render.AuditTemplateRendererTest",
      "timestamp": "2020-07-26T21:54:37",
      "testcase": [
        {
          "name": "AuditTemplateRenderer should properly find variables",
          "classname": "io.lenses.core.channels.publisher.webhook.loader.render.AuditTemplateRendererTest",
          "time": 537,
          "failure": null,
          "error": null,
          "skipped": false
        }
      ]
    },
    {
      "time": 235,
      "tests": 8,
      "failures": 0,
      "errors": 0,
      "skipped": 0,
      "name": "io.lenses.core.channels.config.ChannelConfigServiceTest",
      "timestamp": "2020-07-26T21:54:40",
      "testcase": [
        {
          "name": "PluginConfigService should listAlertChannelTemplates should return a list of the existing templates",
          "classname": "io.lenses.core.channels.config.ChannelConfigServiceTest",
          "time": 20,
          "failure": null,
          "error": null,
          "skipped": false
        },
        {
          "name": "PluginConfigService should listAlertChannelTemplates should include the list of applicable connections",
          "classname": "io.lenses.core.channels.config.ChannelConfigServiceTest",
          "time": 92,
          "failure": null,
          "error": null,
          "skipped": false
        },
        {
          "name": "PluginConfigService should listResolvedPluginConfigs should resolve valid configurations",
          "classname": "io.lenses.core.channels.config.ChannelConfigServiceTest",
          "time": 55,
          "failure": null,
          "error": null,
          "skipped": false
        },
        {
          "name": "PluginConfigService should listResolvedPluginConfigs should ignore if connection is missing",
          "classname": "io.lenses.core.channels.config.ChannelConfigServiceTest",
          "time": 27,
          "failure": null,
          "error": null,
          "skipped": false
        },
        {
          "name": "PluginConfigService should listResolvedPluginConfigs should succeed if className is missing",
          "classname": "io.lenses.core.channels.config.ChannelConfigServiceTest",
          "time": 4,
          "failure": null,
          "error": null,
          "skipped": false
        },
        {
          "name": "PluginConfigService should listResolvedPluginConfigs should ignore if config is missing",
          "classname": "io.lenses.core.channels.config.ChannelConfigServiceTest",
          "time": 7,
          "failure": null,
          "error": null,
          "skipped": false
        },
        {
          "name": "PluginConfigService should listResolvedPluginConfigs should ignore if channel is not enabled",
          "classname": "io.lenses.core.channels.config.ChannelConfigServiceTest",
          "time": 4,
          "failure": null,
          "error": null,
          "skipped": false
        },
        {
          "name": "ResolvedPluginConfigWithTemplate should stringlyTypedResolvedConfiguration should should render json values as strings",
          "classname": "io.lenses.core.channels.config.ChannelConfigServiceTest",
          "time": 26,
          "failure": null,
          "error": null,
          "skipped": false
        }
      ]
    },
    {
      "time": 1404,
      "tests": 3,
      "failures": 0,
      "errors": 0,
      "skipped": 0,
      "name": "io.lenses.core.migration.KafkaOnePartitionTopicReaderCreateTest",
      "timestamp": "2020-07-26T21:54:37",
      "testcase": [
        {
          "name": "returns None if the topic does not exist",
          "classname": "io.lenses.core.migration.KafkaOnePartitionTopicReaderCreateTest",
          "time": 1391,
          "failure": null,
          "error": null,
          "skipped": false
        },
        {
          "name": "returns the reader event if all data was read",
          "classname": "io.lenses.core.migration.KafkaOnePartitionTopicReaderCreateTest",
          "time": 11,
          "failure": null,
          "error": null,
          "skipped": false
        },
        {
          "name": "returns the reader if data needs to be read",
          "classname": "io.lenses.core.migration.KafkaOnePartitionTopicReaderCreateTest",
          "time": 2,
          "failure": null,
          "error": null,
          "skipped": false
        }
      ]
    },
    {
      "time": 997,
      "tests": 4,
      "failures": 0,
      "errors": 0,
      "skipped": 0,
      "name": "io.lenses.core.kafka.TopicInfoEnrichmentTest",
      "timestamp": "2020-07-26T21:54:50",
      "testcase": [
        {
          "name": "TopicInfoEnrichment should enrich topic info with kafka repo attributes and byte size",
          "classname": "io.lenses.core.kafka.TopicInfoEnrichmentTest",
          "time": 88,
          "failure": null,
          "error": null,
          "skipped": false
        },
        {
          "name": "TopicInfoEnrichment should computes no byte size if an empty list of metrics is returned",
          "classname": "io.lenses.core.kafka.TopicInfoEnrichmentTest",
          "time": 82,
          "failure": null,
          "error": null,
          "skipped": false
        },
        {
          "name": "TopicInfoEnrichment should honours the configured grace period on empty metrics",
          "classname": "io.lenses.core.kafka.TopicInfoEnrichmentTest",
          "time": 373,
          "failure": null,
          "error": null,
          "skipped": false
        },
        {
          "name": "TopicInfoEnrichment should honours the configured grace period on error",
          "classname": "io.lenses.core.kafka.TopicInfoEnrichmentTest",
          "time": 454,
          "failure": null,
          "error": null,
          "skipped": false
        }
      ]
    },
    {
      "time": 361,
      "tests": 5,
      "failures": 0,
      "errors": 0,
      "skipped": 0,
      "name": "io.lenses.core.akka.BaseRoutesSpec",
      "timestamp": "2020-07-26T21:54:43",
      "testcase": [
        {
          "name": "pagination should fail when there is no page size parameter",
          "classname": "io.lenses.core.akka.BaseRoutesSpec",
          "time": 178,
          "failure": null,
          "error": null,
          "skipped": false
        },
        {
          "name": "pagination should accept request with valid page and page size parameters",
          "classname": "io.lenses.core.akka.BaseRoutesSpec",
          "time": 103,
          "failure": null,
          "error": null,
          "skipped": false
        },
        {
          "name": "pagination should accept request with missing page parameter",
          "classname": "io.lenses.core.akka.BaseRoutesSpec",
          "time": 30,
          "failure": null,
          "error": null,
          "skipped": false
        },
        {
          "name": "pagination should fail with 422 UnprocessableEntity when page parameter is invalid",
          "classname": "io.lenses.core.akka.BaseRoutesSpec",
          "time": 27,
          "failure": null,
          "error": null,
          "skipped": false
        },
        {
          "name": "pagination should fail with 422 UnprocessableEntity when page size parameter is invalid",
          "classname": "io.lenses.core.akka.BaseRoutesSpec",
          "time": 23,
          "failure": null,
          "error": null,
          "skipped": false
        }
      ]
    },
    {
      "time": 10005,
      "tests": 1,
      "failures": 1,
      "errors": 0,
      "skipped": 0,
      "name": "io.lenses.core.actors.ConnectStatusActorTest",
      "timestamp": "2020-07-26T21:54:41",
      "testcase": [
        {
          "name": "should read task status",
          "classname": "io.lenses.core.actors.ConnectStatusActorTest",
          "time": 10005,
          "failure": {
            "message": null,
            "type": "java.util.concurrent.TimeoutException",
            "stackTrace": "java.util.concurrent.TimeoutException\n\tat org.apache.kafka.common.internals.KafkaFutureImpl$SingleWaiter.await(KafkaFutureImpl.java:108)\n\tat org.apache.kafka.common.internals.KafkaFutureImpl.get(KafkaFutureImpl.java:272)\n\tat io.lenses.test.kafka.cluster.Cluster.createTopic(Cluster.scala:44)\n\tat io.lenses.test.kafka.cluster.Cluster.createTopic$(Cluster.scala:42)\n\tat io.lenses.core.actors.ConnectStatusActorTest.createTopic(ConnectStatusActorTest.scala:31)\n\tat io.lenses.core.actors.ConnectStatusActorTest.$anonfun$new$1(ConnectStatusActorTest.scala:55)\n\tat org.scalatest.OutcomeOf.outcomeOf(OutcomeOf.scala:85)\n\tat org.scalatest.OutcomeOf.outcomeOf$(OutcomeOf.scala:83)\n\tat org.scalatest.OutcomeOf$.outcomeOf(OutcomeOf.scala:104)\n\tat org.scalatest.Transformer.apply(Transformer.scala:22)\n\tat org.scalatest.Transformer.apply(Transformer.scala:20)\n\tat org.scalatest.wordspec.AnyWordSpecLike$$anon$3.apply(AnyWordSpecLike.scala:1076)\n\tat org.scalatest.TestSuite.withFixture(TestSuite.scala:196)\n\tat org.scalatest.TestSuite.withFixture$(TestSuite.scala:195)\n\tat io.lenses.core.actors.ConnectStatusActorTest.withFixture(ConnectStatusActorTest.scala:31)\n\tat org.scalatest.wordspec.AnyWordSpecLike.invokeWithFixture$1(AnyWordSpecLike.scala:1074)\n\tat org.scalatest.wordspec.AnyWordSpecLike.$anonfun$runTest$1(AnyWordSpecLike.scala:1086)\n\tat org.scalatest.SuperEngine.runTestImpl(Engine.scala:306)\n\tat org.scalatest.wordspec.AnyWordSpecLike.runTest(AnyWordSpecLike.scala:1086)\n\tat org.scalatest.wordspec.AnyWordSpecLike.runTest$(AnyWordSpecLike.scala:1068)\n\tat io.lenses.core.actors.ConnectStatusActorTest.runTest(ConnectStatusActorTest.scala:31)\n\tat org.scalatest.wordspec.AnyWordSpecLike.$anonfun$runTests$1(AnyWordSpecLike.scala:1145)\n\tat org.scalatest.SuperEngine.$anonfun$runTestsInBranch$1(Engine.scala:413)\n\tat scala.collection.immutable.List.foreach(List.scala:392)\n\tat org.scalatest.SuperEngine.traverseSubNodes$1(Engine.scala:401)\n\tat org.scalatest.SuperEngine.runTestsInBranch(Engine.scala:396)\n\tat org.scalatest.SuperEngine.runTestsImpl(Engine.scala:475)\n\tat org.scalatest.wordspec.AnyWordSpecLike.runTests(AnyWordSpecLike.scala:1145)\n\tat org.scalatest.wordspec.AnyWordSpecLike.runTests$(AnyWordSpecLike.scala:1144)\n\tat io.lenses.core.actors.ConnectStatusActorTest.runTests(ConnectStatusActorTest.scala:31)\n\tat org.scalatest.Suite.run(Suite.scala:1112)\n\tat org.scalatest.Suite.run$(Suite.scala:1094)\n\tat io.lenses.core.actors.ConnectStatusActorTest.org$scalatest$wordspec$AnyWordSpecLike$$super$run(ConnectStatusActorTest.scala:31)\n\tat org.scalatest.wordspec.AnyWordSpecLike.$anonfun$run$1(AnyWordSpecLike.scala:1190)\n\tat org.scalatest.SuperEngine.runImpl(Engine.scala:535)\n\tat org.scalatest.wordspec.AnyWordSpecLike.run(AnyWordSpecLike.scala:1190)\n\tat org.scalatest.wordspec.AnyWordSpecLike.run$(AnyWordSpecLike.scala:1188)\n\tat io.lenses.core.actors.ConnectStatusActorTest.org$scalatest$BeforeAndAfterAll$$super$run(ConnectStatusActorTest.scala:31)\n\tat org.scalatest.BeforeAndAfterAll.liftedTree1$1(BeforeAndAfterAll.scala:213)\n\tat org.scalatest.BeforeAndAfterAll.run(BeforeAndAfterAll.scala:210)\n\tat org.scalatest.BeforeAndAfterAll.run$(BeforeAndAfterAll.scala:208)\n\tat io.lenses.core.actors.ConnectStatusActorTest.run(ConnectStatusActorTest.scala:31)\n\tat org.scalatest.tools.Framework.org$scalatest$tools$Framework$$runSuite(Framework.scala:318)\n\tat org.scalatest.tools.Framework$ScalaTestTask.execute(Framework.scala:513)\n\tat sbt.TestRunner.runTest$1(TestFramework.scala:139)\n\tat sbt.TestRunner.run(TestFramework.scala:154)\n\tat sbt.TestFramework$$anon$3$$anonfun$$lessinit$greater$1.$anonfun$apply$1(TestFramework.scala:317)\n\tat sbt.TestFramework$.sbt$TestFramework$$withContextLoader(TestFramework.scala:277)\n\tat sbt.TestFramework$$anon$3$$anonfun$$lessinit$greater$1.apply(TestFramework.scala:317)\n\tat sbt.TestFramework$$anon$3$$anonfun$$lessinit$greater$1.apply(TestFramework.scala:317)\n\tat sbt.TestFunction.apply(TestFramework.scala:329)\n\tat sbt.Tests$.$anonfun$toTask$1(Tests.scala:311)\n\tat sbt.std.Transform$$anon$3.$anonfun$apply$2(Transform.scala:46)\n\tat sbt.std.Transform$$anon$4.work(Transform.scala:67)\n\tat sbt.Execute.$anonfun$submit$2(Execute.scala:281)\n\tat sbt.internal.util.ErrorHandling$.wideConvert(ErrorHandling.scala:19)\n\tat sbt.Execute.work(Execute.scala:290)\n\tat sbt.Execute.$anonfun$submit$1(Execute.scala:281)\n\tat sbt.ConcurrentRestrictions$$anon$4.$anonfun$submitValid$1(ConcurrentRestrictions.scala:178)\n\tat sbt.CompletionService$$anon$2.call(CompletionService.scala:37)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:748)"
          },
          "error": null,
          "skipped": false
        }
      ]
    },
    {
      "time": 3,
      "tests": 2,
      "failures": 0,
      "errors": 0,
      "skipped": 0,
      "name": "io.lenses.core.monitoring.actions.RaiseOfflinePartitionsFnTest",
      "timestamp": "2020-07-26T21:54:41",
      "testcase": [
        {
          "name": "RaiseOfflinePartitionsFn should raise an alert when there are offline partitions",
          "classname": "io.lenses.core.monitoring.actions.RaiseOfflinePartitionsFnTest",
          "time": 2,
          "failure": null,
          "error": null,
          "skipped": false
        },
        {
          "name": "RaiseOfflinePartitionsFn should raise an INFO alert when there no more offline partitions",
          "classname": "io.lenses.core.monitoring.actions.RaiseOfflinePartitionsFnTest",
          "time": 1,
          "failure": null,
          "error": null,
          "skipped": false
        }
      ]
    },
    {
      "time": 11925,
      "tests": 3,
      "failures": 0,
      "errors": 0,
      "skipped": 0,
      "name": "io.lenses.core.actors.LicenseActorSpec",
      "timestamp": "2020-07-26T21:54:42",
      "testcase": [
        {
          "name": "LicenseActorSpec with 1 broker should start with default license and 1 broker the actor should not shutdown the system",
          "classname": "io.lenses.core.actors.LicenseActorSpec",
          "time": 5272,
          "failure": null,
          "error": null,
          "skipped": false
        },
        {
          "name": " the actor should not shutdown the system",
          "classname": "io.lenses.core.actors.LicenseActorSpec",
          "time": 5217,
          "failure": null,
          "error": null,
          "skipped": false
        },
        {
          "name": " the actor should shutdown the system",
          "classname": "io.lenses.core.actors.LicenseActorSpec",
          "time": 1434,
          "failure": null,
          "error": null,
          "skipped": false
        }
      ]
    },
    {
      "time": 564,
      "tests": 3,
      "failures": 0,
      "errors": 0,
      "skipped": 0,
      "name": "io.lenses.core.channels.publisher.webhook.loader.parser.TemplateVariablesParserTest",
      "timestamp": "2020-07-26T21:54:38",
      "testcase": [
        {
          "name": "TemplateVariablesParserImpl should forward error in case of unknown variable",
          "classname": "io.lenses.core.channels.publisher.webhook.loader.parser.TemplateVariablesParserTest",
          "time": 562,
          "failure": null,
          "error": null,
          "skipped": false
        },
        {
          "name": "TemplateVariablesParserImpl should properly behave in case of no variables in raw string",
          "classname": "io.lenses.core.channels.publisher.webhook.loader.parser.TemplateVariablesParserTest",
          "time": 1,
          "failure": null,
          "error": null,
          "skipped": false
        },
        {
          "name": "TemplateVariablesParserImpl should properly find variables in raw string",
          "classname": "io.lenses.core.channels.publisher.webhook.loader.parser.TemplateVariablesParserTest",
          "time": 1,
          "failure": null,
          "error": null,
          "skipped": false
        }
      ]
    },
    {
      "time": 1150,
      "tests": 4,
      "failures": 0,
      "errors": 0,
      "skipped": 0,
      "name": "io.lenses.core.telemetry.AlertsTelemetryFnTest",
      "timestamp": "2020-07-26T21:54:53",
      "testcase": [
        {
          "name": "buildTelemetry should filter disabled rules from main array",
          "classname": "io.lenses.core.telemetry.AlertsTelemetryFnTest",
          "time": 1071,
          "failure": null,
          "error": null,
          "skipped": false
        },
        {
          "name": "buildTelemetry should flatten conditional rules",
          "classname": "io.lenses.core.telemetry.AlertsTelemetryFnTest",
          "time": 18,
          "failure": null,
          "error": null,
          "skipped": false
        },
        {
          "name": "buildTelemetry should show a rule in all channels it applies to",
          "classname": "io.lenses.core.telemetry.AlertsTelemetryFnTest",
          "time": 40,
          "failure": null,
          "error": null,
          "skipped": false
        },
        {
          "name": "buildTelemetry should show channels without rule assignments",
          "classname": "io.lenses.core.telemetry.AlertsTelemetryFnTest",
          "time": 21,
          "failure": null,
          "error": null,
          "skipped": false
        }
      ]
    },
    {
      "time": 5,
      "tests": 8,
      "failures": 0,
      "errors": 0,
      "skipped": 0,
      "name": "io.lenses.core.avro.AvroDatasetFieldFlattenerTest",
      "timestamp": "2020-07-26T21:54:51",
      "testcase": [
        {
          "name": "not return any fields when an INT primitive type is involved",
          "classname": "io.lenses.core.avro.AvroDatasetFieldFlattenerTest",
          "time": 0,
          "failure": null,
          "error": null,
          "skipped": false
        },
        {
          "name": "not return any fields when a optional n INT primitive type is involved",
          "classname": "io.lenses.core.avro.AvroDatasetFieldFlattenerTest",
          "time": 0,
          "failure": null,
          "error": null,
          "skipped": false
        },
        {
          "name": "not return any fields when a STRING primitive type is involved",
          "classname": "io.lenses.core.avro.AvroDatasetFieldFlattenerTest",
          "time": 0,
          "failure": null,
          "error": null,
          "skipped": false
        },
        {
          "name": "not return any fields when a MAP type with private value is involved",
          "classname": "io.lenses.core.avro.AvroDatasetFieldFlattenerTest",
          "time": 0,
          "failure": null,
          "error": null,
          "skipped": false
        },
        {
          "name": "not return any fields when a MAP type with a string value involved",
          "classname": "io.lenses.core.avro.AvroDatasetFieldFlattenerTest",
          "time": 0,
          "failure": null,
          "error": null,
          "skipped": false
        },
        {
          "name": "not return any fields when a MAP type with a struct value involved",
          "classname": "io.lenses.core.avro.AvroDatasetFieldFlattenerTest",
          "time": 2,
          "failure": null,
          "error": null,
          "skipped": false
        },
        {
          "name": "return record fields with the expected field types, docs and ancestors",
          "classname": "io.lenses.core.avro.AvroDatasetFieldFlattenerTest",
          "time": 2,
          "failure": null,
          "error": null,
          "skipped": false
        },
        {
          "name": "recursive case",
          "classname": "io.lenses.core.avro.AvroDatasetFieldFlattenerTest",
          "time": 1,
          "failure": null,
          "error": null,
          "skipped": false
        }
      ]
    },
    {
      "time": 0,
      "tests": 0,
      "failures": 0,
      "errors": 0,
      "skipped": 0,
      "name": "io.lenses.core.utils.HttpClientSSLTest",
      "timestamp": "2020-07-26T21:54:44",
      "testcase": []
    },
    {
      "time": 6043,
      "tests": 7,
      "failures": 0,
      "errors": 0,
      "skipped": 0,
      "name": "io.lenses.core.metrics.KafkaDataProducedAlertTriggerPipeTest",
      "timestamp": "2020-07-26T21:54:43",
      "testcase": [
        {
          "name": "KafkaDataProducedAlertTriggerPipe should produce trigger containing correct messageCount for condition duration",
          "classname": "io.lenses.core.metrics.KafkaDataProducedAlertTriggerPipeTest",
          "time": 2206,
          "failure": null,
          "error": null,
          "skipped": false
        },
        {
          "name": "KafkaDataProducedAlertTriggerPipe should raise multiple triggers when multiple topics updated",
          "classname": "io.lenses.core.metrics.KafkaDataProducedAlertTriggerPipeTest",
          "time": 892,
          "failure": null,
          "error": null,
          "skipped": false
        },
        {
          "name": "KafkaDataProducedAlertTriggerPipe should raise multiple triggers when multiple alert rules for a topic",
          "classname": "io.lenses.core.metrics.KafkaDataProducedAlertTriggerPipeTest",
          "time": 816,
          "failure": null,
          "error": null,
          "skipped": false
        },
        {
          "name": "KafkaDataProducedAlertTriggerPipe should not reevaluate more frequently than checkPeriod, when higher frequency data is present",
          "classname": "io.lenses.core.metrics.KafkaDataProducedAlertTriggerPipeTest",
          "time": 555,
          "failure": null,
          "error": null,
          "skipped": false
        },
        {
          "name": "KafkaDataProducedAlertTriggerPipe should not produce trigger when no previous data present",
          "classname": "io.lenses.core.metrics.KafkaDataProducedAlertTriggerPipeTest",
          "time": 559,
          "failure": null,
          "error": null,
          "skipped": false
        },
        {
          "name": "KafkaDataProducedAlertTriggerPipe should not produce trigger when data returned is too short a time period",
          "classname": "io.lenses.core.metrics.KafkaDataProducedAlertTriggerPipeTest",
          "time": 509,
          "failure": null,
          "error": null,
          "skipped": false
        },
        {
          "name": "KafkaDataProducedAlertTriggerPipe should not produce trigger when data returned is for too long a time period",
          "classname": "io.lenses.core.metrics.KafkaDataProducedAlertTriggerPipeTest",
          "time": 505,
          "failure": null,
          "error": null,
          "skipped": false
        }
      ]
    },
    {
      "time": 770,
      "tests": 3,
      "failures": 0,
      "errors": 0,
      "skipped": 0,
      "name": "io.lenses.core.audits.KafkaAuditLoggerTest",
      "timestamp": "2020-07-26T21:54:42",
      "testcase": [
        {
          "name": "KafkaAuditLogger should log audits to kafka producer",
          "classname": "io.lenses.core.audits.KafkaAuditLoggerTest",
          "time": 624,
          "failure": null,
          "error": null,
          "skipped": false
        },
        {
          "name": "KafkaAuditLogger should only complete when producer callback fires",
          "classname": "io.lenses.core.audits.KafkaAuditLoggerTest",
          "time": 64,
          "failure": null,
          "error": null,
          "skipped": false
        },
        {
          "name": "KafkaAuditLogger should fail if producer fails",
          "classname": "io.lenses.core.audits.KafkaAuditLoggerTest",
          "time": 82,
          "failure": null,
          "error": null,
          "skipped": false
        }
      ]
    }
  ],
  "failed": [
    {
      "time": 65372,
      "tests": 11,
      "failures": 3,
      "errors": 0,
      "skipped": 0,
      "name": "io.lenses.core.kafka.TopicCommandTest",
      "timestamp": "2020-07-26T21:54:37",
      "failedTestcases": [
        {
          "name": "createTopic should create a topic with compact cleanup policy",
          "classname": "io.lenses.core.kafka.TopicCommandTest",
          "time": 20011,
          "failure": {
            "message": null,
            "type": "java.util.concurrent.TimeoutException",
            "stackTrace": "java.util.concurrent.TimeoutException\n\tat org.apache.kafka.common.internals.KafkaFutureImpl$SingleWaiter.await(KafkaFutureImpl.java:108)\n\tat org.apache.kafka.common.internals.KafkaFutureImpl.get(KafkaFutureImpl.java:272)\n\tat io.lenses.core.kafka.TopicCommand$.$anonfun$createTopic$1(TopicCommand.scala:93)\n\tat io.lenses.domain.logging.MetricsSupport.timed(MetricsSupport.scala:22)\n\tat io.lenses.domain.logging.MetricsSupport.timed$(MetricsSupport.scala:20)\n\tat io.lenses.core.kafka.TopicCommand$.timed(TopicCommand.scala:47)\n\tat io.lenses.core.kafka.TopicCommand$.createTopic(TopicCommand.scala:58)\n\tat io.lenses.core.kafka.TopicCommandTest.$anonfun$new$8(TopicCommandTest.scala:105)\n\tat io.lenses.core.kafka.TopicCommandTest.$anonfun$new$8$adapted(TopicCommandTest.scala:96)\n\tat io.lenses.core.kafka.TopicCommandTest.testEnvironment$1(TopicCommandTest.scala:67)\n\tat io.lenses.core.kafka.TopicCommandTest.$anonfun$new$6(TopicCommandTest.scala:96)\n\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n\tat org.scalatest.OutcomeOf.outcomeOf(OutcomeOf.scala:85)\n\tat org.scalatest.OutcomeOf.outcomeOf$(OutcomeOf.scala:83)\n\tat org.scalatest.OutcomeOf$.outcomeOf(OutcomeOf.scala:104)\n\tat org.scalatest.Transformer.apply(Transformer.scala:22)\n\tat org.scalatest.Transformer.apply(Transformer.scala:20)\n\tat org.scalatest.wordspec.AnyWordSpecLike$$anon$3.apply(AnyWordSpecLike.scala:1076)\n\tat org.scalatest.TestSuite.withFixture(TestSuite.scala:196)\n\tat org.scalatest.TestSuite.withFixture$(TestSuite.scala:195)\n\tat org.scalatest.wordspec.AnyWordSpec.withFixture(AnyWordSpec.scala:1879)\n\tat org.scalatest.wordspec.AnyWordSpecLike.invokeWithFixture$1(AnyWordSpecLike.scala:1074)\n\tat org.scalatest.wordspec.AnyWordSpecLike.$anonfun$runTest$1(AnyWordSpecLike.scala:1086)\n\tat org.scalatest.SuperEngine.runTestImpl(Engine.scala:306)\n\tat org.scalatest.wordspec.AnyWordSpecLike.runTest(AnyWordSpecLike.scala:1086)\n\tat org.scalatest.wordspec.AnyWordSpecLike.runTest$(AnyWordSpecLike.scala:1068)\n\tat org.scalatest.wordspec.AnyWordSpec.runTest(AnyWordSpec.scala:1879)\n\tat org.scalatest.wordspec.AnyWordSpecLike.$anonfun$runTests$1(AnyWordSpecLike.scala:1145)\n\tat org.scalatest.SuperEngine.$anonfun$runTestsInBranch$1(Engine.scala:413)\n\tat scala.collection.immutable.List.foreach(List.scala:392)\n\tat org.scalatest.SuperEngine.traverseSubNodes$1(Engine.scala:401)\n\tat org.scalatest.SuperEngine.runTestsInBranch(Engine.scala:390)\n\tat org.scalatest.SuperEngine.$anonfun$runTestsInBranch$1(Engine.scala:427)\n\tat scala.collection.immutable.List.foreach(List.scala:392)\n\tat org.scalatest.SuperEngine.traverseSubNodes$1(Engine.scala:401)\n\tat org.scalatest.SuperEngine.runTestsInBranch(Engine.scala:396)\n\tat org.scalatest.SuperEngine.runTestsImpl(Engine.scala:475)\n\tat org.scalatest.wordspec.AnyWordSpecLike.runTests(AnyWordSpecLike.scala:1145)\n\tat org.scalatest.wordspec.AnyWordSpecLike.runTests$(AnyWordSpecLike.scala:1144)\n\tat org.scalatest.wordspec.AnyWordSpec.runTests(AnyWordSpec.scala:1879)\n\tat org.scalatest.Suite.run(Suite.scala:1112)\n\tat org.scalatest.Suite.run$(Suite.scala:1094)\n\tat org.scalatest.wordspec.AnyWordSpec.org$scalatest$wordspec$AnyWordSpecLike$$super$run(AnyWordSpec.scala:1879)\n\tat org.scalatest.wordspec.AnyWordSpecLike.$anonfun$run$1(AnyWordSpecLike.scala:1190)\n\tat org.scalatest.SuperEngine.runImpl(Engine.scala:535)\n\tat org.scalatest.wordspec.AnyWordSpecLike.run(AnyWordSpecLike.scala:1190)\n\tat org.scalatest.wordspec.AnyWordSpecLike.run$(AnyWordSpecLike.scala:1188)\n\tat io.lenses.core.kafka.TopicCommandTest.org$scalatest$BeforeAndAfterAll$$super$run(TopicCommandTest.scala:53)\n\tat org.scalatest.BeforeAndAfterAll.liftedTree1$1(BeforeAndAfterAll.scala:213)\n\tat org.scalatest.BeforeAndAfterAll.run(BeforeAndAfterAll.scala:210)\n\tat org.scalatest.BeforeAndAfterAll.run$(BeforeAndAfterAll.scala:208)\n\tat io.lenses.core.kafka.TopicCommandTest.run(TopicCommandTest.scala:53)\n\tat org.scalatest.tools.Framework.org$scalatest$tools$Framework$$runSuite(Framework.scala:318)\n\tat org.scalatest.tools.Framework$ScalaTestTask.execute(Framework.scala:513)\n\tat sbt.TestRunner.runTest$1(TestFramework.scala:139)\n\tat sbt.TestRunner.run(TestFramework.scala:154)\n\tat sbt.TestFramework$$anon$3$$anonfun$$lessinit$greater$1.$anonfun$apply$1(TestFramework.scala:317)\n\tat sbt.TestFramework$.sbt$TestFramework$$withContextLoader(TestFramework.scala:277)\n\tat sbt.TestFramework$$anon$3$$anonfun$$lessinit$greater$1.apply(TestFramework.scala:317)\n\tat sbt.TestFramework$$anon$3$$anonfun$$lessinit$greater$1.apply(TestFramework.scala:317)\n\tat sbt.TestFunction.apply(TestFramework.scala:329)\n\tat sbt.Tests$.$anonfun$toTask$1(Tests.scala:311)\n\tat sbt.std.Transform$$anon$3.$anonfun$apply$2(Transform.scala:46)\n\tat sbt.std.Transform$$anon$4.work(Transform.scala:67)\n\tat sbt.Execute.$anonfun$submit$2(Execute.scala:281)\n\tat sbt.internal.util.ErrorHandling$.wideConvert(ErrorHandling.scala:19)\n\tat sbt.Execute.work(Execute.scala:290)\n\tat sbt.Execute.$anonfun$submit$1(Execute.scala:281)\n\tat sbt.ConcurrentRestrictions$$anon$4.$anonfun$submitValid$1(ConcurrentRestrictions.scala:178)\n\tat sbt.CompletionService$$anon$2.call(CompletionService.scala:37)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:748)"
          }
        },
        {
          "name": "type CreateTime",
          "classname": "io.lenses.core.kafka.TopicCommandTest",
          "time": 20010,
          "failure": {
            "message": null,
            "type": "java.util.concurrent.TimeoutException",
            "stackTrace": "java.util.concurrent.TimeoutException\n\tat org.apache.kafka.common.internals.KafkaFutureImpl$SingleWaiter.await(KafkaFutureImpl.java:108)\n\tat org.apache.kafka.common.internals.KafkaFutureImpl.get(KafkaFutureImpl.java:272)\n\tat io.lenses.core.kafka.TopicCommand$.$anonfun$createTopic$1(TopicCommand.scala:93)\n\tat io.lenses.domain.logging.MetricsSupport.timed(MetricsSupport.scala:22)\n\tat io.lenses.domain.logging.MetricsSupport.timed$(MetricsSupport.scala:20)\n\tat io.lenses.core.kafka.TopicCommand$.timed(TopicCommand.scala:47)\n\tat io.lenses.core.kafka.TopicCommand$.createTopic(TopicCommand.scala:58)\n\tat io.lenses.core.kafka.TopicCommandTest.$anonfun$new$13(TopicCommandTest.scala:125)\n\tat io.lenses.core.kafka.TopicCommandTest.$anonfun$new$13$adapted(TopicCommandTest.scala:118)\n\tat io.lenses.core.kafka.TopicCommandTest.testEnvironment$1(TopicCommandTest.scala:67)\n\tat io.lenses.core.kafka.TopicCommandTest.$anonfun$new$11(TopicCommandTest.scala:118)\n\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n\tat org.scalatest.OutcomeOf.outcomeOf(OutcomeOf.scala:85)\n\tat org.scalatest.OutcomeOf.outcomeOf$(OutcomeOf.scala:83)\n\tat org.scalatest.OutcomeOf$.outcomeOf(OutcomeOf.scala:104)\n\tat org.scalatest.Transformer.apply(Transformer.scala:22)\n\tat org.scalatest.Transformer.apply(Transformer.scala:20)\n\tat org.scalatest.wordspec.AnyWordSpecLike$$anon$3.apply(AnyWordSpecLike.scala:1076)\n\tat org.scalatest.TestSuite.withFixture(TestSuite.scala:196)\n\tat org.scalatest.TestSuite.withFixture$(TestSuite.scala:195)\n\tat org.scalatest.wordspec.AnyWordSpec.withFixture(AnyWordSpec.scala:1879)\n\tat org.scalatest.wordspec.AnyWordSpecLike.invokeWithFixture$1(AnyWordSpecLike.scala:1074)\n\tat org.scalatest.wordspec.AnyWordSpecLike.$anonfun$runTest$1(AnyWordSpecLike.scala:1086)\n\tat org.scalatest.SuperEngine.runTestImpl(Engine.scala:306)\n\tat org.scalatest.wordspec.AnyWordSpecLike.runTest(AnyWordSpecLike.scala:1086)\n\tat org.scalatest.wordspec.AnyWordSpecLike.runTest$(AnyWordSpecLike.scala:1068)\n\tat org.scalatest.wordspec.AnyWordSpec.runTest(AnyWordSpec.scala:1879)\n\tat org.scalatest.wordspec.AnyWordSpecLike.$anonfun$runTests$1(AnyWordSpecLike.scala:1145)\n\tat org.scalatest.SuperEngine.$anonfun$runTestsInBranch$1(Engine.scala:413)\n\tat scala.collection.immutable.List.foreach(List.scala:392)\n\tat org.scalatest.SuperEngine.traverseSubNodes$1(Engine.scala:401)\n\tat org.scalatest.SuperEngine.runTestsInBranch(Engine.scala:390)\n\tat org.scalatest.SuperEngine.$anonfun$runTestsInBranch$1(Engine.scala:427)\n\tat scala.collection.immutable.List.foreach(List.scala:392)\n\tat org.scalatest.SuperEngine.traverseSubNodes$1(Engine.scala:401)\n\tat org.scalatest.SuperEngine.runTestsInBranch(Engine.scala:396)\n\tat org.scalatest.SuperEngine.runTestsImpl(Engine.scala:475)\n\tat org.scalatest.wordspec.AnyWordSpecLike.runTests(AnyWordSpecLike.scala:1145)\n\tat org.scalatest.wordspec.AnyWordSpecLike.runTests$(AnyWordSpecLike.scala:1144)\n\tat org.scalatest.wordspec.AnyWordSpec.runTests(AnyWordSpec.scala:1879)\n\tat org.scalatest.Suite.run(Suite.scala:1112)\n\tat org.scalatest.Suite.run$(Suite.scala:1094)\n\tat org.scalatest.wordspec.AnyWordSpec.org$scalatest$wordspec$AnyWordSpecLike$$super$run(AnyWordSpec.scala:1879)\n\tat org.scalatest.wordspec.AnyWordSpecLike.$anonfun$run$1(AnyWordSpecLike.scala:1190)\n\tat org.scalatest.SuperEngine.runImpl(Engine.scala:535)\n\tat org.scalatest.wordspec.AnyWordSpecLike.run(AnyWordSpecLike.scala:1190)\n\tat org.scalatest.wordspec.AnyWordSpecLike.run$(AnyWordSpecLike.scala:1188)\n\tat io.lenses.core.kafka.TopicCommandTest.org$scalatest$BeforeAndAfterAll$$super$run(TopicCommandTest.scala:53)\n\tat org.scalatest.BeforeAndAfterAll.liftedTree1$1(BeforeAndAfterAll.scala:213)\n\tat org.scalatest.BeforeAndAfterAll.run(BeforeAndAfterAll.scala:210)\n\tat org.scalatest.BeforeAndAfterAll.run$(BeforeAndAfterAll.scala:208)\n\tat io.lenses.core.kafka.TopicCommandTest.run(TopicCommandTest.scala:53)\n\tat org.scalatest.tools.Framework.org$scalatest$tools$Framework$$runSuite(Framework.scala:318)\n\tat org.scalatest.tools.Framework$ScalaTestTask.execute(Framework.scala:513)\n\tat sbt.TestRunner.runTest$1(TestFramework.scala:139)\n\tat sbt.TestRunner.run(TestFramework.scala:154)\n\tat sbt.TestFramework$$anon$3$$anonfun$$lessinit$greater$1.$anonfun$apply$1(TestFramework.scala:317)\n\tat sbt.TestFramework$.sbt$TestFramework$$withContextLoader(TestFramework.scala:277)\n\tat sbt.TestFramework$$anon$3$$anonfun$$lessinit$greater$1.apply(TestFramework.scala:317)\n\tat sbt.TestFramework$$anon$3$$anonfun$$lessinit$greater$1.apply(TestFramework.scala:317)\n\tat sbt.TestFunction.apply(TestFramework.scala:329)\n\tat sbt.Tests$.$anonfun$toTask$1(Tests.scala:311)\n\tat sbt.std.Transform$$anon$3.$anonfun$apply$2(Transform.scala:46)\n\tat sbt.std.Transform$$anon$4.work(Transform.scala:67)\n\tat sbt.Execute.$anonfun$submit$2(Execute.scala:281)\n\tat sbt.internal.util.ErrorHandling$.wideConvert(ErrorHandling.scala:19)\n\tat sbt.Execute.work(Execute.scala:290)\n\tat sbt.Execute.$anonfun$submit$1(Execute.scala:281)\n\tat sbt.ConcurrentRestrictions$$anon$4.$anonfun$submitValid$1(ConcurrentRestrictions.scala:178)\n\tat sbt.CompletionService$$anon$2.call(CompletionService.scala:37)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:748)"
          }
        },
        {
          "name": "createTopic should update topic config, preserving default values",
          "classname": "io.lenses.core.kafka.TopicCommandTest",
          "time": 25044,
          "failure": {
            "message": null,
            "type": "java.util.concurrent.TimeoutException",
            "stackTrace": "java.util.concurrent.TimeoutException\n\tat org.apache.kafka.common.internals.KafkaFutureImpl$SingleWaiter.await(KafkaFutureImpl.java:108)\n\tat org.apache.kafka.common.internals.KafkaFutureImpl.get(KafkaFutureImpl.java:272)\n\tat io.lenses.core.kafka.TopicCommand$.$anonfun$createTopic$1(TopicCommand.scala:93)\n\tat io.lenses.domain.logging.MetricsSupport.timed(MetricsSupport.scala:22)\n\tat io.lenses.domain.logging.MetricsSupport.timed$(MetricsSupport.scala:20)\n\tat io.lenses.core.kafka.TopicCommand$.timed(TopicCommand.scala:47)\n\tat io.lenses.core.kafka.TopicCommand$.createTopic(TopicCommand.scala:58)\n\tat io.lenses.core.kafka.TopicCommandTest.$anonfun$new$19(TopicCommandTest.scala:145)\n\tat io.lenses.core.kafka.TopicCommandTest.withKafkaTableRepository(TopicCommandTest.scala:341)\n\tat io.lenses.core.kafka.TopicCommandTest.$anonfun$new$18(TopicCommandTest.scala:144)\n\tat io.lenses.core.kafka.TopicCommandTest.testEnvironment$1(TopicCommandTest.scala:67)\n\tat io.lenses.core.kafka.TopicCommandTest.$anonfun$new$16(TopicCommandTest.scala:138)\n\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n\tat org.scalatest.OutcomeOf.outcomeOf(OutcomeOf.scala:85)\n\tat org.scalatest.OutcomeOf.outcomeOf$(OutcomeOf.scala:83)\n\tat org.scalatest.OutcomeOf$.outcomeOf(OutcomeOf.scala:104)\n\tat org.scalatest.Transformer.apply(Transformer.scala:22)\n\tat org.scalatest.Transformer.apply(Transformer.scala:20)\n\tat org.scalatest.wordspec.AnyWordSpecLike$$anon$3.apply(AnyWordSpecLike.scala:1076)\n\tat org.scalatest.TestSuite.withFixture(TestSuite.scala:196)\n\tat org.scalatest.TestSuite.withFixture$(TestSuite.scala:195)\n\tat org.scalatest.wordspec.AnyWordSpec.withFixture(AnyWordSpec.scala:1879)\n\tat org.scalatest.wordspec.AnyWordSpecLike.invokeWithFixture$1(AnyWordSpecLike.scala:1074)\n\tat org.scalatest.wordspec.AnyWordSpecLike.$anonfun$runTest$1(AnyWordSpecLike.scala:1086)\n\tat org.scalatest.SuperEngine.runTestImpl(Engine.scala:306)\n\tat org.scalatest.wordspec.AnyWordSpecLike.runTest(AnyWordSpecLike.scala:1086)\n\tat org.scalatest.wordspec.AnyWordSpecLike.runTest$(AnyWordSpecLike.scala:1068)\n\tat org.scalatest.wordspec.AnyWordSpec.runTest(AnyWordSpec.scala:1879)\n\tat org.scalatest.wordspec.AnyWordSpecLike.$anonfun$runTests$1(AnyWordSpecLike.scala:1145)\n\tat org.scalatest.SuperEngine.$anonfun$runTestsInBranch$1(Engine.scala:413)\n\tat scala.collection.immutable.List.foreach(List.scala:392)\n\tat org.scalatest.SuperEngine.traverseSubNodes$1(Engine.scala:401)\n\tat org.scalatest.SuperEngine.runTestsInBranch(Engine.scala:390)\n\tat org.scalatest.SuperEngine.$anonfun$runTestsInBranch$1(Engine.scala:427)\n\tat scala.collection.immutable.List.foreach(List.scala:392)\n\tat org.scalatest.SuperEngine.traverseSubNodes$1(Engine.scala:401)\n\tat org.scalatest.SuperEngine.runTestsInBranch(Engine.scala:396)\n\tat org.scalatest.SuperEngine.runTestsImpl(Engine.scala:475)\n\tat org.scalatest.wordspec.AnyWordSpecLike.runTests(AnyWordSpecLike.scala:1145)\n\tat org.scalatest.wordspec.AnyWordSpecLike.runTests$(AnyWordSpecLike.scala:1144)\n\tat org.scalatest.wordspec.AnyWordSpec.runTests(AnyWordSpec.scala:1879)\n\tat org.scalatest.Suite.run(Suite.scala:1112)\n\tat org.scalatest.Suite.run$(Suite.scala:1094)\n\tat org.scalatest.wordspec.AnyWordSpec.org$scalatest$wordspec$AnyWordSpecLike$$super$run(AnyWordSpec.scala:1879)\n\tat org.scalatest.wordspec.AnyWordSpecLike.$anonfun$run$1(AnyWordSpecLike.scala:1190)\n\tat org.scalatest.SuperEngine.runImpl(Engine.scala:535)\n\tat org.scalatest.wordspec.AnyWordSpecLike.run(AnyWordSpecLike.scala:1190)\n\tat org.scalatest.wordspec.AnyWordSpecLike.run$(AnyWordSpecLike.scala:1188)\n\tat io.lenses.core.kafka.TopicCommandTest.org$scalatest$BeforeAndAfterAll$$super$run(TopicCommandTest.scala:53)\n\tat org.scalatest.BeforeAndAfterAll.liftedTree1$1(BeforeAndAfterAll.scala:213)\n\tat org.scalatest.BeforeAndAfterAll.run(BeforeAndAfterAll.scala:210)\n\tat org.scalatest.BeforeAndAfterAll.run$(BeforeAndAfterAll.scala:208)\n\tat io.lenses.core.kafka.TopicCommandTest.run(TopicCommandTest.scala:53)\n\tat org.scalatest.tools.Framework.org$scalatest$tools$Framework$$runSuite(Framework.scala:318)\n\tat org.scalatest.tools.Framework$ScalaTestTask.execute(Framework.scala:513)\n\tat sbt.TestRunner.runTest$1(TestFramework.scala:139)\n\tat sbt.TestRunner.run(TestFramework.scala:154)\n\tat sbt.TestFramework$$anon$3$$anonfun$$lessinit$greater$1.$anonfun$apply$1(TestFramework.scala:317)\n\tat sbt.TestFramework$.sbt$TestFramework$$withContextLoader(TestFramework.scala:277)\n\tat sbt.TestFramework$$anon$3$$anonfun$$lessinit$greater$1.apply(TestFramework.scala:317)\n\tat sbt.TestFramework$$anon$3$$anonfun$$lessinit$greater$1.apply(TestFramework.scala:317)\n\tat sbt.TestFunction.apply(TestFramework.scala:329)\n\tat sbt.Tests$.$anonfun$toTask$1(Tests.scala:311)\n\tat sbt.std.Transform$$anon$3.$anonfun$apply$2(Transform.scala:46)\n\tat sbt.std.Transform$$anon$4.work(Transform.scala:67)\n\tat sbt.Execute.$anonfun$submit$2(Execute.scala:281)\n\tat sbt.internal.util.ErrorHandling$.wideConvert(ErrorHandling.scala:19)\n\tat sbt.Execute.work(Execute.scala:290)\n\tat sbt.Execute.$anonfun$submit$1(Execute.scala:281)\n\tat sbt.ConcurrentRestrictions$$anon$4.$anonfun$submitValid$1(ConcurrentRestrictions.scala:178)\n\tat sbt.CompletionService$$anon$2.call(CompletionService.scala:37)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:748)"
          }
        }
      ]
    },
    {
      "time": 120086,
      "tests": 6,
      "failures": 1,
      "errors": 0,
      "skipped": 0,
      "name": "io.lenses.core.lsql.JdbcRoutesControllerInsertStatementTest",
      "timestamp": "2020-07-26T21:54:39",
      "failedTestcases": [
        {
          "name": "handlePrepareStatementData should return partition and offset info",
          "classname": "io.lenses.core.lsql.JdbcRoutesControllerInsertStatementTest",
          "time": 120068,
          "failure": {
            "message": "Topic myTopic not present in metadata after 60000 ms.",
            "type": "org.apache.kafka.common.errors.TimeoutException",
            "stackTrace": "org.apache.kafka.common.errors.TimeoutException: Topic myTopic not present in metadata after 60000 ms."
          }
        }
      ]
    },
    {
      "time": 255755,
      "tests": 5,
      "failures": 4,
      "errors": 0,
      "skipped": 0,
      "name": "io.lenses.core.kafka.admin.KafkaAdminClientImplSpec",
      "timestamp": "2020-07-26T21:54:37",
      "failedTestcases": [
        {
          "name": "describeCluster should returns the Kafka cluster description",
          "classname": "io.lenses.core.kafka.admin.KafkaAdminClientImplSpec",
          "time": 5728,
          "failure": {
            "message": "Timed out waiting for a node assignment.",
            "type": "org.apache.kafka.common.errors.TimeoutException",
            "stackTrace": "org.apache.kafka.common.errors.TimeoutException: Timed out waiting for a node assignment."
          }
        },
        {
          "name": "describeLogDirs should returns logDir info by broker id",
          "classname": "io.lenses.core.kafka.admin.KafkaAdminClientImplSpec",
          "time": 5014,
          "failure": {
            "message": "Set() was not equal to Set(0)",
            "type": "org.scalatest.exceptions.TestFailedException",
            "stackTrace": "org.scalatest.exceptions.TestFailedException: Set() was not equal to Set(0)\n\tat org.scalatest.matchers.MatchersHelper$.indicateFailure(MatchersHelper.scala:339)\n\tat org.scalatest.matchers.should.Matchers$AnyShouldWrapper.shouldBe(Matchers.scala:6982)\n\tat io.lenses.core.kafka.admin.KafkaAdminClientImplSpec.$anonfun$new$8(KafkaAdminClientImplSpec.scala:34)\n\tat cats.effect.IO$Map.apply(IO.scala:1504)\n\tat cats.effect.IO$Map.apply(IO.scala:1502)\n\tat cats.effect.internals.IORunLoop$.cats$effect$internals$IORunLoop$$loop(IORunLoop.scala:142)\n\tat cats.effect.internals.IORunLoop$RestartCallback.signal(IORunLoop.scala:361)\n\tat cats.effect.internals.IORunLoop$RestartCallback.apply(IORunLoop.scala:380)\n\tat cats.effect.internals.IORunLoop$RestartCallback.apply(IORunLoop.scala:323)\n\tat cats.effect.internals.Callback$AsyncIdempotentCallback.run(Callback.scala:130)\n\tat cats.effect.internals.Trampoline.cats$effect$internals$Trampoline$$immediateLoop(Trampoline.scala:67)\n\tat cats.effect.internals.Trampoline.startLoop(Trampoline.scala:35)\n\tat cats.effect.internals.TrampolineEC$JVMTrampoline.super$startLoop(TrampolineEC.scala:89)\n\tat cats.effect.internals.TrampolineEC$JVMTrampoline.$anonfun$startLoop$1(TrampolineEC.scala:89)\n\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n\tat cats.effect.internals.TrampolineEC$JVMTrampoline.startLoop(TrampolineEC.scala:89)\n\tat cats.effect.internals.Trampoline.execute(Trampoline.scala:43)\n\tat cats.effect.internals.TrampolineEC.execute(TrampolineEC.scala:42)\n\tat cats.effect.internals.Callback$AsyncIdempotentCallback.apply(Callback.scala:136)\n\tat cats.effect.internals.Callback$AsyncIdempotentCallback.apply(Callback.scala:125)\n\tat io.lenses.core.kafka.admin.KafkaAdminClientImpl.$anonfun$describeLogDirs$8(KafkaAdminClientImpl.scala:145)\n\tat io.lenses.core.kafka.admin.KafkaAdminClientImpl.$anonfun$describeLogDirs$8$adapted(KafkaAdminClientImpl.scala:145)\n\tat io.lenses.core.kafka.KafkaFutureOps$Wrapper.$anonfun$asyncComplete$1(KafkaFutureOps.scala:14)\n\tat org.apache.kafka.common.internals.KafkaFutureImpl$WhenCompleteBiConsumer.accept(KafkaFutureImpl.java:175)\n\tat org.apache.kafka.common.internals.KafkaFutureImpl$WhenCompleteBiConsumer.accept(KafkaFutureImpl.java:162)\n\tat org.apache.kafka.common.internals.KafkaFutureImpl.completeExceptionally(KafkaFutureImpl.java:238)\n\tat org.apache.kafka.clients.admin.KafkaAdminClient.completeAllExceptionally(KafkaAdminClient.java:287)\n\tat org.apache.kafka.clients.admin.KafkaAdminClient.access$2300(KafkaAdminClient.java:181)\n\tat org.apache.kafka.clients.admin.KafkaAdminClient$14.handleFailure(KafkaAdminClient.java:2134)\n\tat org.apache.kafka.clients.admin.KafkaAdminClient$Call.fail(KafkaAdminClient.java:641)\n\tat org.apache.kafka.clients.admin.KafkaAdminClient$TimeoutProcessor.handleTimeouts(KafkaAdminClient.java:757)\n\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.timeoutPendingCalls(KafkaAdminClient.java:825)\n\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.run(KafkaAdminClient.java:1119)\n\tat java.lang.Thread.run(Thread.java:748)"
          }
        },
        {
          "name": "describeLogDirs should omits the log dir info when a broker lookup fails",
          "classname": "io.lenses.core.kafka.admin.KafkaAdminClientImplSpec",
          "time": 5004,
          "failure": {
            "message": "Set() was not equal to Set(0)",
            "type": "org.scalatest.exceptions.TestFailedException",
            "stackTrace": "org.scalatest.exceptions.TestFailedException: Set() was not equal to Set(0)\n\tat org.scalatest.matchers.MatchersHelper$.indicateFailure(MatchersHelper.scala:339)\n\tat org.scalatest.matchers.should.Matchers$AnyShouldWrapper.shouldBe(Matchers.scala:6982)\n\tat io.lenses.core.kafka.admin.KafkaAdminClientImplSpec.$anonfun$new$11(KafkaAdminClientImplSpec.scala:41)\n\tat cats.effect.IO$Map.apply(IO.scala:1504)\n\tat cats.effect.IO$Map.apply(IO.scala:1502)\n\tat cats.effect.internals.IORunLoop$.cats$effect$internals$IORunLoop$$loop(IORunLoop.scala:142)\n\tat cats.effect.internals.IORunLoop$RestartCallback.signal(IORunLoop.scala:361)\n\tat cats.effect.internals.IORunLoop$RestartCallback.apply(IORunLoop.scala:380)\n\tat cats.effect.internals.IORunLoop$RestartCallback.apply(IORunLoop.scala:323)\n\tat cats.effect.internals.Callback$AsyncIdempotentCallback.run(Callback.scala:130)\n\tat cats.effect.internals.Trampoline.cats$effect$internals$Trampoline$$immediateLoop(Trampoline.scala:67)\n\tat cats.effect.internals.Trampoline.startLoop(Trampoline.scala:35)\n\tat cats.effect.internals.TrampolineEC$JVMTrampoline.super$startLoop(TrampolineEC.scala:89)\n\tat cats.effect.internals.TrampolineEC$JVMTrampoline.$anonfun$startLoop$1(TrampolineEC.scala:89)\n\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n\tat cats.effect.internals.TrampolineEC$JVMTrampoline.startLoop(TrampolineEC.scala:89)\n\tat cats.effect.internals.Trampoline.execute(Trampoline.scala:43)\n\tat cats.effect.internals.TrampolineEC.execute(TrampolineEC.scala:42)\n\tat cats.effect.internals.Callback$AsyncIdempotentCallback.apply(Callback.scala:136)\n\tat cats.effect.internals.Callback$AsyncIdempotentCallback.apply(Callback.scala:125)\n\tat io.lenses.core.kafka.admin.KafkaAdminClientImpl.$anonfun$describeLogDirs$8(KafkaAdminClientImpl.scala:145)\n\tat io.lenses.core.kafka.admin.KafkaAdminClientImpl.$anonfun$describeLogDirs$8$adapted(KafkaAdminClientImpl.scala:145)\n\tat io.lenses.core.kafka.KafkaFutureOps$Wrapper.$anonfun$asyncComplete$1(KafkaFutureOps.scala:14)\n\tat org.apache.kafka.common.internals.KafkaFutureImpl$WhenCompleteBiConsumer.accept(KafkaFutureImpl.java:175)\n\tat org.apache.kafka.common.internals.KafkaFutureImpl$WhenCompleteBiConsumer.accept(KafkaFutureImpl.java:162)\n\tat org.apache.kafka.common.internals.KafkaFutureImpl.completeExceptionally(KafkaFutureImpl.java:238)\n\tat org.apache.kafka.clients.admin.KafkaAdminClient.completeAllExceptionally(KafkaAdminClient.java:287)\n\tat org.apache.kafka.clients.admin.KafkaAdminClient.access$2300(KafkaAdminClient.java:181)\n\tat org.apache.kafka.clients.admin.KafkaAdminClient$14.handleFailure(KafkaAdminClient.java:2134)\n\tat org.apache.kafka.clients.admin.KafkaAdminClient$Call.fail(KafkaAdminClient.java:641)\n\tat org.apache.kafka.clients.admin.KafkaAdminClient$TimeoutProcessor.handleTimeouts(KafkaAdminClient.java:757)\n\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.timeoutPendingCalls(KafkaAdminClient.java:825)\n\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.run(KafkaAdminClient.java:1119)\n\tat java.lang.Thread.run(Thread.java:748)"
          }
        },
        {
          "name": "describeTopics should return a key for an existing topic",
          "classname": "io.lenses.core.kafka.admin.KafkaAdminClientImplSpec",
          "time": 120005,
          "failure": {
            "message": "false did not equal true",
            "type": "org.scalatest.exceptions.TestFailedException",
            "stackTrace": "org.scalatest.exceptions.TestFailedException: false did not equal true\n\tat org.scalatest.matchers.MatchersHelper$.indicateFailure(MatchersHelper.scala:344)\n\tat org.scalatest.matchers.should.Matchers$AnyShouldWrapper.shouldEqual(Matchers.scala:6860)\n\tat io.lenses.core.kafka.admin.KafkaAdminClientImplSpec.$anonfun$new$18(KafkaAdminClientImplSpec.scala:56)\n\tat scala.Function1.$anonfun$andThen$1(Function1.scala:57)\n\tat cats.effect.IO$Map.apply(IO.scala:1504)\n\tat cats.effect.IO$Map.apply(IO.scala:1502)\n\tat cats.effect.internals.IORunLoop$.cats$effect$internals$IORunLoop$$loop(IORunLoop.scala:142)\n\tat cats.effect.internals.IORunLoop$RestartCallback.signal(IORunLoop.scala:361)\n\tat cats.effect.internals.IORunLoop$RestartCallback.apply(IORunLoop.scala:380)\n\tat cats.effect.internals.IORunLoop$RestartCallback.apply(IORunLoop.scala:323)\n\tat cats.effect.internals.Callback$AsyncIdempotentCallback.run(Callback.scala:130)\n\tat cats.effect.internals.Trampoline.cats$effect$internals$Trampoline$$immediateLoop(Trampoline.scala:67)\n\tat cats.effect.internals.Trampoline.startLoop(Trampoline.scala:35)\n\tat cats.effect.internals.TrampolineEC$JVMTrampoline.super$startLoop(TrampolineEC.scala:89)\n\tat cats.effect.internals.TrampolineEC$JVMTrampoline.$anonfun$startLoop$1(TrampolineEC.scala:89)\n\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n\tat cats.effect.internals.TrampolineEC$JVMTrampoline.startLoop(TrampolineEC.scala:89)\n\tat cats.effect.internals.Trampoline.execute(Trampoline.scala:43)\n\tat cats.effect.internals.TrampolineEC.execute(TrampolineEC.scala:42)\n\tat cats.effect.internals.Callback$AsyncIdempotentCallback.apply(Callback.scala:136)\n\tat cats.effect.internals.Callback$AsyncIdempotentCallback.apply(Callback.scala:125)\n\tat io.lenses.core.kafka.admin.KafkaAdminClientImpl.$anonfun$describeTopics$3(KafkaAdminClientImpl.scala:114)\n\tat io.lenses.core.kafka.admin.KafkaAdminClientImpl.$anonfun$describeTopics$3$adapted(KafkaAdminClientImpl.scala:114)\n\tat io.lenses.core.kafka.KafkaFutureOps$Wrapper.$anonfun$asyncComplete$1(KafkaFutureOps.scala:14)\n\tat org.apache.kafka.common.internals.KafkaFutureImpl$WhenCompleteBiConsumer.accept(KafkaFutureImpl.java:175)\n\tat org.apache.kafka.common.internals.KafkaFutureImpl$WhenCompleteBiConsumer.accept(KafkaFutureImpl.java:162)\n\tat org.apache.kafka.common.internals.KafkaFutureImpl.completeExceptionally(KafkaFutureImpl.java:238)\n\tat org.apache.kafka.clients.admin.KafkaAdminClient.completeAllExceptionally(KafkaAdminClient.java:287)\n\tat org.apache.kafka.clients.admin.KafkaAdminClient.access$2300(KafkaAdminClient.java:181)\n\tat org.apache.kafka.clients.admin.KafkaAdminClient$4.handleFailure(KafkaAdminClient.java:1545)\n\tat org.apache.kafka.clients.admin.KafkaAdminClient$Call.fail(KafkaAdminClient.java:641)\n\tat org.apache.kafka.clients.admin.KafkaAdminClient$TimeoutProcessor.handleTimeouts(KafkaAdminClient.java:757)\n\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.timeoutPendingCalls(KafkaAdminClient.java:825)\n\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.run(KafkaAdminClient.java:1119)\n\tat java.lang.Thread.run(Thread.java:748)"
          }
        }
      ]
    },
    {
      "time": 670279,
      "tests": 1,
      "failures": 1,
      "errors": 0,
      "skipped": 0,
      "name": "io.lenses.core.migration.AuditMigrationIntegrationTest",
      "timestamp": "2020-07-26T21:54:37",
      "failedTestcases": [
        {
          "name": "migrate audits to AuditStore",
          "classname": "io.lenses.core.migration.AuditMigrationIntegrationTest",
          "time": 670279,
          "failure": {
            "message": "java.lang.InterruptedException",
            "type": "org.apache.kafka.common.errors.InterruptException",
            "stackTrace": "org.apache.kafka.common.errors.InterruptException: java.lang.InterruptedException\n\tat org.apache.kafka.clients.producer.KafkaProducer.doSend(KafkaProducer.java:937)\n\tat org.apache.kafka.clients.producer.KafkaProducer.send(KafkaProducer.java:856)\n\tat org.apache.kafka.clients.producer.KafkaProducer.send(KafkaProducer.java:743)\n\tat io.lenses.core.migration.AuditMigrationIntegrationTest.$anonfun$new$2(AuditMigrationIntegrationTest.scala:67)\n\tat scala.collection.immutable.Stream.foreach(Stream.scala:533)\n\tat io.lenses.core.migration.AuditMigrationIntegrationTest.$anonfun$new$1(AuditMigrationIntegrationTest.scala:60)\n\tat org.scalatest.OutcomeOf.outcomeOf(OutcomeOf.scala:85)\n\tat org.scalatest.OutcomeOf.outcomeOf$(OutcomeOf.scala:83)\n\tat org.scalatest.OutcomeOf$.outcomeOf(OutcomeOf.scala:104)\n\tat org.scalatest.Transformer.apply(Transformer.scala:22)\n\tat org.scalatest.Transformer.apply(Transformer.scala:20)\n\tat org.scalatest.funsuite.AnyFunSuiteLike$$anon$1.apply(AnyFunSuiteLike.scala:189)\n\tat org.scalatest.TestSuite.withFixture(TestSuite.scala:196)\n\tat org.scalatest.TestSuite.withFixture$(TestSuite.scala:195)\n\tat org.scalatest.funsuite.AnyFunSuite.withFixture(AnyFunSuite.scala:1562)\n\tat org.scalatest.funsuite.AnyFunSuiteLike.invokeWithFixture$1(AnyFunSuiteLike.scala:187)\n\tat org.scalatest.funsuite.AnyFunSuiteLike.$anonfun$runTest$1(AnyFunSuiteLike.scala:199)\n\tat org.scalatest.SuperEngine.runTestImpl(Engine.scala:306)\n\tat org.scalatest.funsuite.AnyFunSuiteLike.runTest(AnyFunSuiteLike.scala:199)\n\tat org.scalatest.funsuite.AnyFunSuiteLike.runTest$(AnyFunSuiteLike.scala:181)\n\tat org.scalatest.funsuite.AnyFunSuite.runTest(AnyFunSuite.scala:1562)\n\tat org.scalatest.funsuite.AnyFunSuiteLike.$anonfun$runTests$1(AnyFunSuiteLike.scala:232)\n\tat org.scalatest.SuperEngine.$anonfun$runTestsInBranch$1(Engine.scala:413)\n\tat scala.collection.immutable.List.foreach(List.scala:392)\n\tat org.scalatest.SuperEngine.traverseSubNodes$1(Engine.scala:401)\n\tat org.scalatest.SuperEngine.runTestsInBranch(Engine.scala:396)\n\tat org.scalatest.SuperEngine.runTestsImpl(Engine.scala:475)\n\tat org.scalatest.funsuite.AnyFunSuiteLike.runTests(AnyFunSuiteLike.scala:232)\n\tat org.scalatest.funsuite.AnyFunSuiteLike.runTests$(AnyFunSuiteLike.scala:231)\n\tat org.scalatest.funsuite.AnyFunSuite.runTests(AnyFunSuite.scala:1562)\n\tat org.scalatest.Suite.run(Suite.scala:1112)\n\tat org.scalatest.Suite.run$(Suite.scala:1094)\n\tat org.scalatest.funsuite.AnyFunSuite.org$scalatest$funsuite$AnyFunSuiteLike$$super$run(AnyFunSuite.scala:1562)\n\tat org.scalatest.funsuite.AnyFunSuiteLike.$anonfun$run$1(AnyFunSuiteLike.scala:236)\n\tat org.scalatest.SuperEngine.runImpl(Engine.scala:535)\n\tat org.scalatest.funsuite.AnyFunSuiteLike.run(AnyFunSuiteLike.scala:236)\n\tat org.scalatest.funsuite.AnyFunSuiteLike.run$(AnyFunSuiteLike.scala:235)\n\tat org.scalatest.funsuite.AnyFunSuite.run(AnyFunSuite.scala:1562)\n\tat org.scalatest.tools.Framework.org$scalatest$tools$Framework$$runSuite(Framework.scala:318)\n\tat org.scalatest.tools.Framework$ScalaTestTask.execute(Framework.scala:513)\n\tat sbt.TestRunner.runTest$1(TestFramework.scala:139)\n\tat sbt.TestRunner.run(TestFramework.scala:154)\n\tat sbt.TestFramework$$anon$3$$anonfun$$lessinit$greater$1.$anonfun$apply$1(TestFramework.scala:317)\n\tat sbt.TestFramework$.sbt$TestFramework$$withContextLoader(TestFramework.scala:277)\n\tat sbt.TestFramework$$anon$3$$anonfun$$lessinit$greater$1.apply(TestFramework.scala:317)\n\tat sbt.TestFramework$$anon$3$$anonfun$$lessinit$greater$1.apply(TestFramework.scala:317)\n\tat sbt.TestFunction.apply(TestFramework.scala:329)\n\tat sbt.Tests$.$anonfun$toTask$1(Tests.scala:311)\n\tat sbt.std.Transform$$anon$3.$anonfun$apply$2(Transform.scala:46)\n\tat sbt.std.Transform$$anon$4.work(Transform.scala:67)\n\tat sbt.Execute.$anonfun$submit$2(Execute.scala:281)\n\tat sbt.internal.util.ErrorHandling$.wideConvert(ErrorHandling.scala:19)\n\tat sbt.Execute.work(Execute.scala:290)\n\tat sbt.Execute.$anonfun$submit$1(Execute.scala:281)\n\tat sbt.ConcurrentRestrictions$$anon$4.$anonfun$submitValid$1(ConcurrentRestrictions.scala:178)\n\tat sbt.CompletionService$$anon$2.call(CompletionService.scala:37)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:748)\nCaused by: java.lang.InterruptedException\n\tat java.lang.Object.wait(Native Method)\n\tat org.apache.kafka.common.utils.SystemTime.waitObject(SystemTime.java:60)\n\tat org.apache.kafka.clients.producer.internals.ProducerMetadata.awaitUpdate(ProducerMetadata.java:97)\n\tat org.apache.kafka.clients.producer.KafkaProducer.waitOnMetadata(KafkaProducer.java:999)\n\tat org.apache.kafka.clients.producer.KafkaProducer.doSend(KafkaProducer.java:876)\n\t... 61 more"
          }
        }
      ]
    },
    {
      "time": 240015,
      "tests": 2,
      "failures": 2,
      "errors": 0,
      "skipped": 0,
      "name": "io.lenses.core.kafka.admin.KafkaAdminClientCreateAndDeleteSpec",
      "timestamp": "2020-07-26T21:54:39",
      "failedTestcases": [
        {
          "name": "createTopics and deleteTopics should work as expected when all topics new",
          "classname": "io.lenses.core.kafka.admin.KafkaAdminClientCreateAndDeleteSpec",
          "time": 120008,
          "failure": {
            "message": "Timed out waiting for a node assignment.",
            "type": "org.apache.kafka.common.errors.TimeoutException",
            "stackTrace": "org.apache.kafka.common.errors.TimeoutException: Timed out waiting for a node assignment."
          }
        },
        {
          "name": "createTopics and deleteTopics should fail creating topics that are already present",
          "classname": "io.lenses.core.kafka.admin.KafkaAdminClientCreateAndDeleteSpec",
          "time": 120007,
          "failure": {
            "message": "Timed out waiting for a node assignment.",
            "type": "org.apache.kafka.common.errors.TimeoutException",
            "stackTrace": "org.apache.kafka.common.errors.TimeoutException: Timed out waiting for a node assignment."
          }
        }
      ]
    },
    {
      "time": 663080,
      "tests": 1,
      "failures": 1,
      "errors": 0,
      "skipped": 0,
      "name": "io.lenses.core.migration.AlertMigrationIntegrationTest",
      "timestamp": "2020-07-26T21:54:45",
      "failedTestcases": [
        {
          "name": "migrate alerts to AlertStore",
          "classname": "io.lenses.core.migration.AlertMigrationIntegrationTest",
          "time": 663080,
          "failure": {
            "message": "java.lang.InterruptedException",
            "type": "org.apache.kafka.common.errors.InterruptException",
            "stackTrace": "org.apache.kafka.common.errors.InterruptException: java.lang.InterruptedException\n\tat org.apache.kafka.clients.producer.KafkaProducer.doSend(KafkaProducer.java:937)\n\tat org.apache.kafka.clients.producer.KafkaProducer.send(KafkaProducer.java:856)\n\tat org.apache.kafka.clients.producer.KafkaProducer.send(KafkaProducer.java:743)\n\tat io.lenses.core.migration.AlertMigrationIntegrationTest.$anonfun$new$2(AlertMigrationIntegrationTest.scala:70)\n\tat scala.collection.immutable.Stream.foreach(Stream.scala:533)\n\tat io.lenses.core.migration.AlertMigrationIntegrationTest.$anonfun$new$1(AlertMigrationIntegrationTest.scala:62)\n\tat org.scalatest.OutcomeOf.outcomeOf(OutcomeOf.scala:85)\n\tat org.scalatest.OutcomeOf.outcomeOf$(OutcomeOf.scala:83)\n\tat org.scalatest.OutcomeOf$.outcomeOf(OutcomeOf.scala:104)\n\tat org.scalatest.Transformer.apply(Transformer.scala:22)\n\tat org.scalatest.Transformer.apply(Transformer.scala:20)\n\tat org.scalatest.funsuite.AnyFunSuiteLike$$anon$1.apply(AnyFunSuiteLike.scala:189)\n\tat org.scalatest.TestSuite.withFixture(TestSuite.scala:196)\n\tat org.scalatest.TestSuite.withFixture$(TestSuite.scala:195)\n\tat org.scalatest.funsuite.AnyFunSuite.withFixture(AnyFunSuite.scala:1562)\n\tat org.scalatest.funsuite.AnyFunSuiteLike.invokeWithFixture$1(AnyFunSuiteLike.scala:187)\n\tat org.scalatest.funsuite.AnyFunSuiteLike.$anonfun$runTest$1(AnyFunSuiteLike.scala:199)\n\tat org.scalatest.SuperEngine.runTestImpl(Engine.scala:306)\n\tat org.scalatest.funsuite.AnyFunSuiteLike.runTest(AnyFunSuiteLike.scala:199)\n\tat org.scalatest.funsuite.AnyFunSuiteLike.runTest$(AnyFunSuiteLike.scala:181)\n\tat org.scalatest.funsuite.AnyFunSuite.runTest(AnyFunSuite.scala:1562)\n\tat org.scalatest.funsuite.AnyFunSuiteLike.$anonfun$runTests$1(AnyFunSuiteLike.scala:232)\n\tat org.scalatest.SuperEngine.$anonfun$runTestsInBranch$1(Engine.scala:413)\n\tat scala.collection.immutable.List.foreach(List.scala:392)\n\tat org.scalatest.SuperEngine.traverseSubNodes$1(Engine.scala:401)\n\tat org.scalatest.SuperEngine.runTestsInBranch(Engine.scala:396)\n\tat org.scalatest.SuperEngine.runTestsImpl(Engine.scala:475)\n\tat org.scalatest.funsuite.AnyFunSuiteLike.runTests(AnyFunSuiteLike.scala:232)\n\tat org.scalatest.funsuite.AnyFunSuiteLike.runTests$(AnyFunSuiteLike.scala:231)\n\tat org.scalatest.funsuite.AnyFunSuite.runTests(AnyFunSuite.scala:1562)\n\tat org.scalatest.Suite.run(Suite.scala:1112)\n\tat org.scalatest.Suite.run$(Suite.scala:1094)\n\tat org.scalatest.funsuite.AnyFunSuite.org$scalatest$funsuite$AnyFunSuiteLike$$super$run(AnyFunSuite.scala:1562)\n\tat org.scalatest.funsuite.AnyFunSuiteLike.$anonfun$run$1(AnyFunSuiteLike.scala:236)\n\tat org.scalatest.SuperEngine.runImpl(Engine.scala:535)\n\tat org.scalatest.funsuite.AnyFunSuiteLike.run(AnyFunSuiteLike.scala:236)\n\tat org.scalatest.funsuite.AnyFunSuiteLike.run$(AnyFunSuiteLike.scala:235)\n\tat org.scalatest.funsuite.AnyFunSuite.run(AnyFunSuite.scala:1562)\n\tat org.scalatest.tools.Framework.org$scalatest$tools$Framework$$runSuite(Framework.scala:318)\n\tat org.scalatest.tools.Framework$ScalaTestTask.execute(Framework.scala:513)\n\tat sbt.TestRunner.runTest$1(TestFramework.scala:139)\n\tat sbt.TestRunner.run(TestFramework.scala:154)\n\tat sbt.TestFramework$$anon$3$$anonfun$$lessinit$greater$1.$anonfun$apply$1(TestFramework.scala:317)\n\tat sbt.TestFramework$.sbt$TestFramework$$withContextLoader(TestFramework.scala:277)\n\tat sbt.TestFramework$$anon$3$$anonfun$$lessinit$greater$1.apply(TestFramework.scala:317)\n\tat sbt.TestFramework$$anon$3$$anonfun$$lessinit$greater$1.apply(TestFramework.scala:317)\n\tat sbt.TestFunction.apply(TestFramework.scala:329)\n\tat sbt.Tests$.$anonfun$toTask$1(Tests.scala:311)\n\tat sbt.std.Transform$$anon$3.$anonfun$apply$2(Transform.scala:46)\n\tat sbt.std.Transform$$anon$4.work(Transform.scala:67)\n\tat sbt.Execute.$anonfun$submit$2(Execute.scala:281)\n\tat sbt.internal.util.ErrorHandling$.wideConvert(ErrorHandling.scala:19)\n\tat sbt.Execute.work(Execute.scala:290)\n\tat sbt.Execute.$anonfun$submit$1(Execute.scala:281)\n\tat sbt.ConcurrentRestrictions$$anon$4.$anonfun$submitValid$1(ConcurrentRestrictions.scala:178)\n\tat sbt.CompletionService$$anon$2.call(CompletionService.scala:37)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:748)\nCaused by: java.lang.InterruptedException\n\tat java.lang.Object.wait(Native Method)\n\tat org.apache.kafka.common.utils.SystemTime.waitObject(SystemTime.java:60)\n\tat org.apache.kafka.clients.producer.internals.ProducerMetadata.awaitUpdate(ProducerMetadata.java:97)\n\tat org.apache.kafka.clients.producer.KafkaProducer.waitOnMetadata(KafkaProducer.java:999)\n\tat org.apache.kafka.clients.producer.KafkaProducer.doSend(KafkaProducer.java:876)\n\t... 61 more"
          }
        }
      ]
    },
    {
      "time": 10001,
      "tests": 1,
      "failures": 1,
      "errors": 0,
      "skipped": 0,
      "name": "io.lenses.core.kafka.FetcherWrapperTest",
      "timestamp": "2020-07-26T21:54:49",
      "failedTestcases": [
        {
          "name": "should read last offset",
          "classname": "io.lenses.core.kafka.FetcherWrapperTest",
          "time": 10001,
          "failure": {
            "message": null,
            "type": "java.util.concurrent.TimeoutException",
            "stackTrace": "java.util.concurrent.TimeoutException\n\tat org.apache.kafka.common.internals.KafkaFutureImpl$SingleWaiter.await(KafkaFutureImpl.java:108)\n\tat org.apache.kafka.common.internals.KafkaFutureImpl.get(KafkaFutureImpl.java:272)\n\tat io.lenses.test.kafka.cluster.Cluster.createTopic(Cluster.scala:44)\n\tat io.lenses.test.kafka.cluster.Cluster.createTopic$(Cluster.scala:42)\n\tat io.lenses.core.kafka.FetcherWrapperTest.createTopic(FetcherWrapperTest.scala:24)\n\tat io.lenses.core.kafka.FetcherWrapperTest.$anonfun$new$1(FetcherWrapperTest.scala:37)\n\tat org.scalatest.OutcomeOf.outcomeOf(OutcomeOf.scala:85)\n\tat org.scalatest.OutcomeOf.outcomeOf$(OutcomeOf.scala:83)\n\tat org.scalatest.OutcomeOf$.outcomeOf(OutcomeOf.scala:104)\n\tat org.scalatest.Transformer.apply(Transformer.scala:22)\n\tat org.scalatest.Transformer.apply(Transformer.scala:20)\n\tat org.scalatest.wordspec.AnyWordSpecLike$$anon$3.apply(AnyWordSpecLike.scala:1076)\n\tat org.scalatest.TestSuite.withFixture(TestSuite.scala:196)\n\tat org.scalatest.TestSuite.withFixture$(TestSuite.scala:195)\n\tat io.lenses.core.kafka.FetcherWrapperTest.withFixture(FetcherWrapperTest.scala:24)\n\tat org.scalatest.wordspec.AnyWordSpecLike.invokeWithFixture$1(AnyWordSpecLike.scala:1074)\n\tat org.scalatest.wordspec.AnyWordSpecLike.$anonfun$runTest$1(AnyWordSpecLike.scala:1086)\n\tat org.scalatest.SuperEngine.runTestImpl(Engine.scala:306)\n\tat org.scalatest.wordspec.AnyWordSpecLike.runTest(AnyWordSpecLike.scala:1086)\n\tat org.scalatest.wordspec.AnyWordSpecLike.runTest$(AnyWordSpecLike.scala:1068)\n\tat io.lenses.core.kafka.FetcherWrapperTest.runTest(FetcherWrapperTest.scala:24)\n\tat org.scalatest.wordspec.AnyWordSpecLike.$anonfun$runTests$1(AnyWordSpecLike.scala:1145)\n\tat org.scalatest.SuperEngine.$anonfun$runTestsInBranch$1(Engine.scala:413)\n\tat scala.collection.immutable.List.foreach(List.scala:392)\n\tat org.scalatest.SuperEngine.traverseSubNodes$1(Engine.scala:401)\n\tat org.scalatest.SuperEngine.runTestsInBranch(Engine.scala:396)\n\tat org.scalatest.SuperEngine.runTestsImpl(Engine.scala:475)\n\tat org.scalatest.wordspec.AnyWordSpecLike.runTests(AnyWordSpecLike.scala:1145)\n\tat org.scalatest.wordspec.AnyWordSpecLike.runTests$(AnyWordSpecLike.scala:1144)\n\tat io.lenses.core.kafka.FetcherWrapperTest.runTests(FetcherWrapperTest.scala:24)\n\tat org.scalatest.Suite.run(Suite.scala:1112)\n\tat org.scalatest.Suite.run$(Suite.scala:1094)\n\tat io.lenses.core.kafka.FetcherWrapperTest.org$scalatest$wordspec$AnyWordSpecLike$$super$run(FetcherWrapperTest.scala:24)\n\tat org.scalatest.wordspec.AnyWordSpecLike.$anonfun$run$1(AnyWordSpecLike.scala:1190)\n\tat org.scalatest.SuperEngine.runImpl(Engine.scala:535)\n\tat org.scalatest.wordspec.AnyWordSpecLike.run(AnyWordSpecLike.scala:1190)\n\tat org.scalatest.wordspec.AnyWordSpecLike.run$(AnyWordSpecLike.scala:1188)\n\tat io.lenses.core.kafka.FetcherWrapperTest.org$scalatest$BeforeAndAfterAll$$super$run(FetcherWrapperTest.scala:24)\n\tat org.scalatest.BeforeAndAfterAll.liftedTree1$1(BeforeAndAfterAll.scala:213)\n\tat org.scalatest.BeforeAndAfterAll.run(BeforeAndAfterAll.scala:210)\n\tat org.scalatest.BeforeAndAfterAll.run$(BeforeAndAfterAll.scala:208)\n\tat io.lenses.core.kafka.FetcherWrapperTest.run(FetcherWrapperTest.scala:24)\n\tat org.scalatest.tools.Framework.org$scalatest$tools$Framework$$runSuite(Framework.scala:318)\n\tat org.scalatest.tools.Framework$ScalaTestTask.execute(Framework.scala:513)\n\tat sbt.TestRunner.runTest$1(TestFramework.scala:139)\n\tat sbt.TestRunner.run(TestFramework.scala:154)\n\tat sbt.TestFramework$$anon$3$$anonfun$$lessinit$greater$1.$anonfun$apply$1(TestFramework.scala:317)\n\tat sbt.TestFramework$.sbt$TestFramework$$withContextLoader(TestFramework.scala:277)\n\tat sbt.TestFramework$$anon$3$$anonfun$$lessinit$greater$1.apply(TestFramework.scala:317)\n\tat sbt.TestFramework$$anon$3$$anonfun$$lessinit$greater$1.apply(TestFramework.scala:317)\n\tat sbt.TestFunction.apply(TestFramework.scala:329)\n\tat sbt.Tests$.$anonfun$toTask$1(Tests.scala:311)\n\tat sbt.std.Transform$$anon$3.$anonfun$apply$2(Transform.scala:46)\n\tat sbt.std.Transform$$anon$4.work(Transform.scala:67)\n\tat sbt.Execute.$anonfun$submit$2(Execute.scala:281)\n\tat sbt.internal.util.ErrorHandling$.wideConvert(ErrorHandling.scala:19)\n\tat sbt.Execute.work(Execute.scala:290)\n\tat sbt.Execute.$anonfun$submit$1(Execute.scala:281)\n\tat sbt.ConcurrentRestrictions$$anon$4.$anonfun$submitValid$1(ConcurrentRestrictions.scala:178)\n\tat sbt.CompletionService$$anon$2.call(CompletionService.scala:37)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:748)"
          }
        }
      ]
    },
    {
      "time": 240505,
      "tests": 3,
      "failures": 2,
      "errors": 0,
      "skipped": 0,
      "name": "io.lenses.core.kafka.topics.TopicCreateServiceTest",
      "timestamp": "2020-07-26T21:54:38",
      "failedTestcases": [
        {
          "name": "createTopic should be able to create a topic",
          "classname": "io.lenses.core.kafka.topics.TopicCreateServiceTest",
          "time": 120398,
          "failure": {
            "message": null,
            "type": "java.util.concurrent.TimeoutException",
            "stackTrace": "java.util.concurrent.TimeoutException\n\tat org.apache.kafka.common.internals.KafkaFutureImpl$SingleWaiter.await(KafkaFutureImpl.java:108)\n\tat org.apache.kafka.common.internals.KafkaFutureImpl.get(KafkaFutureImpl.java:272)\n\tat io.lenses.core.kafka.TopicCommand$.$anonfun$createTopic$1(TopicCommand.scala:93)\n\tat io.lenses.domain.logging.MetricsSupport.timed(MetricsSupport.scala:22)\n\tat io.lenses.domain.logging.MetricsSupport.timed$(MetricsSupport.scala:20)\n\tat io.lenses.core.kafka.TopicCommand$.timed(TopicCommand.scala:47)\n\tat io.lenses.core.kafka.TopicCommand$.createTopic(TopicCommand.scala:58)\n\tat io.lenses.core.kafka.topics.TopicCreateServiceImpl.$anonfun$createTopic$2(TopicCreateService.scala:79)\n\tat cats.effect.internals.IORunLoop$.cats$effect$internals$IORunLoop$$loop(IORunLoop.scala:87)\n\tat cats.effect.internals.IORunLoop$.startCancelable(IORunLoop.scala:41)\n\tat cats.effect.internals.IOBracket$BracketStart.run(IOBracket.scala:88)\n\tat cats.effect.internals.Trampoline.cats$effect$internals$Trampoline$$immediateLoop(Trampoline.scala:67)\n\tat cats.effect.internals.Trampoline.startLoop(Trampoline.scala:35)\n\tat cats.effect.internals.TrampolineEC$JVMTrampoline.super$startLoop(TrampolineEC.scala:89)\n\tat cats.effect.internals.TrampolineEC$JVMTrampoline.$anonfun$startLoop$1(TrampolineEC.scala:89)\n\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n\tat cats.effect.internals.TrampolineEC$JVMTrampoline.startLoop(TrampolineEC.scala:89)\n\tat cats.effect.internals.Trampoline.execute(Trampoline.scala:43)\n\tat cats.effect.internals.TrampolineEC.execute(TrampolineEC.scala:42)\n\tat cats.effect.internals.IOBracket$BracketStart.apply(IOBracket.scala:69)\n\tat cats.effect.internals.IOBracket$BracketStart.apply(IOBracket.scala:49)\n\tat cats.effect.internals.IORunLoop$.cats$effect$internals$IORunLoop$$loop(IORunLoop.scala:139)\n\tat cats.effect.internals.IORunLoop$RestartCallback.signal(IORunLoop.scala:359)\n\tat cats.effect.internals.IORunLoop$RestartCallback.apply(IORunLoop.scala:380)\n\tat cats.effect.internals.IORunLoop$RestartCallback.apply(IORunLoop.scala:323)\n\tat cats.effect.internals.IORunLoop$.cats$effect$internals$IORunLoop$$loop(IORunLoop.scala:139)\n\tat cats.effect.internals.IORunLoop$RestartCallback.signal(IORunLoop.scala:359)\n\tat cats.effect.internals.IORunLoop$RestartCallback.apply(IORunLoop.scala:380)\n\tat cats.effect.internals.IORunLoop$RestartCallback.apply(IORunLoop.scala:323)\n\tat cats.effect.internals.IOShift$Tick.run(IOShift.scala:35)\n\tat java.util.concurrent.ForkJoinTask$RunnableExecuteAction.exec(ForkJoinTask.java:1402)\n\tat java.util.concurrent.ForkJoinTask.doExec(ForkJoinTask.java:289)\n\tat java.util.concurrent.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1056)\n\tat java.util.concurrent.ForkJoinPool.runWorker(ForkJoinPool.java:1692)\n\tat java.util.concurrent.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:157)"
          }
        },
        {
          "name": "createTopic should be unable to create topic due to InvalidReplicationFactorException",
          "classname": "io.lenses.core.kafka.topics.TopicCreateServiceTest",
          "time": 120106,
          "failure": {
            "message": null,
            "type": "java.util.concurrent.TimeoutException",
            "stackTrace": "java.util.concurrent.TimeoutException\n\tat org.apache.kafka.common.internals.KafkaFutureImpl$SingleWaiter.await(KafkaFutureImpl.java:108)\n\tat org.apache.kafka.common.internals.KafkaFutureImpl.get(KafkaFutureImpl.java:272)\n\tat io.lenses.core.kafka.TopicCommand$.$anonfun$createTopic$1(TopicCommand.scala:93)\n\tat io.lenses.domain.logging.MetricsSupport.timed(MetricsSupport.scala:22)\n\tat io.lenses.domain.logging.MetricsSupport.timed$(MetricsSupport.scala:20)\n\tat io.lenses.core.kafka.TopicCommand$.timed(TopicCommand.scala:47)\n\tat io.lenses.core.kafka.TopicCommand$.createTopic(TopicCommand.scala:58)\n\tat io.lenses.core.kafka.topics.TopicCreateServiceImpl.$anonfun$createTopic$2(TopicCreateService.scala:79)\n\tat cats.effect.internals.IORunLoop$.cats$effect$internals$IORunLoop$$loop(IORunLoop.scala:87)\n\tat cats.effect.internals.IORunLoop$.startCancelable(IORunLoop.scala:41)\n\tat cats.effect.internals.IOBracket$BracketStart.run(IOBracket.scala:88)\n\tat cats.effect.internals.Trampoline.cats$effect$internals$Trampoline$$immediateLoop(Trampoline.scala:67)\n\tat cats.effect.internals.Trampoline.startLoop(Trampoline.scala:35)\n\tat cats.effect.internals.TrampolineEC$JVMTrampoline.super$startLoop(TrampolineEC.scala:89)\n\tat cats.effect.internals.TrampolineEC$JVMTrampoline.$anonfun$startLoop$1(TrampolineEC.scala:89)\n\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n\tat cats.effect.internals.TrampolineEC$JVMTrampoline.startLoop(TrampolineEC.scala:89)\n\tat cats.effect.internals.Trampoline.execute(Trampoline.scala:43)\n\tat cats.effect.internals.TrampolineEC.execute(TrampolineEC.scala:42)\n\tat cats.effect.internals.IOBracket$BracketStart.apply(IOBracket.scala:69)\n\tat cats.effect.internals.IOBracket$BracketStart.apply(IOBracket.scala:49)\n\tat cats.effect.internals.IORunLoop$.cats$effect$internals$IORunLoop$$loop(IORunLoop.scala:139)\n\tat cats.effect.internals.IORunLoop$RestartCallback.signal(IORunLoop.scala:359)\n\tat cats.effect.internals.IORunLoop$RestartCallback.apply(IORunLoop.scala:380)\n\tat cats.effect.internals.IORunLoop$RestartCallback.apply(IORunLoop.scala:323)\n\tat cats.effect.internals.IORunLoop$.cats$effect$internals$IORunLoop$$loop(IORunLoop.scala:139)\n\tat cats.effect.internals.IORunLoop$RestartCallback.signal(IORunLoop.scala:359)\n\tat cats.effect.internals.IORunLoop$RestartCallback.apply(IORunLoop.scala:380)\n\tat cats.effect.internals.IORunLoop$RestartCallback.apply(IORunLoop.scala:323)\n\tat cats.effect.internals.IOShift$Tick.run(IOShift.scala:35)\n\tat java.util.concurrent.ForkJoinTask$RunnableExecuteAction.exec(ForkJoinTask.java:1402)\n\tat java.util.concurrent.ForkJoinTask.doExec(ForkJoinTask.java:289)\n\tat java.util.concurrent.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1056)\n\tat java.util.concurrent.ForkJoinPool.runWorker(ForkJoinPool.java:1692)\n\tat java.util.concurrent.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:157)"
          }
        }
      ]
    },
    {
      "time": 45214,
      "tests": 4,
      "failures": 3,
      "errors": 0,
      "skipped": 0,
      "name": "io.lenses.core.kafka.topics.TopicMessageResenderTest",
      "timestamp": "2020-07-26T21:54:37",
      "failedTestcases": [
        {
          "name": "resend should copy existing String message",
          "classname": "io.lenses.core.kafka.topics.TopicMessageResenderTest",
          "time": 10163,
          "failure": {
            "message": null,
            "type": "java.util.concurrent.TimeoutException",
            "stackTrace": "java.util.concurrent.TimeoutException\n\tat org.apache.kafka.common.internals.KafkaFutureImpl$SingleWaiter.await(KafkaFutureImpl.java:108)\n\tat org.apache.kafka.common.internals.KafkaFutureImpl.get(KafkaFutureImpl.java:272)\n\tat io.lenses.test.kafka.cluster.Cluster.createTopic(Cluster.scala:44)\n\tat io.lenses.test.kafka.cluster.Cluster.createTopic$(Cluster.scala:42)\n\tat io.lenses.core.kafka.topics.TopicMessageResenderTest.createTopic(TopicMessageResenderTest.scala:30)\n\tat io.lenses.core.kafka.topics.TopicMessageResenderTest.createUniqueTopic(TopicMessageResenderTest.scala:112)\n\tat io.lenses.core.kafka.topics.TopicMessageResenderTest.$anonfun$new$1(TopicMessageResenderTest.scala:48)\n\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n\tat org.scalatest.OutcomeOf.outcomeOf(OutcomeOf.scala:85)\n\tat org.scalatest.OutcomeOf.outcomeOf$(OutcomeOf.scala:83)\n\tat org.scalatest.OutcomeOf$.outcomeOf(OutcomeOf.scala:104)\n\tat org.scalatest.Transformer.apply(Transformer.scala:22)\n\tat org.scalatest.Transformer.apply(Transformer.scala:20)\n\tat org.scalatest.flatspec.AnyFlatSpecLike$$anon$5.apply(AnyFlatSpecLike.scala:1683)\n\tat org.scalatest.TestSuite.withFixture(TestSuite.scala:196)\n\tat org.scalatest.TestSuite.withFixture$(TestSuite.scala:195)\n\tat org.scalatest.flatspec.AnyFlatSpec.withFixture(AnyFlatSpec.scala:1685)\n\tat org.scalatest.flatspec.AnyFlatSpecLike.invokeWithFixture$1(AnyFlatSpecLike.scala:1681)\n\tat org.scalatest.flatspec.AnyFlatSpecLike.$anonfun$runTest$1(AnyFlatSpecLike.scala:1693)\n\tat org.scalatest.SuperEngine.runTestImpl(Engine.scala:306)\n\tat org.scalatest.flatspec.AnyFlatSpecLike.runTest(AnyFlatSpecLike.scala:1693)\n\tat org.scalatest.flatspec.AnyFlatSpecLike.runTest$(AnyFlatSpecLike.scala:1675)\n\tat org.scalatest.flatspec.AnyFlatSpec.runTest(AnyFlatSpec.scala:1685)\n\tat org.scalatest.flatspec.AnyFlatSpecLike.$anonfun$runTests$1(AnyFlatSpecLike.scala:1751)\n\tat org.scalatest.SuperEngine.$anonfun$runTestsInBranch$1(Engine.scala:413)\n\tat scala.collection.immutable.List.foreach(List.scala:392)\n\tat org.scalatest.SuperEngine.traverseSubNodes$1(Engine.scala:401)\n\tat org.scalatest.SuperEngine.runTestsInBranch(Engine.scala:390)\n\tat org.scalatest.SuperEngine.$anonfun$runTestsInBranch$1(Engine.scala:427)\n\tat scala.collection.immutable.List.foreach(List.scala:392)\n\tat org.scalatest.SuperEngine.traverseSubNodes$1(Engine.scala:401)\n\tat org.scalatest.SuperEngine.runTestsInBranch(Engine.scala:396)\n\tat org.scalatest.SuperEngine.runTestsImpl(Engine.scala:475)\n\tat org.scalatest.flatspec.AnyFlatSpecLike.runTests(AnyFlatSpecLike.scala:1751)\n\tat org.scalatest.flatspec.AnyFlatSpecLike.runTests$(AnyFlatSpecLike.scala:1750)\n\tat org.scalatest.flatspec.AnyFlatSpec.runTests(AnyFlatSpec.scala:1685)\n\tat org.scalatest.Suite.run(Suite.scala:1112)\n\tat org.scalatest.Suite.run$(Suite.scala:1094)\n\tat org.scalatest.flatspec.AnyFlatSpec.org$scalatest$flatspec$AnyFlatSpecLike$$super$run(AnyFlatSpec.scala:1685)\n\tat org.scalatest.flatspec.AnyFlatSpecLike.$anonfun$run$1(AnyFlatSpecLike.scala:1796)\n\tat org.scalatest.SuperEngine.runImpl(Engine.scala:535)\n\tat org.scalatest.flatspec.AnyFlatSpecLike.run(AnyFlatSpecLike.scala:1796)\n\tat org.scalatest.flatspec.AnyFlatSpecLike.run$(AnyFlatSpecLike.scala:1794)\n\tat org.scalatest.flatspec.AnyFlatSpec.run(AnyFlatSpec.scala:1685)\n\tat org.scalatest.tools.Framework.org$scalatest$tools$Framework$$runSuite(Framework.scala:318)\n\tat org.scalatest.tools.Framework$ScalaTestTask.execute(Framework.scala:513)\n\tat sbt.TestRunner.runTest$1(TestFramework.scala:139)\n\tat sbt.TestRunner.run(TestFramework.scala:154)\n\tat sbt.TestFramework$$anon$3$$anonfun$$lessinit$greater$1.$anonfun$apply$1(TestFramework.scala:317)\n\tat sbt.TestFramework$.sbt$TestFramework$$withContextLoader(TestFramework.scala:277)\n\tat sbt.TestFramework$$anon$3$$anonfun$$lessinit$greater$1.apply(TestFramework.scala:317)\n\tat sbt.TestFramework$$anon$3$$anonfun$$lessinit$greater$1.apply(TestFramework.scala:317)\n\tat sbt.TestFunction.apply(TestFramework.scala:329)\n\tat sbt.Tests$.$anonfun$toTask$1(Tests.scala:311)\n\tat sbt.std.Transform$$anon$3.$anonfun$apply$2(Transform.scala:46)\n\tat sbt.std.Transform$$anon$4.work(Transform.scala:67)\n\tat sbt.Execute.$anonfun$submit$2(Execute.scala:281)\n\tat sbt.internal.util.ErrorHandling$.wideConvert(ErrorHandling.scala:19)\n\tat sbt.Execute.work(Execute.scala:290)\n\tat sbt.Execute.$anonfun$submit$1(Execute.scala:281)\n\tat sbt.ConcurrentRestrictions$$anon$4.$anonfun$submitValid$1(ConcurrentRestrictions.scala:178)\n\tat sbt.CompletionService$$anon$2.call(CompletionService.scala:37)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:748)"
          }
        },
        {
          "name": "resend should fail when partition does not exist",
          "classname": "io.lenses.core.kafka.topics.TopicMessageResenderTest",
          "time": 10003,
          "failure": {
            "message": null,
            "type": "java.util.concurrent.TimeoutException",
            "stackTrace": "java.util.concurrent.TimeoutException\n\tat org.apache.kafka.common.internals.KafkaFutureImpl$SingleWaiter.await(KafkaFutureImpl.java:108)\n\tat org.apache.kafka.common.internals.KafkaFutureImpl.get(KafkaFutureImpl.java:272)\n\tat io.lenses.test.kafka.cluster.Cluster.createTopic(Cluster.scala:44)\n\tat io.lenses.test.kafka.cluster.Cluster.createTopic$(Cluster.scala:42)\n\tat io.lenses.core.kafka.topics.TopicMessageResenderTest.createTopic(TopicMessageResenderTest.scala:30)\n\tat io.lenses.core.kafka.topics.TopicMessageResenderTest.createUniqueTopic(TopicMessageResenderTest.scala:112)\n\tat io.lenses.core.kafka.topics.TopicMessageResenderTest.$anonfun$new$5(TopicMessageResenderTest.scala:78)\n\tat org.scalatest.OutcomeOf.outcomeOf(OutcomeOf.scala:85)\n\tat org.scalatest.OutcomeOf.outcomeOf$(OutcomeOf.scala:83)\n\tat org.scalatest.OutcomeOf$.outcomeOf(OutcomeOf.scala:104)\n\tat org.scalatest.Transformer.apply(Transformer.scala:22)\n\tat org.scalatest.Transformer.apply(Transformer.scala:20)\n\tat org.scalatest.flatspec.AnyFlatSpecLike$$anon$5.apply(AnyFlatSpecLike.scala:1683)\n\tat org.scalatest.TestSuite.withFixture(TestSuite.scala:196)\n\tat org.scalatest.TestSuite.withFixture$(TestSuite.scala:195)\n\tat org.scalatest.flatspec.AnyFlatSpec.withFixture(AnyFlatSpec.scala:1685)\n\tat org.scalatest.flatspec.AnyFlatSpecLike.invokeWithFixture$1(AnyFlatSpecLike.scala:1681)\n\tat org.scalatest.flatspec.AnyFlatSpecLike.$anonfun$runTest$1(AnyFlatSpecLike.scala:1693)\n\tat org.scalatest.SuperEngine.runTestImpl(Engine.scala:306)\n\tat org.scalatest.flatspec.AnyFlatSpecLike.runTest(AnyFlatSpecLike.scala:1693)\n\tat org.scalatest.flatspec.AnyFlatSpecLike.runTest$(AnyFlatSpecLike.scala:1675)\n\tat org.scalatest.flatspec.AnyFlatSpec.runTest(AnyFlatSpec.scala:1685)\n\tat org.scalatest.flatspec.AnyFlatSpecLike.$anonfun$runTests$1(AnyFlatSpecLike.scala:1751)\n\tat org.scalatest.SuperEngine.$anonfun$runTestsInBranch$1(Engine.scala:413)\n\tat scala.collection.immutable.List.foreach(List.scala:392)\n\tat org.scalatest.SuperEngine.traverseSubNodes$1(Engine.scala:401)\n\tat org.scalatest.SuperEngine.runTestsInBranch(Engine.scala:390)\n\tat org.scalatest.SuperEngine.$anonfun$runTestsInBranch$1(Engine.scala:427)\n\tat scala.collection.immutable.List.foreach(List.scala:392)\n\tat org.scalatest.SuperEngine.traverseSubNodes$1(Engine.scala:401)\n\tat org.scalatest.SuperEngine.runTestsInBranch(Engine.scala:396)\n\tat org.scalatest.SuperEngine.runTestsImpl(Engine.scala:475)\n\tat org.scalatest.flatspec.AnyFlatSpecLike.runTests(AnyFlatSpecLike.scala:1751)\n\tat org.scalatest.flatspec.AnyFlatSpecLike.runTests$(AnyFlatSpecLike.scala:1750)\n\tat org.scalatest.flatspec.AnyFlatSpec.runTests(AnyFlatSpec.scala:1685)\n\tat org.scalatest.Suite.run(Suite.scala:1112)\n\tat org.scalatest.Suite.run$(Suite.scala:1094)\n\tat org.scalatest.flatspec.AnyFlatSpec.org$scalatest$flatspec$AnyFlatSpecLike$$super$run(AnyFlatSpec.scala:1685)\n\tat org.scalatest.flatspec.AnyFlatSpecLike.$anonfun$run$1(AnyFlatSpecLike.scala:1796)\n\tat org.scalatest.SuperEngine.runImpl(Engine.scala:535)\n\tat org.scalatest.flatspec.AnyFlatSpecLike.run(AnyFlatSpecLike.scala:1796)\n\tat org.scalatest.flatspec.AnyFlatSpecLike.run$(AnyFlatSpecLike.scala:1794)\n\tat org.scalatest.flatspec.AnyFlatSpec.run(AnyFlatSpec.scala:1685)\n\tat org.scalatest.tools.Framework.org$scalatest$tools$Framework$$runSuite(Framework.scala:318)\n\tat org.scalatest.tools.Framework$ScalaTestTask.execute(Framework.scala:513)\n\tat sbt.TestRunner.runTest$1(TestFramework.scala:139)\n\tat sbt.TestRunner.run(TestFramework.scala:154)\n\tat sbt.TestFramework$$anon$3$$anonfun$$lessinit$greater$1.$anonfun$apply$1(TestFramework.scala:317)\n\tat sbt.TestFramework$.sbt$TestFramework$$withContextLoader(TestFramework.scala:277)\n\tat sbt.TestFramework$$anon$3$$anonfun$$lessinit$greater$1.apply(TestFramework.scala:317)\n\tat sbt.TestFramework$$anon$3$$anonfun$$lessinit$greater$1.apply(TestFramework.scala:317)\n\tat sbt.TestFunction.apply(TestFramework.scala:329)\n\tat sbt.Tests$.$anonfun$toTask$1(Tests.scala:311)\n\tat sbt.std.Transform$$anon$3.$anonfun$apply$2(Transform.scala:46)\n\tat sbt.std.Transform$$anon$4.work(Transform.scala:67)\n\tat sbt.Execute.$anonfun$submit$2(Execute.scala:281)\n\tat sbt.internal.util.ErrorHandling$.wideConvert(ErrorHandling.scala:19)\n\tat sbt.Execute.work(Execute.scala:290)\n\tat sbt.Execute.$anonfun$submit$1(Execute.scala:281)\n\tat sbt.ConcurrentRestrictions$$anon$4.$anonfun$submitValid$1(ConcurrentRestrictions.scala:178)\n\tat sbt.CompletionService$$anon$2.call(CompletionService.scala:37)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:748)"
          }
        },
        {
          "name": "resend should fail when offset out of bounds",
          "classname": "io.lenses.core.kafka.topics.TopicMessageResenderTest",
          "time": 10001,
          "failure": {
            "message": null,
            "type": "java.util.concurrent.TimeoutException",
            "stackTrace": "java.util.concurrent.TimeoutException\n\tat org.apache.kafka.common.internals.KafkaFutureImpl$SingleWaiter.await(KafkaFutureImpl.java:108)\n\tat org.apache.kafka.common.internals.KafkaFutureImpl.get(KafkaFutureImpl.java:272)\n\tat io.lenses.test.kafka.cluster.Cluster.createTopic(Cluster.scala:44)\n\tat io.lenses.test.kafka.cluster.Cluster.createTopic$(Cluster.scala:42)\n\tat io.lenses.core.kafka.topics.TopicMessageResenderTest.createTopic(TopicMessageResenderTest.scala:30)\n\tat io.lenses.core.kafka.topics.TopicMessageResenderTest.createUniqueTopic(TopicMessageResenderTest.scala:112)\n\tat io.lenses.core.kafka.topics.TopicMessageResenderTest.$anonfun$new$7(TopicMessageResenderTest.scala:91)\n\tat org.scalatest.OutcomeOf.outcomeOf(OutcomeOf.scala:85)\n\tat org.scalatest.OutcomeOf.outcomeOf$(OutcomeOf.scala:83)\n\tat org.scalatest.OutcomeOf$.outcomeOf(OutcomeOf.scala:104)\n\tat org.scalatest.Transformer.apply(Transformer.scala:22)\n\tat org.scalatest.Transformer.apply(Transformer.scala:20)\n\tat org.scalatest.flatspec.AnyFlatSpecLike$$anon$5.apply(AnyFlatSpecLike.scala:1683)\n\tat org.scalatest.TestSuite.withFixture(TestSuite.scala:196)\n\tat org.scalatest.TestSuite.withFixture$(TestSuite.scala:195)\n\tat org.scalatest.flatspec.AnyFlatSpec.withFixture(AnyFlatSpec.scala:1685)\n\tat org.scalatest.flatspec.AnyFlatSpecLike.invokeWithFixture$1(AnyFlatSpecLike.scala:1681)\n\tat org.scalatest.flatspec.AnyFlatSpecLike.$anonfun$runTest$1(AnyFlatSpecLike.scala:1693)\n\tat org.scalatest.SuperEngine.runTestImpl(Engine.scala:306)\n\tat org.scalatest.flatspec.AnyFlatSpecLike.runTest(AnyFlatSpecLike.scala:1693)\n\tat org.scalatest.flatspec.AnyFlatSpecLike.runTest$(AnyFlatSpecLike.scala:1675)\n\tat org.scalatest.flatspec.AnyFlatSpec.runTest(AnyFlatSpec.scala:1685)\n\tat org.scalatest.flatspec.AnyFlatSpecLike.$anonfun$runTests$1(AnyFlatSpecLike.scala:1751)\n\tat org.scalatest.SuperEngine.$anonfun$runTestsInBranch$1(Engine.scala:413)\n\tat scala.collection.immutable.List.foreach(List.scala:392)\n\tat org.scalatest.SuperEngine.traverseSubNodes$1(Engine.scala:401)\n\tat org.scalatest.SuperEngine.runTestsInBranch(Engine.scala:390)\n\tat org.scalatest.SuperEngine.$anonfun$runTestsInBranch$1(Engine.scala:427)\n\tat scala.collection.immutable.List.foreach(List.scala:392)\n\tat org.scalatest.SuperEngine.traverseSubNodes$1(Engine.scala:401)\n\tat org.scalatest.SuperEngine.runTestsInBranch(Engine.scala:396)\n\tat org.scalatest.SuperEngine.runTestsImpl(Engine.scala:475)\n\tat org.scalatest.flatspec.AnyFlatSpecLike.runTests(AnyFlatSpecLike.scala:1751)\n\tat org.scalatest.flatspec.AnyFlatSpecLike.runTests$(AnyFlatSpecLike.scala:1750)\n\tat org.scalatest.flatspec.AnyFlatSpec.runTests(AnyFlatSpec.scala:1685)\n\tat org.scalatest.Suite.run(Suite.scala:1112)\n\tat org.scalatest.Suite.run$(Suite.scala:1094)\n\tat org.scalatest.flatspec.AnyFlatSpec.org$scalatest$flatspec$AnyFlatSpecLike$$super$run(AnyFlatSpec.scala:1685)\n\tat org.scalatest.flatspec.AnyFlatSpecLike.$anonfun$run$1(AnyFlatSpecLike.scala:1796)\n\tat org.scalatest.SuperEngine.runImpl(Engine.scala:535)\n\tat org.scalatest.flatspec.AnyFlatSpecLike.run(AnyFlatSpecLike.scala:1796)\n\tat org.scalatest.flatspec.AnyFlatSpecLike.run$(AnyFlatSpecLike.scala:1794)\n\tat org.scalatest.flatspec.AnyFlatSpec.run(AnyFlatSpec.scala:1685)\n\tat org.scalatest.tools.Framework.org$scalatest$tools$Framework$$runSuite(Framework.scala:318)\n\tat org.scalatest.tools.Framework$ScalaTestTask.execute(Framework.scala:513)\n\tat sbt.TestRunner.runTest$1(TestFramework.scala:139)\n\tat sbt.TestRunner.run(TestFramework.scala:154)\n\tat sbt.TestFramework$$anon$3$$anonfun$$lessinit$greater$1.$anonfun$apply$1(TestFramework.scala:317)\n\tat sbt.TestFramework$.sbt$TestFramework$$withContextLoader(TestFramework.scala:277)\n\tat sbt.TestFramework$$anon$3$$anonfun$$lessinit$greater$1.apply(TestFramework.scala:317)\n\tat sbt.TestFramework$$anon$3$$anonfun$$lessinit$greater$1.apply(TestFramework.scala:317)\n\tat sbt.TestFunction.apply(TestFramework.scala:329)\n\tat sbt.Tests$.$anonfun$toTask$1(Tests.scala:311)\n\tat sbt.std.Transform$$anon$3.$anonfun$apply$2(Transform.scala:46)\n\tat sbt.std.Transform$$anon$4.work(Transform.scala:67)\n\tat sbt.Execute.$anonfun$submit$2(Execute.scala:281)\n\tat sbt.internal.util.ErrorHandling$.wideConvert(ErrorHandling.scala:19)\n\tat sbt.Execute.work(Execute.scala:290)\n\tat sbt.Execute.$anonfun$submit$1(Execute.scala:281)\n\tat sbt.ConcurrentRestrictions$$anon$4.$anonfun$submitValid$1(ConcurrentRestrictions.scala:178)\n\tat sbt.CompletionService$$anon$2.call(CompletionService.scala:37)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:748)"
          }
        }
      ]
    },
    {
      "time": 648077,
      "tests": 2,
      "failures": 1,
      "errors": 0,
      "skipped": 0,
      "name": "io.lenses.core.kafka.KafkaBrokersMetadataSpec",
      "timestamp": "2020-07-26T21:54:45",
      "failedTestcases": [
        {
          "name": "returns the broker information from zookeeper",
          "classname": "io.lenses.core.kafka.KafkaBrokersMetadataSpec",
          "time": 648044,
          "failure": {
            "message": "KeeperErrorCode = ConnectionLoss for /brokers/ids",
            "type": "org.apache.zookeeper.KeeperException$ConnectionLossException",
            "stackTrace": "org.apache.zookeeper.KeeperException$ConnectionLossException: KeeperErrorCode = ConnectionLoss for /brokers/ids\n\tat org.apache.zookeeper.KeeperException.create(KeeperException.java:99)\n\tat org.apache.zookeeper.KeeperException.create(KeeperException.java:51)\n\tat org.apache.zookeeper.ZooKeeper.getChildren(ZooKeeper.java:2595)\n\tat org.apache.curator.framework.imps.GetChildrenBuilderImpl$3.call(GetChildrenBuilderImpl.java:242)\n\tat org.apache.curator.framework.imps.GetChildrenBuilderImpl$3.call(GetChildrenBuilderImpl.java:231)\n\tat org.apache.curator.connection.StandardConnectionHandlingPolicy.callWithRetry(StandardConnectionHandlingPolicy.java:64)\n\tat org.apache.curator.RetryLoop.callWithRetry(RetryLoop.java:100)\n\tat org.apache.curator.framework.imps.GetChildrenBuilderImpl.pathInForeground(GetChildrenBuilderImpl.java:228)\n\tat org.apache.curator.framework.imps.GetChildrenBuilderImpl.forPath(GetChildrenBuilderImpl.java:219)\n\tat org.apache.curator.framework.imps.GetChildrenBuilderImpl.forPath(GetChildrenBuilderImpl.java:41)\n\tat io.lenses.core.kafka.KafkaBrokersMetadata$.getBrokers(KafkaBrokersMetadata.scala:42)\n\tat io.lenses.core.kafka.KafkaBrokersMetadataSpec.$anonfun$new$1(KafkaBrokersMetadataSpec.scala:35)\n\tat org.scalatest.OutcomeOf.outcomeOf(OutcomeOf.scala:85)\n\tat org.scalatest.OutcomeOf.outcomeOf$(OutcomeOf.scala:83)\n\tat org.scalatest.OutcomeOf$.outcomeOf(OutcomeOf.scala:104)\n\tat org.scalatest.Transformer.apply(Transformer.scala:22)\n\tat org.scalatest.Transformer.apply(Transformer.scala:20)\n\tat org.scalatest.funsuite.AnyFunSuiteLike$$anon$1.apply(AnyFunSuiteLike.scala:189)\n\tat org.scalatest.TestSuite.withFixture(TestSuite.scala:196)\n\tat org.scalatest.TestSuite.withFixture$(TestSuite.scala:195)\n\tat org.scalatest.funsuite.AnyFunSuite.withFixture(AnyFunSuite.scala:1562)\n\tat org.scalatest.funsuite.AnyFunSuiteLike.invokeWithFixture$1(AnyFunSuiteLike.scala:187)\n\tat org.scalatest.funsuite.AnyFunSuiteLike.$anonfun$runTest$1(AnyFunSuiteLike.scala:199)\n\tat org.scalatest.SuperEngine.runTestImpl(Engine.scala:306)\n\tat org.scalatest.funsuite.AnyFunSuiteLike.runTest(AnyFunSuiteLike.scala:199)\n\tat org.scalatest.funsuite.AnyFunSuiteLike.runTest$(AnyFunSuiteLike.scala:181)\n\tat org.scalatest.funsuite.AnyFunSuite.runTest(AnyFunSuite.scala:1562)\n\tat org.scalatest.funsuite.AnyFunSuiteLike.$anonfun$runTests$1(AnyFunSuiteLike.scala:232)\n\tat org.scalatest.SuperEngine.$anonfun$runTestsInBranch$1(Engine.scala:413)\n\tat scala.collection.immutable.List.foreach(List.scala:392)\n\tat org.scalatest.SuperEngine.traverseSubNodes$1(Engine.scala:401)\n\tat org.scalatest.SuperEngine.runTestsInBranch(Engine.scala:396)\n\tat org.scalatest.SuperEngine.runTestsImpl(Engine.scala:475)\n\tat org.scalatest.funsuite.AnyFunSuiteLike.runTests(AnyFunSuiteLike.scala:232)\n\tat org.scalatest.funsuite.AnyFunSuiteLike.runTests$(AnyFunSuiteLike.scala:231)\n\tat org.scalatest.funsuite.AnyFunSuite.runTests(AnyFunSuite.scala:1562)\n\tat org.scalatest.Suite.run(Suite.scala:1112)\n\tat org.scalatest.Suite.run$(Suite.scala:1094)\n\tat org.scalatest.funsuite.AnyFunSuite.org$scalatest$funsuite$AnyFunSuiteLike$$super$run(AnyFunSuite.scala:1562)\n\tat org.scalatest.funsuite.AnyFunSuiteLike.$anonfun$run$1(AnyFunSuiteLike.scala:236)\n\tat org.scalatest.SuperEngine.runImpl(Engine.scala:535)\n\tat org.scalatest.funsuite.AnyFunSuiteLike.run(AnyFunSuiteLike.scala:236)\n\tat org.scalatest.funsuite.AnyFunSuiteLike.run$(AnyFunSuiteLike.scala:235)\n\tat io.lenses.core.kafka.KafkaBrokersMetadataSpec.org$scalatest$BeforeAndAfterAll$$super$run(KafkaBrokersMetadataSpec.scala:18)\n\tat org.scalatest.BeforeAndAfterAll.liftedTree1$1(BeforeAndAfterAll.scala:213)\n\tat org.scalatest.BeforeAndAfterAll.run(BeforeAndAfterAll.scala:210)\n\tat org.scalatest.BeforeAndAfterAll.run$(BeforeAndAfterAll.scala:208)\n\tat io.lenses.core.kafka.KafkaBrokersMetadataSpec.run(KafkaBrokersMetadataSpec.scala:18)\n\tat org.scalatest.tools.Framework.org$scalatest$tools$Framework$$runSuite(Framework.scala:318)\n\tat org.scalatest.tools.Framework$ScalaTestTask.execute(Framework.scala:513)\n\tat sbt.TestRunner.runTest$1(TestFramework.scala:139)\n\tat sbt.TestRunner.run(TestFramework.scala:154)\n\tat sbt.TestFramework$$anon$3$$anonfun$$lessinit$greater$1.$anonfun$apply$1(TestFramework.scala:317)\n\tat sbt.TestFramework$.sbt$TestFramework$$withContextLoader(TestFramework.scala:277)\n\tat sbt.TestFramework$$anon$3$$anonfun$$lessinit$greater$1.apply(TestFramework.scala:317)\n\tat sbt.TestFramework$$anon$3$$anonfun$$lessinit$greater$1.apply(TestFramework.scala:317)\n\tat sbt.TestFunction.apply(TestFramework.scala:329)\n\tat sbt.Tests$.$anonfun$toTask$1(Tests.scala:311)\n\tat sbt.std.Transform$$anon$3.$anonfun$apply$2(Transform.scala:46)\n\tat sbt.std.Transform$$anon$4.work(Transform.scala:67)\n\tat sbt.Execute.$anonfun$submit$2(Execute.scala:281)\n\tat sbt.internal.util.ErrorHandling$.wideConvert(ErrorHandling.scala:19)\n\tat sbt.Execute.work(Execute.scala:290)\n\tat sbt.Execute.$anonfun$submit$1(Execute.scala:281)\n\tat sbt.ConcurrentRestrictions$$anon$4.$anonfun$submitValid$1(ConcurrentRestrictions.scala:178)\n\tat sbt.CompletionService$$anon$2.call(CompletionService.scala:37)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:748)"
          }
        }
      ]
    },
    {
      "time": 21066,
      "tests": 3,
      "failures": 2,
      "errors": 0,
      "skipped": 0,
      "name": "io.lenses.core.actors.KafkaTopicsActorSpec",
      "timestamp": "2020-07-26T21:54:37",
      "failedTestcases": [
        {
          "name": "ScheduleTopicPartitionsStatistics should handle DeleteFromTopicToOffset message for compacting topics by preventing deletion",
          "classname": "io.lenses.core.actors.KafkaTopicsActorSpec",
          "time": 10251,
          "failure": {
            "message": null,
            "type": "java.util.concurrent.TimeoutException",
            "stackTrace": "java.util.concurrent.TimeoutException\n\tat org.apache.kafka.common.internals.KafkaFutureImpl$SingleWaiter.await(KafkaFutureImpl.java:108)\n\tat org.apache.kafka.common.internals.KafkaFutureImpl.get(KafkaFutureImpl.java:272)\n\tat io.lenses.test.kafka.cluster.Cluster.createTopic(Cluster.scala:44)\n\tat io.lenses.test.kafka.cluster.Cluster.createTopic$(Cluster.scala:42)\n\tat io.lenses.core.actors.KafkaTopicsActorSpec.createTopic(KafkaTopicsActorSpec.scala:61)\n\tat io.lenses.core.actors.KafkaTopicsActorSpec.io$lenses$core$actors$KafkaTopicsActorSpec$$createTopicAndSetConfiguration(KafkaTopicsActorSpec.scala:206)\n\tat io.lenses.core.actors.KafkaTopicsActorSpec$$anon$3.$anonfun$new$7(KafkaTopicsActorSpec.scala:129)\n\tat io.lenses.core.actors.KafkaTopicsActorSpec$TestContext.$anonfun$withActor$2(KafkaTopicsActorSpec.scala:263)\n\tat cats.effect.internals.IORunLoop$.cats$effect$internals$IORunLoop$$loop(IORunLoop.scala:87)\n\tat cats.effect.internals.IORunLoop$.startCancelable(IORunLoop.scala:41)\n\tat cats.effect.internals.IOBracket$BracketStart.run(IOBracket.scala:88)\n\tat cats.effect.internals.Trampoline.cats$effect$internals$Trampoline$$immediateLoop(Trampoline.scala:67)\n\tat cats.effect.internals.Trampoline.startLoop(Trampoline.scala:35)\n\tat cats.effect.internals.TrampolineEC$JVMTrampoline.super$startLoop(TrampolineEC.scala:89)\n\tat cats.effect.internals.TrampolineEC$JVMTrampoline.$anonfun$startLoop$1(TrampolineEC.scala:89)\n\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n\tat cats.effect.internals.TrampolineEC$JVMTrampoline.startLoop(TrampolineEC.scala:89)\n\tat cats.effect.internals.Trampoline.execute(Trampoline.scala:43)\n\tat cats.effect.internals.TrampolineEC.execute(TrampolineEC.scala:42)\n\tat cats.effect.internals.IOBracket$BracketStart.apply(IOBracket.scala:69)\n\tat cats.effect.internals.IOBracket$BracketStart.apply(IOBracket.scala:49)\n\tat cats.effect.internals.IORunLoop$.cats$effect$internals$IORunLoop$$loop(IORunLoop.scala:139)\n\tat cats.effect.internals.IORunLoop$RestartCallback.signal(IORunLoop.scala:359)\n\tat cats.effect.internals.IORunLoop$RestartCallback.apply(IORunLoop.scala:380)\n\tat cats.effect.internals.IORunLoop$RestartCallback.apply(IORunLoop.scala:323)\n\tat cats.effect.internals.IORunLoop$.cats$effect$internals$IORunLoop$$loop(IORunLoop.scala:139)\n\tat cats.effect.internals.IORunLoop$RestartCallback.signal(IORunLoop.scala:359)\n\tat cats.effect.internals.IORunLoop$RestartCallback.apply(IORunLoop.scala:380)\n\tat cats.effect.internals.IORunLoop$RestartCallback.apply(IORunLoop.scala:323)\n\tat cats.effect.internals.IOShift$Tick.run(IOShift.scala:35)\n\tat akka.dispatch.TaskInvocation.run(AbstractDispatcher.scala:47)\n\tat akka.dispatch.ForkJoinExecutorConfigurator$AkkaForkJoinTask.exec(ForkJoinExecutorConfigurator.scala:47)\n\tat java.util.concurrent.ForkJoinTask.doExec(ForkJoinTask.java:289)\n\tat java.util.concurrent.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1056)\n\tat java.util.concurrent.ForkJoinPool.runWorker(ForkJoinPool.java:1692)\n\tat java.util.concurrent.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:157)"
          }
        },
        {
          "name": "ScheduleTopicPartitionsStatistics should handle DeleteFromTopicToOffset message for non-compacting topics by allowing deletion",
          "classname": "io.lenses.core.actors.KafkaTopicsActorSpec",
          "time": 10135,
          "failure": {
            "message": null,
            "type": "java.util.concurrent.TimeoutException",
            "stackTrace": "java.util.concurrent.TimeoutException\n\tat org.apache.kafka.common.internals.KafkaFutureImpl$SingleWaiter.await(KafkaFutureImpl.java:108)\n\tat org.apache.kafka.common.internals.KafkaFutureImpl.get(KafkaFutureImpl.java:272)\n\tat io.lenses.test.kafka.cluster.Cluster.createTopic(Cluster.scala:44)\n\tat io.lenses.test.kafka.cluster.Cluster.createTopic$(Cluster.scala:42)\n\tat io.lenses.core.actors.KafkaTopicsActorSpec.createTopic(KafkaTopicsActorSpec.scala:61)\n\tat io.lenses.core.actors.KafkaTopicsActorSpec.io$lenses$core$actors$KafkaTopicsActorSpec$$createTopicAndSetConfiguration(KafkaTopicsActorSpec.scala:206)\n\tat io.lenses.core.actors.KafkaTopicsActorSpec$$anon$4.$anonfun$new$10(KafkaTopicsActorSpec.scala:155)\n\tat io.lenses.core.actors.KafkaTopicsActorSpec$TestContext.$anonfun$withActor$2(KafkaTopicsActorSpec.scala:263)\n\tat cats.effect.internals.IORunLoop$.cats$effect$internals$IORunLoop$$loop(IORunLoop.scala:87)\n\tat cats.effect.internals.IORunLoop$.startCancelable(IORunLoop.scala:41)\n\tat cats.effect.internals.IOBracket$BracketStart.run(IOBracket.scala:88)\n\tat cats.effect.internals.Trampoline.cats$effect$internals$Trampoline$$immediateLoop(Trampoline.scala:67)\n\tat cats.effect.internals.Trampoline.startLoop(Trampoline.scala:35)\n\tat cats.effect.internals.TrampolineEC$JVMTrampoline.super$startLoop(TrampolineEC.scala:89)\n\tat cats.effect.internals.TrampolineEC$JVMTrampoline.$anonfun$startLoop$1(TrampolineEC.scala:89)\n\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n\tat cats.effect.internals.TrampolineEC$JVMTrampoline.startLoop(TrampolineEC.scala:89)\n\tat cats.effect.internals.Trampoline.execute(Trampoline.scala:43)\n\tat cats.effect.internals.TrampolineEC.execute(TrampolineEC.scala:42)\n\tat cats.effect.internals.IOBracket$BracketStart.apply(IOBracket.scala:69)\n\tat cats.effect.internals.IOBracket$BracketStart.apply(IOBracket.scala:49)\n\tat cats.effect.internals.IORunLoop$.cats$effect$internals$IORunLoop$$loop(IORunLoop.scala:139)\n\tat cats.effect.internals.IORunLoop$RestartCallback.signal(IORunLoop.scala:359)\n\tat cats.effect.internals.IORunLoop$RestartCallback.apply(IORunLoop.scala:380)\n\tat cats.effect.internals.IORunLoop$RestartCallback.apply(IORunLoop.scala:323)\n\tat cats.effect.internals.IORunLoop$.cats$effect$internals$IORunLoop$$loop(IORunLoop.scala:139)\n\tat cats.effect.internals.IORunLoop$RestartCallback.signal(IORunLoop.scala:359)\n\tat cats.effect.internals.IORunLoop$RestartCallback.apply(IORunLoop.scala:380)\n\tat cats.effect.internals.IORunLoop$RestartCallback.apply(IORunLoop.scala:323)\n\tat cats.effect.internals.IOShift$Tick.run(IOShift.scala:35)\n\tat akka.dispatch.TaskInvocation.run(AbstractDispatcher.scala:47)\n\tat akka.dispatch.ForkJoinExecutorConfigurator$AkkaForkJoinTask.exec(ForkJoinExecutorConfigurator.scala:47)\n\tat java.util.concurrent.ForkJoinTask.doExec(ForkJoinTask.java:289)\n\tat java.util.concurrent.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1056)\n\tat java.util.concurrent.ForkJoinPool.runWorker(ForkJoinPool.java:1692)\n\tat java.util.concurrent.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:157)"
          }
        }
      ]
    },
    {
      "time": 10005,
      "tests": 1,
      "failures": 1,
      "errors": 0,
      "skipped": 0,
      "name": "io.lenses.core.actors.ConnectStatusActorTest",
      "timestamp": "2020-07-26T21:54:41",
      "failedTestcases": [
        {
          "name": "should read task status",
          "classname": "io.lenses.core.actors.ConnectStatusActorTest",
          "time": 10005,
          "failure": {
            "message": null,
            "type": "java.util.concurrent.TimeoutException",
            "stackTrace": "java.util.concurrent.TimeoutException\n\tat org.apache.kafka.common.internals.KafkaFutureImpl$SingleWaiter.await(KafkaFutureImpl.java:108)\n\tat org.apache.kafka.common.internals.KafkaFutureImpl.get(KafkaFutureImpl.java:272)\n\tat io.lenses.test.kafka.cluster.Cluster.createTopic(Cluster.scala:44)\n\tat io.lenses.test.kafka.cluster.Cluster.createTopic$(Cluster.scala:42)\n\tat io.lenses.core.actors.ConnectStatusActorTest.createTopic(ConnectStatusActorTest.scala:31)\n\tat io.lenses.core.actors.ConnectStatusActorTest.$anonfun$new$1(ConnectStatusActorTest.scala:55)\n\tat org.scalatest.OutcomeOf.outcomeOf(OutcomeOf.scala:85)\n\tat org.scalatest.OutcomeOf.outcomeOf$(OutcomeOf.scala:83)\n\tat org.scalatest.OutcomeOf$.outcomeOf(OutcomeOf.scala:104)\n\tat org.scalatest.Transformer.apply(Transformer.scala:22)\n\tat org.scalatest.Transformer.apply(Transformer.scala:20)\n\tat org.scalatest.wordspec.AnyWordSpecLike$$anon$3.apply(AnyWordSpecLike.scala:1076)\n\tat org.scalatest.TestSuite.withFixture(TestSuite.scala:196)\n\tat org.scalatest.TestSuite.withFixture$(TestSuite.scala:195)\n\tat io.lenses.core.actors.ConnectStatusActorTest.withFixture(ConnectStatusActorTest.scala:31)\n\tat org.scalatest.wordspec.AnyWordSpecLike.invokeWithFixture$1(AnyWordSpecLike.scala:1074)\n\tat org.scalatest.wordspec.AnyWordSpecLike.$anonfun$runTest$1(AnyWordSpecLike.scala:1086)\n\tat org.scalatest.SuperEngine.runTestImpl(Engine.scala:306)\n\tat org.scalatest.wordspec.AnyWordSpecLike.runTest(AnyWordSpecLike.scala:1086)\n\tat org.scalatest.wordspec.AnyWordSpecLike.runTest$(AnyWordSpecLike.scala:1068)\n\tat io.lenses.core.actors.ConnectStatusActorTest.runTest(ConnectStatusActorTest.scala:31)\n\tat org.scalatest.wordspec.AnyWordSpecLike.$anonfun$runTests$1(AnyWordSpecLike.scala:1145)\n\tat org.scalatest.SuperEngine.$anonfun$runTestsInBranch$1(Engine.scala:413)\n\tat scala.collection.immutable.List.foreach(List.scala:392)\n\tat org.scalatest.SuperEngine.traverseSubNodes$1(Engine.scala:401)\n\tat org.scalatest.SuperEngine.runTestsInBranch(Engine.scala:396)\n\tat org.scalatest.SuperEngine.runTestsImpl(Engine.scala:475)\n\tat org.scalatest.wordspec.AnyWordSpecLike.runTests(AnyWordSpecLike.scala:1145)\n\tat org.scalatest.wordspec.AnyWordSpecLike.runTests$(AnyWordSpecLike.scala:1144)\n\tat io.lenses.core.actors.ConnectStatusActorTest.runTests(ConnectStatusActorTest.scala:31)\n\tat org.scalatest.Suite.run(Suite.scala:1112)\n\tat org.scalatest.Suite.run$(Suite.scala:1094)\n\tat io.lenses.core.actors.ConnectStatusActorTest.org$scalatest$wordspec$AnyWordSpecLike$$super$run(ConnectStatusActorTest.scala:31)\n\tat org.scalatest.wordspec.AnyWordSpecLike.$anonfun$run$1(AnyWordSpecLike.scala:1190)\n\tat org.scalatest.SuperEngine.runImpl(Engine.scala:535)\n\tat org.scalatest.wordspec.AnyWordSpecLike.run(AnyWordSpecLike.scala:1190)\n\tat org.scalatest.wordspec.AnyWordSpecLike.run$(AnyWordSpecLike.scala:1188)\n\tat io.lenses.core.actors.ConnectStatusActorTest.org$scalatest$BeforeAndAfterAll$$super$run(ConnectStatusActorTest.scala:31)\n\tat org.scalatest.BeforeAndAfterAll.liftedTree1$1(BeforeAndAfterAll.scala:213)\n\tat org.scalatest.BeforeAndAfterAll.run(BeforeAndAfterAll.scala:210)\n\tat org.scalatest.BeforeAndAfterAll.run$(BeforeAndAfterAll.scala:208)\n\tat io.lenses.core.actors.ConnectStatusActorTest.run(ConnectStatusActorTest.scala:31)\n\tat org.scalatest.tools.Framework.org$scalatest$tools$Framework$$runSuite(Framework.scala:318)\n\tat org.scalatest.tools.Framework$ScalaTestTask.execute(Framework.scala:513)\n\tat sbt.TestRunner.runTest$1(TestFramework.scala:139)\n\tat sbt.TestRunner.run(TestFramework.scala:154)\n\tat sbt.TestFramework$$anon$3$$anonfun$$lessinit$greater$1.$anonfun$apply$1(TestFramework.scala:317)\n\tat sbt.TestFramework$.sbt$TestFramework$$withContextLoader(TestFramework.scala:277)\n\tat sbt.TestFramework$$anon$3$$anonfun$$lessinit$greater$1.apply(TestFramework.scala:317)\n\tat sbt.TestFramework$$anon$3$$anonfun$$lessinit$greater$1.apply(TestFramework.scala:317)\n\tat sbt.TestFunction.apply(TestFramework.scala:329)\n\tat sbt.Tests$.$anonfun$toTask$1(Tests.scala:311)\n\tat sbt.std.Transform$$anon$3.$anonfun$apply$2(Transform.scala:46)\n\tat sbt.std.Transform$$anon$4.work(Transform.scala:67)\n\tat sbt.Execute.$anonfun$submit$2(Execute.scala:281)\n\tat sbt.internal.util.ErrorHandling$.wideConvert(ErrorHandling.scala:19)\n\tat sbt.Execute.work(Execute.scala:290)\n\tat sbt.Execute.$anonfun$submit$1(Execute.scala:281)\n\tat sbt.ConcurrentRestrictions$$anon$4.$anonfun$submitValid$1(ConcurrentRestrictions.scala:178)\n\tat sbt.CompletionService$$anon$2.call(CompletionService.scala:37)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:748)"
          }
        }
      ]
    }
  ],
  "summary": {
    "time": 3095684,
    "tests": 487,
    "failures": 22,
    "errors": 0,
    "skipped": 3
  }
}